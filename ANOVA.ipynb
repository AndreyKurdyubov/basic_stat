{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "945c5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats as scipy_stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b0e1c28",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module statsmodels.api in statsmodels:\n",
      "\n",
      "NAME\n",
      "    statsmodels.api - # -*- coding: utf-8 -*-\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        statsmodels.duration.survfunc.SurvfuncRight\n",
      "        statsmodels.graphics.gofplots.ProbPlot\n",
      "        statsmodels.imputation.bayes_mi.BayesGaussMI\n",
      "        statsmodels.imputation.bayes_mi.MI\n",
      "        statsmodels.imputation.mice.MICE\n",
      "        statsmodels.imputation.mice.MICEData\n",
      "        statsmodels.multivariate.pca.PCA\n",
      "    statsmodels.base._penalized.PenalizedMixin(builtins.object)\n",
      "        statsmodels.gam.generalized_additive_model.GLMGam(statsmodels.base._penalized.PenalizedMixin, statsmodels.genmod.generalized_linear_model.GLM)\n",
      "    statsmodels.base.model.LikelihoodModel(statsmodels.base.model.Model)\n",
      "        statsmodels.duration.hazard_regression.PHReg\n",
      "        statsmodels.genmod.generalized_linear_model.GLM\n",
      "            statsmodels.gam.generalized_additive_model.GLMGam(statsmodels.base._penalized.PenalizedMixin, statsmodels.genmod.generalized_linear_model.GLM)\n",
      "            statsmodels.genmod.generalized_estimating_equations.GEE\n",
      "                statsmodels.genmod.generalized_estimating_equations.NominalGEE\n",
      "                statsmodels.genmod.generalized_estimating_equations.OrdinalGEE\n",
      "        statsmodels.regression.mixed_linear_model.MixedLM\n",
      "        statsmodels.robust.robust_linear_model.RLM\n",
      "    statsmodels.base.model.Model(builtins.object)\n",
      "        statsmodels.multivariate.factor.Factor\n",
      "        statsmodels.multivariate.manova.MANOVA\n",
      "    statsmodels.discrete.count_model.GenericZeroInflated(statsmodels.discrete.discrete_model.CountModel)\n",
      "        statsmodels.discrete.count_model.ZeroInflatedGeneralizedPoisson\n",
      "        statsmodels.discrete.count_model.ZeroInflatedNegativeBinomialP\n",
      "        statsmodels.discrete.count_model.ZeroInflatedPoisson\n",
      "    statsmodels.discrete.discrete_model.BinaryModel(statsmodels.discrete.discrete_model.DiscreteModel)\n",
      "        statsmodels.discrete.discrete_model.Logit\n",
      "        statsmodels.discrete.discrete_model.Probit\n",
      "    statsmodels.discrete.discrete_model.CountModel(statsmodels.discrete.discrete_model.DiscreteModel)\n",
      "        statsmodels.discrete.discrete_model.GeneralizedPoisson\n",
      "        statsmodels.discrete.discrete_model.NegativeBinomial\n",
      "        statsmodels.discrete.discrete_model.NegativeBinomialP\n",
      "        statsmodels.discrete.discrete_model.Poisson\n",
      "    statsmodels.discrete.discrete_model.MultinomialModel(statsmodels.discrete.discrete_model.BinaryModel)\n",
      "        statsmodels.discrete.discrete_model.MNLogit\n",
      "    statsmodels.genmod.bayes_mixed_glm._BayesMixedGLM(statsmodels.base.model.Model)\n",
      "        statsmodels.genmod.bayes_mixed_glm.BinomialBayesMixedGLM(statsmodels.genmod.bayes_mixed_glm._VariationalBayesMixedGLM, statsmodels.genmod.bayes_mixed_glm._BayesMixedGLM)\n",
      "        statsmodels.genmod.bayes_mixed_glm.PoissonBayesMixedGLM(statsmodels.genmod.bayes_mixed_glm._VariationalBayesMixedGLM, statsmodels.genmod.bayes_mixed_glm._BayesMixedGLM)\n",
      "    statsmodels.genmod.bayes_mixed_glm._VariationalBayesMixedGLM(builtins.object)\n",
      "        statsmodels.genmod.bayes_mixed_glm.BinomialBayesMixedGLM(statsmodels.genmod.bayes_mixed_glm._VariationalBayesMixedGLM, statsmodels.genmod.bayes_mixed_glm._BayesMixedGLM)\n",
      "        statsmodels.genmod.bayes_mixed_glm.PoissonBayesMixedGLM(statsmodels.genmod.bayes_mixed_glm._VariationalBayesMixedGLM, statsmodels.genmod.bayes_mixed_glm._BayesMixedGLM)\n",
      "    statsmodels.regression.linear_model.RegressionModel(statsmodels.base.model.LikelihoodModel)\n",
      "        statsmodels.regression.linear_model.GLS\n",
      "            statsmodels.regression.linear_model.GLSAR\n",
      "        statsmodels.regression.linear_model.WLS\n",
      "            statsmodels.regression.linear_model.OLS\n",
      "        statsmodels.regression.quantile_regression.QuantReg\n",
      "    statsmodels.tsa.statespace.mlemodel.MLEModel(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "        statsmodels.regression.recursive_ls.RecursiveLS\n",
      "    \n",
      "    class BayesGaussMI(builtins.object)\n",
      "     |  BayesGaussMI(data, mean_prior=None, cov_prior=None, cov_prior_df=1)\n",
      "     |  \n",
      "     |  Bayesian Imputation using a Gaussian model.\n",
      "     |  \n",
      "     |  The approach is Bayesian.  The goal is to sample from the joint\n",
      "     |  distribution of the mean vector, covariance matrix, and missing\n",
      "     |  data values given the observed data values.  Conjugate priors for\n",
      "     |  the population mean and covariance matrix are used.  Gibbs\n",
      "     |  sampling is used to update the mean vector, covariance matrix, and\n",
      "     |  missing data values in turn.  After burn-in, the imputed complete\n",
      "     |  data sets from the Gibbs chain can be used in multiple imputation\n",
      "     |  analyses (MI).\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : ndarray\n",
      "     |      The array of data to be imputed.  Values in the array equal to\n",
      "     |      NaN are imputed.\n",
      "     |  mean_prior : ndarray, optional\n",
      "     |      The covariance matrix of the Gaussian prior distribution for\n",
      "     |      the mean vector.  If not provided, the identity matrix is\n",
      "     |      used.\n",
      "     |  cov_prior : ndarray, optional\n",
      "     |      The center matrix for the inverse Wishart prior distribution\n",
      "     |      for the covariance matrix.  If not provided, the identity\n",
      "     |      matrix is used.\n",
      "     |  cov_prior_df : positive float\n",
      "     |      The degrees of freedom of the inverse Wishart prior\n",
      "     |      distribution for the covariance matrix.  Defaults to 1.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  A basic example with OLS. Data is generated assuming 10% is missing at\n",
      "     |  random.\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> x = np.random.standard_normal((1000, 2))\n",
      "     |  >>> x.flat[np.random.sample(2000) < 0.1] = np.nan\n",
      "     |  \n",
      "     |  The imputer is used with ``MI``.\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> def model_args_fn(x):\n",
      "     |  ...     # Return endog, exog from x\n",
      "     |  ...    return x[:, 0], x[:, 1:]\n",
      "     |  >>> imp = sm.BayesGaussMI(x)\n",
      "     |  >>> mi = sm.MI(imp, sm.OLS, model_args_fn)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data, mean_prior=None, cov_prior=None, cov_prior_df=1)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  update(self)\n",
      "     |      Cycle through all Gibbs updates.\n",
      "     |  \n",
      "     |  update_cov(self)\n",
      "     |      Gibbs update of the covariance matrix.\n",
      "     |      \n",
      "     |      Do not call until update_data has been called once.\n",
      "     |  \n",
      "     |  update_data(self)\n",
      "     |      Gibbs update of the missing data values.\n",
      "     |  \n",
      "     |  update_mean(self)\n",
      "     |      Gibbs update of the mean vector.\n",
      "     |      \n",
      "     |      Do not call until update_data has been called once.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class BinomialBayesMixedGLM(_VariationalBayesMixedGLM, _BayesMixedGLM)\n",
      "     |  BinomialBayesMixedGLM(endog, exog, exog_vc, ident, vcp_p=1, fe_p=2, fep_names=None, vcp_names=None, vc_names=None)\n",
      "     |  \n",
      "     |  Generalized Linear Mixed Model with Bayesian estimation\n",
      "     |  \n",
      "     |  The class implements the Laplace approximation to the posterior\n",
      "     |  distribution (`fit_map`) and a variational Bayes approximation to\n",
      "     |  the posterior (`fit_vb`).  See the two fit method docstrings for\n",
      "     |  more information about the fitting approaches.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      Vector of response values.\n",
      "     |  exog : array_like\n",
      "     |      Array of covariates for the fixed effects part of the mean\n",
      "     |      structure.\n",
      "     |  exog_vc : array_like\n",
      "     |      Array of covariates for the random part of the model.  A\n",
      "     |      scipy.sparse array may be provided, or else the passed\n",
      "     |      array will be converted to sparse internally.\n",
      "     |  ident : array_like\n",
      "     |      Array of integer labels showing which random terms (columns\n",
      "     |      of `exog_vc`) have a common variance.\n",
      "     |  vcp_p : float\n",
      "     |      Prior standard deviation for variance component parameters\n",
      "     |      (the prior standard deviation of log(s) is vcp_p, where s is\n",
      "     |      the standard deviation of a random effect).\n",
      "     |  fe_p : float\n",
      "     |      Prior standard deviation for fixed effects parameters.\n",
      "     |  family : statsmodels.genmod.families instance\n",
      "     |      The GLM family.\n",
      "     |  fep_names : list[str]\n",
      "     |      The names of the fixed effects parameters (corresponding to\n",
      "     |      columns of exog).  If None, default names are constructed.\n",
      "     |  vcp_names : list[str]\n",
      "     |      The names of the variance component parameters (corresponding\n",
      "     |      to distinct labels in ident).  If None, default names are\n",
      "     |      constructed.\n",
      "     |  vc_names : list[str]\n",
      "     |      The names of the random effect realizations.\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  MixedGLMResults object\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  There are three types of values in the posterior distribution:\n",
      "     |  fixed effects parameters (fep), corresponding to the columns of\n",
      "     |  `exog`, random effects realizations (vc), corresponding to the\n",
      "     |  columns of `exog_vc`, and the standard deviations of the random\n",
      "     |  effects realizations (vcp), corresponding to the unique integer\n",
      "     |  labels in `ident`.\n",
      "     |  \n",
      "     |  All random effects are modeled as being independent Gaussian\n",
      "     |  values (given the variance structure parameters).  Every column of\n",
      "     |  `exog_vc` has a distinct realized random effect that is used to\n",
      "     |  form the linear predictors.  The elements of `ident` determine the\n",
      "     |  distinct variance structure parameters.  Two random effect\n",
      "     |  realizations that have the same value in `ident` have the same\n",
      "     |  variance.  When fitting with a formula, `ident` is constructed\n",
      "     |  internally (each element of `vc_formulas` yields a distinct label\n",
      "     |  in `ident`).\n",
      "     |  \n",
      "     |  The random effect standard deviation parameters (`vcp`) have\n",
      "     |  log-normal prior distributions with mean 0 and standard deviation\n",
      "     |  `vcp_p`.\n",
      "     |  \n",
      "     |  Note that for some families, e.g. Binomial, the posterior mode may\n",
      "     |  be difficult to find numerically if `vcp_p` is set to too large of\n",
      "     |  a value.  Setting `vcp_p` to 0.5 seems to work well.\n",
      "     |  \n",
      "     |  The prior for the fixed effects parameters is Gaussian with mean 0\n",
      "     |  and standard deviation `fe_p`.  It is recommended that quantitative\n",
      "     |  covariates be standardized.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  A binomial (logistic) random effects model with random intercepts\n",
      "     |  for villages and random slopes for each year within each village:\n",
      "     |  \n",
      "     |  >>> random = {\"a\": '0 + C(Village)', \"b\": '0 + C(Village)*year_cen'}\n",
      "     |  >>> model = BinomialBayesMixedGLM.from_formula(\n",
      "     |                 'y ~ year_cen', random, data)\n",
      "     |  >>> result = model.fit_vb()\n",
      "     |  \n",
      "     |  \n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Introduction to generalized linear mixed models:\n",
      "     |  https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models\n",
      "     |  \n",
      "     |  SAS documentation:\n",
      "     |  https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_intromix_a0000000215.htm\n",
      "     |  \n",
      "     |  An assessment of estimation methods for generalized linear mixed\n",
      "     |  models with binary outcomes\n",
      "     |  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3866838/\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BinomialBayesMixedGLM\n",
      "     |      _VariationalBayesMixedGLM\n",
      "     |      _BayesMixedGLM\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, exog_vc, ident, vcp_p=1, fe_p=2, fep_names=None, vcp_names=None, vc_names=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  vb_elbo(self, vb_mean, vb_sd)\n",
      "     |      Returns the evidence lower bound (ELBO) for the model.\n",
      "     |  \n",
      "     |  vb_elbo_grad(self, vb_mean, vb_sd)\n",
      "     |      Returns the gradient of the model's evidence lower bound (ELBO).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, vc_formulas, data, vcp_p=1, fe_p=2) from builtins.type\n",
      "     |      Fit a BayesMixedGLM using a formula.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str\n",
      "     |          Formula for the endog and fixed effects terms (use ~ to\n",
      "     |          separate dependent and independent expressions).\n",
      "     |      vc_formulas : dictionary\n",
      "     |          vc_formulas[name] is a one-sided formula that creates one\n",
      "     |          collection of random effects with a common variance\n",
      "     |          parameter.  If using categorical (factor) variables to\n",
      "     |          produce variance components, note that generally `0 + ...`\n",
      "     |          should be used so that an intercept is not included.\n",
      "     |      data : data frame\n",
      "     |          The data to which the formulas are applied.\n",
      "     |      family : genmod.families instance\n",
      "     |          A GLM family.\n",
      "     |      vcp_p : float\n",
      "     |          The prior standard deviation for the logarithms of the standard\n",
      "     |          deviations of the random effects.\n",
      "     |      fe_p : float\n",
      "     |          The prior standard deviation for the fixed effects parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _VariationalBayesMixedGLM:\n",
      "     |  \n",
      "     |  fit_vb(self, mean=None, sd=None, fit_method='BFGS', minim_opts=None, scale_fe=False, verbose=False)\n",
      "     |      Fit a model using the variational Bayes mean field approximation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : array_like\n",
      "     |          Starting value for VB mean vector\n",
      "     |      sd : array_like\n",
      "     |          Starting value for VB standard deviation vector\n",
      "     |      fit_method : str\n",
      "     |          Algorithm for scipy.minimize\n",
      "     |      minim_opts : dict\n",
      "     |          Options passed to scipy.minimize\n",
      "     |      scale_fe : bool\n",
      "     |          If true, the columns of the fixed effects design matrix\n",
      "     |          are centered and scaled to unit variance before fitting\n",
      "     |          the model.  The results are back-transformed so that the\n",
      "     |          results are presented on the original scale.\n",
      "     |      verbose : bool\n",
      "     |          If True, print the gradient norm to the screen each time\n",
      "     |          it is calculated.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The goal is to find a factored Gaussian approximation\n",
      "     |      q1*q2*...  to the posterior distribution, approximately\n",
      "     |      minimizing the KL divergence from the factored approximation\n",
      "     |      to the actual posterior.  The KL divergence, or ELBO function\n",
      "     |      has the form\n",
      "     |      \n",
      "     |          E* log p(y, fe, vcp, vc) - E* log q\n",
      "     |      \n",
      "     |      where E* is expectation with respect to the product of qj.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Blei, Kucukelbir, McAuliffe (2017).  Variational Inference: A\n",
      "     |      review for Statisticians\n",
      "     |      https://arxiv.org/pdf/1601.00670.pdf\n",
      "     |  \n",
      "     |  vb_elbo_base(self, h, tm, fep_mean, vcp_mean, vc_mean, fep_sd, vcp_sd, vc_sd)\n",
      "     |      Returns the evidence lower bound (ELBO) for the model.\n",
      "     |      \n",
      "     |      This function calculates the family-specific ELBO function\n",
      "     |      based on information provided from a subclass.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      h : function mapping 1d vector to 1d vector\n",
      "     |          The contribution of the model to the ELBO function can be\n",
      "     |          expressed as y_i*lp_i + Eh_i(z), where y_i and lp_i are\n",
      "     |          the response and linear predictor for observation i, and z\n",
      "     |          is a standard normal random variable.  This formulation\n",
      "     |          can be achieved for any GLM with a canonical link\n",
      "     |          function.\n",
      "     |  \n",
      "     |  vb_elbo_grad_base(self, h, tm, tv, fep_mean, vcp_mean, vc_mean, fep_sd, vcp_sd, vc_sd)\n",
      "     |      Return the gradient of the ELBO function.\n",
      "     |      \n",
      "     |      See vb_elbo_base for parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _VariationalBayesMixedGLM:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _VariationalBayesMixedGLM:\n",
      "     |  \n",
      "     |  rng = 5\n",
      "     |  \n",
      "     |  verbose = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BayesMixedGLM:\n",
      "     |  \n",
      "     |  fit(self, method='BFGS', minim_opts=None)\n",
      "     |      fit is equivalent to fit_map.\n",
      "     |      \n",
      "     |      See fit_map for parameter information.\n",
      "     |      \n",
      "     |      Use `fit_vb` to fit the model using variational Bayes.\n",
      "     |  \n",
      "     |  fit_map(self, method='BFGS', minim_opts=None, scale_fe=False)\n",
      "     |      Construct the Laplace approximation to the posterior distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str\n",
      "     |          Optimization method for finding the posterior mode.\n",
      "     |      minim_opts : dict\n",
      "     |          Options passed to scipy.minimize.\n",
      "     |      scale_fe : bool\n",
      "     |          If True, the columns of the fixed effects design matrix\n",
      "     |          are centered and scaled to unit variance before fitting\n",
      "     |          the model.  The results are back-transformed so that the\n",
      "     |          results are presented on the original scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      BayesMixedGLMResults instance.\n",
      "     |  \n",
      "     |  logposterior(self, params)\n",
      "     |      The overall log-density: log p(y, fe, vc, vcp).\n",
      "     |      \n",
      "     |      This differs by an additive constant from the log posterior\n",
      "     |      log p(fe, vc, vcp | y).\n",
      "     |  \n",
      "     |  logposterior_grad(self, params)\n",
      "     |      The gradient of the log posterior.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, linear=False)\n",
      "     |      Return the fitted mean structure.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameter vector, may be the full parameter vector, or may\n",
      "     |          be truncated to include only the mean parameters.\n",
      "     |      exog : array_like\n",
      "     |          The design matrix for the mean structure.  If omitted, use the\n",
      "     |          model's design matrix.\n",
      "     |      linear : bool\n",
      "     |          If True, return the linear predictor without passing through the\n",
      "     |          link function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A 1-dimensional array of predicted values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "    \n",
      "    class Factor(statsmodels.base.model.Model)\n",
      "     |  Factor(endog=None, n_factor=1, corr=None, method='pa', smc=True, endog_names=None, nobs=None, missing='drop')\n",
      "     |  \n",
      "     |  Factor analysis\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      Variables in columns, observations in rows.  May be `None` if\n",
      "     |      `corr` is not `None`.\n",
      "     |  n_factor : int\n",
      "     |      The number of factors to extract\n",
      "     |  corr : array_like\n",
      "     |      Directly specify the correlation matrix instead of estimating\n",
      "     |      it from `endog`.  If provided, `endog` is not used for the\n",
      "     |      factor analysis, it may be used in post-estimation.\n",
      "     |  method : str\n",
      "     |      The method to extract factors, currently must be either 'pa'\n",
      "     |      for principal axis factor analysis or 'ml' for maximum\n",
      "     |      likelihood estimation.\n",
      "     |  smc : True or False\n",
      "     |      Whether or not to apply squared multiple correlations (method='pa')\n",
      "     |  endog_names : str\n",
      "     |      Names of endogenous variables.  If specified, it will be used\n",
      "     |      instead of the column names in endog\n",
      "     |  nobs : int\n",
      "     |      The number of observations, not used if endog is present. Needs to\n",
      "     |      be provided for inference if endog is None.\n",
      "     |  missing : 'none', 'drop', or 'raise'\n",
      "     |      Missing value handling for endog, default is row-wise deletion 'drop'\n",
      "     |      If 'none', no nan checking is done. If 'drop', any observations with\n",
      "     |      nans are dropped. If 'raise', an error is raised.\n",
      "     |  \n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  **Experimental**\n",
      "     |  \n",
      "     |  Supported rotations: 'varimax', 'quartimax', 'biquartimax',\n",
      "     |  'equamax', 'oblimin', 'parsimax', 'parsimony', 'biquartimin',\n",
      "     |  'promax'\n",
      "     |  \n",
      "     |  If method='ml', the factors are rotated to satisfy condition IC3\n",
      "     |  of Bai and Li (2012).  This means that the scores have covariance\n",
      "     |  I, so the model for the covariance matrix is L * L' + diag(U),\n",
      "     |  where L are the loadings and U are the uniquenesses.  In addition,\n",
      "     |  L' * diag(U)^{-1} L must be diagonal.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [*] Hofacker, C. (2004). Exploratory Factor Analysis, Mathematical\n",
      "     |     Marketing. http://www.openaccesstexts.org/pdf/Quant_Chapter_11_efa.pdf\n",
      "     |  .. [*] J Bai, K Li (2012).  Statistical analysis of factor models of high\n",
      "     |     dimension.  Annals of Statistics. https://arxiv.org/pdf/1205.6617.pdf\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Factor\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog=None, n_factor=1, corr=None, method='pa', smc=True, endog_names=None, nobs=None, missing='drop')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, maxiter=50, tol=1e-08, start=None, opt_method='BFGS', opt=None, em_iter=3)\n",
      "     |      Estimate factor model parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations for iterative estimation algorithms\n",
      "     |      tol : float\n",
      "     |          Stopping criteria (error tolerance) for iterative estimation\n",
      "     |          algorithms\n",
      "     |      start : array_like\n",
      "     |          Starting values, currently only used for ML estimation\n",
      "     |      opt_method : str\n",
      "     |          Optimization method for ML estimation\n",
      "     |      opt : dict-like\n",
      "     |          Keyword arguments passed to optimizer, only used for ML estimation\n",
      "     |      em_iter : int\n",
      "     |          The number of EM iterations before starting gradient optimization,\n",
      "     |          only used for ML estimation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      FactorResults\n",
      "     |          Results class instance.\n",
      "     |  \n",
      "     |  loglike(self, par)\n",
      "     |      Evaluate the log-likelihood function.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      par : ndarray or tuple of 2 ndarray's\n",
      "     |          The model parameters, either a packed representation of\n",
      "     |          the model parameters or a 2-tuple containing a `k_endog x\n",
      "     |          n_factor` matrix of factor loadings and a `k_endog` vector\n",
      "     |          of uniquenesses.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The value of the log-likelihood evaluated at par.\n",
      "     |  \n",
      "     |  score(self, par)\n",
      "     |      Evaluate the score function (first derivative of loglike).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      par : ndarray or tuple of 2 ndarray's\n",
      "     |          The model parameters, either a packed representation of\n",
      "     |          the model parameters or a 2-tuple containing a `k_endog x\n",
      "     |          n_factor` matrix of factor loadings and a `k_endog` vector\n",
      "     |          of uniquenesses.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score function evaluated at par.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GEE(statsmodels.genmod.generalized_linear_model.GLM)\n",
      "     |  GEE(endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs)\n",
      "     |  \n",
      "     |  Marginal Regression Model using Generalized Estimating Equations.\n",
      "     |  \n",
      "     |  Marginal regression model fit using Generalized Estimating Equations.\n",
      "     |  \n",
      "     |  GEE can be used to fit Generalized Linear Models (GLMs) when the\n",
      "     |  data have a grouped structure, and the observations are possibly\n",
      "     |  correlated within groups but not between groups.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      1d array of endogenous values (i.e. responses, outcomes,\n",
      "     |      dependent variables, or 'Y' values).\n",
      "     |  exog : array_like\n",
      "     |      2d array of exogeneous values (i.e. covariates, predictors,\n",
      "     |      independent variables, regressors, or 'X' values). A `nobs x\n",
      "     |      k` array where `nobs` is the number of observations and `k` is\n",
      "     |      the number of regressors. An intercept is not included by\n",
      "     |      default and should be added by the user. See\n",
      "     |      `statsmodels.tools.add_constant`.\n",
      "     |  groups : array_like\n",
      "     |      A 1d array of length `nobs` containing the group labels.\n",
      "     |  time : array_like\n",
      "     |      A 2d array of time (or other index) values, used by some\n",
      "     |      dependence structures to define similarity relationships among\n",
      "     |      observations within a cluster.\n",
      "     |  family : family class instance\n",
      "     |      The default is Gaussian.  To specify the binomial\n",
      "     |      distribution use `family=sm.families.Binomial()`. Each family\n",
      "     |      can take a link instance as an argument.  See\n",
      "     |      statsmodels.genmod.families.family for more information.\n",
      "     |  cov_struct : CovStruct class instance\n",
      "     |      The default is Independence.  To specify an exchangeable\n",
      "     |      structure use cov_struct = Exchangeable().  See\n",
      "     |      statsmodels.genmod.cov_struct.CovStruct for more\n",
      "     |      information.\n",
      "     |  offset : array_like\n",
      "     |      An offset to be included in the fit.  If provided, must be\n",
      "     |      an array whose length is the number of rows in exog.\n",
      "     |  dep_data : array_like\n",
      "     |      Additional data passed to the dependence structure.\n",
      "     |  constraint : (ndarray, ndarray)\n",
      "     |      If provided, the constraint is a tuple (L, R) such that the\n",
      "     |      model parameters are estimated under the constraint L *\n",
      "     |      param = R, where L is a q x p matrix and R is a\n",
      "     |      q-dimensional vector.  If constraint is provided, a score\n",
      "     |      test is performed to compare the constrained model to the\n",
      "     |      unconstrained model.\n",
      "     |  update_dep : bool\n",
      "     |      If true, the dependence parameters are optimized, otherwise\n",
      "     |      they are held fixed at their starting values.\n",
      "     |  weights : array_like\n",
      "     |      An array of case weights to use in the analysis.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.genmod.families.family\n",
      "     |  :ref:`families`\n",
      "     |  :ref:`links`\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Only the following combinations make sense for family and link ::\n",
      "     |  \n",
      "     |                 + ident log logit probit cloglog pow opow nbinom loglog logc\n",
      "     |    Gaussian     |   x    x                        x\n",
      "     |    inv Gaussian |   x    x                        x\n",
      "     |    binomial     |   x    x    x     x       x     x    x           x      x\n",
      "     |    Poisson      |   x    x                        x\n",
      "     |    neg binomial |   x    x                        x          x\n",
      "     |    gamma        |   x    x                        x\n",
      "     |  \n",
      "     |  Not all of these link functions are currently available.\n",
      "     |  \n",
      "     |  Endog and exog are references so that if the data they refer\n",
      "     |  to are already arrays and these arrays are changed, endog and\n",
      "     |  exog will change.\n",
      "     |  \n",
      "     |  The \"robust\" covariance type is the standard \"sandwich estimator\"\n",
      "     |  (e.g. Liang and Zeger (1986)).  It is the default here and in most\n",
      "     |  other packages.  The \"naive\" estimator gives smaller standard\n",
      "     |  errors, but is only correct if the working correlation structure\n",
      "     |  is correctly specified.  The \"bias reduced\" estimator of Mancl and\n",
      "     |  DeRouen (Biometrics, 2001) reduces the downward bias of the robust\n",
      "     |  estimator.\n",
      "     |  \n",
      "     |  The robust covariance provided here follows Liang and Zeger (1986)\n",
      "     |  and agrees with R's gee implementation.  To obtain the robust\n",
      "     |  standard errors reported in Stata, multiply by sqrt(N / (N - g)),\n",
      "     |  where N is the total sample size, and g is the average group size.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  Logistic regression with autoregressive working dependence:\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> family = sm.families.Binomial()\n",
      "     |  >>> va = sm.cov_struct.Autoregressive()\n",
      "     |  >>> model = sm.GEE(endog, exog, group, family=family, cov_struct=va)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Use formulas to fit a Poisson GLM with independent working\n",
      "     |  dependence:\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> fam = sm.families.Poisson()\n",
      "     |  >>> ind = sm.cov_struct.Independence()\n",
      "     |  >>> model = sm.GEE.from_formula(\"y ~ age + trt + base\", \"subject\",\n",
      "     |                               data, cov_struct=ind, family=fam)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Equivalent, using the formula API:\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> import statsmodels.formula.api as smf\n",
      "     |  >>> fam = sm.families.Poisson()\n",
      "     |  >>> ind = sm.cov_struct.Independence()\n",
      "     |  >>> model = smf.gee(\"y ~ age + trt + base\", \"subject\",\n",
      "     |                  data, cov_struct=ind, family=fam)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GEE\n",
      "     |      statsmodels.genmod.generalized_linear_model.GLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  cluster_list(self, array)\n",
      "     |      Returns `array` split into subarrays corresponding to the\n",
      "     |      cluster structure.\n",
      "     |  \n",
      "     |  compare_score_test(self, submodel)\n",
      "     |      Perform a score test for the given submodel against this model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      submodel : GEEResults instance\n",
      "     |          A fitted GEE model that is a submodel of this model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A dictionary with keys \"statistic\", \"p-value\", and \"df\",\n",
      "     |      containing the score test statistic, its chi^2 p-value,\n",
      "     |      and the degrees of freedom used to compute the p-value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The score test can be performed without calling 'fit' on the\n",
      "     |      larger model.  The provided submodel must be obtained from a\n",
      "     |      fitted GEE.\n",
      "     |      \n",
      "     |      This method performs the same score test as can be obtained by\n",
      "     |      fitting the GEE with a linear constraint and calling `score_test`\n",
      "     |      on the results.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Xu Guo and Wei Pan (2002). \"Small sample performance of the score\n",
      "     |      test in GEE\".\n",
      "     |      http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\n",
      "     |  \n",
      "     |  estimate_scale(self)\n",
      "     |      Estimate the dispersion/scale.\n",
      "     |  \n",
      "     |  fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust', ddof_scale=None, scaling_factor=1.0, scale=None)\n",
      "     |      Fits a marginal regression model using generalized estimating\n",
      "     |      equations (GEE).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxiter : int\n",
      "     |          The maximum number of iterations\n",
      "     |      ctol : float\n",
      "     |          The convergence criterion for stopping the Gauss-Seidel\n",
      "     |          iterations\n",
      "     |      start_params : array_like\n",
      "     |          A vector of starting values for the regression\n",
      "     |          coefficients.  If None, a default is chosen.\n",
      "     |      params_niter : int\n",
      "     |          The number of Gauss-Seidel updates of the mean structure\n",
      "     |          parameters that take place prior to each update of the\n",
      "     |          dependence structure.\n",
      "     |      first_dep_update : int\n",
      "     |          No dependence structure updates occur before this\n",
      "     |          iteration number.\n",
      "     |      cov_type : str\n",
      "     |          One of \"robust\", \"naive\", or \"bias_reduced\".\n",
      "     |      ddof_scale : scalar or None\n",
      "     |          The scale parameter is estimated as the sum of squared\n",
      "     |          Pearson residuals divided by `N - ddof_scale`, where N\n",
      "     |          is the total sample size.  If `ddof_scale` is None, the\n",
      "     |          number of covariates (including an intercept if present)\n",
      "     |          is used.\n",
      "     |      scaling_factor : scalar\n",
      "     |          The estimated covariance of the parameter estimates is\n",
      "     |          scaled by this value.  Default is 1, Stata uses N / (N - g),\n",
      "     |          where N is the total sample size and g is the average group\n",
      "     |          size.\n",
      "     |      scale : str or float, optional\n",
      "     |          `scale` can be None, 'X2', or a float\n",
      "     |          If a float, its value is used as the scale parameter.\n",
      "     |          The default value is None, which uses `X2` (Pearson's\n",
      "     |          chi-square) for Gamma, Gaussian, and Inverse Gaussian.\n",
      "     |          The default is 1 for the Binomial and Poisson families.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An instance of the GEEResults class or subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If convergence difficulties occur, increase the values of\n",
      "     |      `first_dep_update` and/or `params_niter`.  Setting\n",
      "     |      `first_dep_update` to a greater value (e.g. ~10-20) causes the\n",
      "     |      algorithm to move close to the GLM solution before attempting\n",
      "     |      to identify the dependence structure.\n",
      "     |      \n",
      "     |      For the Gaussian family, there is no benefit to setting\n",
      "     |      `params_niter` to a value greater than 1, since the mean\n",
      "     |      structure parameters converge in one step.\n",
      "     |  \n",
      "     |  fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None)\n",
      "     |      Regularized estimation for GEE.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pen_wt : float\n",
      "     |          The penalty weight (a non-negative scalar).\n",
      "     |      scad_param : float\n",
      "     |          Non-negative scalar determining the shape of the Scad\n",
      "     |          penalty.\n",
      "     |      maxiter : int\n",
      "     |          The maximum number of iterations.\n",
      "     |      ddof_scale : int\n",
      "     |          Value to subtract from `nobs` when calculating the\n",
      "     |          denominator degrees of freedom for t-statistics, defaults\n",
      "     |          to the number of columns in `exog`.\n",
      "     |      update_assoc : int\n",
      "     |          The dependence parameters are updated every `update_assoc`\n",
      "     |          iterations of the mean structure parameter updates.\n",
      "     |      ctol : float\n",
      "     |          Convergence criterion, default is one order of magnitude\n",
      "     |          smaller than proposed in section 3.1 of Wang et al.\n",
      "     |      ztol : float\n",
      "     |          Coefficients smaller than this value are treated as\n",
      "     |          being zero, default is based on section 5 of Wang et al.\n",
      "     |      eps : non-negative scalar\n",
      "     |          Numerical constant, see section 3.2 of Wang et al.\n",
      "     |      scale : float or string\n",
      "     |          If a float, this value is used as the scale parameter.\n",
      "     |          If \"X2\", the scale parameter is always estimated using\n",
      "     |          Pearson's chi-square method (e.g. as in a quasi-Poisson\n",
      "     |          analysis).  If None, the default approach for the family\n",
      "     |          is used to estimate the scale parameter.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GEEResults instance.  Note that not all methods of the results\n",
      "     |      class make sense when the model has been fit with regularization.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This implementation assumes that the link is canonical.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\n",
      "     |      equations for high-dimensional longitudinal data analysis.\n",
      "     |      Biometrics. 2012 Jun;68(2):353-60.\n",
      "     |      doi: 10.1111/j.1541-0420.2011.01678.x.\n",
      "     |      https://www.ncbi.nlm.nih.gov/pubmed/21955051\n",
      "     |      http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\n",
      "     |  \n",
      "     |  mean_deriv(self, exog, lin_pred)\n",
      "     |      Derivative of the expected endog with respect to the parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array_like\n",
      "     |         The exogeneous data at which the derivative is computed.\n",
      "     |      lin_pred : array_like\n",
      "     |         The values of the linear predictor.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The value of the derivative of the expected endog with respect\n",
      "     |      to the parameter vector.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If there is an offset or exposure, it should be added to\n",
      "     |      `lin_pred` prior to calling this function.\n",
      "     |  \n",
      "     |  mean_deriv_exog(self, exog, params, offset_exposure=None)\n",
      "     |      Derivative of the expected endog with respect to exog.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array_like\n",
      "     |          Values of the independent variables at which the derivative\n",
      "     |          is calculated.\n",
      "     |      params : array_like\n",
      "     |          Parameter values at which the derivative is calculated.\n",
      "     |      offset_exposure : array_like, optional\n",
      "     |          Combined offset and exposure.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The derivative of the expected endog with respect to exog.\n",
      "     |  \n",
      "     |  qic(self, params, scale, cov_params, n_step=1000)\n",
      "     |      Returns quasi-information criteria and quasi-likelihood values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The GEE estimates of the regression parameters.\n",
      "     |      scale : scalar\n",
      "     |          Estimated scale parameter\n",
      "     |      cov_params : array_like\n",
      "     |          An estimate of the covariance matrix for the\n",
      "     |          model parameters.  Conventionally this is the robust\n",
      "     |          covariance matrix.\n",
      "     |      n_step : integer\n",
      "     |          The number of points in the trapezoidal approximation\n",
      "     |          to the quasi-likelihood function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ql : scalar\n",
      "     |          The quasi-likelihood value\n",
      "     |      qic : scalar\n",
      "     |          A QIC that can be used to compare the mean and covariance\n",
      "     |          structures of the model.\n",
      "     |      qicu : scalar\n",
      "     |          A simplified QIC that can be used to compare mean structures\n",
      "     |          but not covariance structures\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The quasi-likelihood used here is obtained by numerically evaluating\n",
      "     |      Wedderburn's integral representation of the quasi-likelihood function.\n",
      "     |      This approach is valid for all families and  links.  Many other\n",
      "     |      packages use analytical expressions for quasi-likelihoods that are\n",
      "     |      valid in special cases where the link function is canonical.  These\n",
      "     |      analytical expressions may omit additive constants that only depend\n",
      "     |      on the data.  Therefore, the numerical values of our QL and QIC values\n",
      "     |      will differ from the values reported by other packages.  However only\n",
      "     |      the differences between two QIC values calculated for different models\n",
      "     |      using the same data are meaningful.  Our QIC should produce the same\n",
      "     |      QIC differences as other software.\n",
      "     |      \n",
      "     |      When using the QIC for models with unknown scale parameter, use a\n",
      "     |      common estimate of the scale parameter for all models being compared.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] W. Pan (2001).  Akaike's information criterion in generalized\n",
      "     |             estimating equations.  Biometrics (57) 1.\n",
      "     |  \n",
      "     |  update_cached_means(self, mean_params)\n",
      "     |      cached_means should always contain the most recent calculation\n",
      "     |      of the group-wise mean vectors.  This function should be\n",
      "     |      called every time the regression parameters are changed, to\n",
      "     |      keep the cached means up to date.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  cached_means = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.genmod.generalized_linear_model.GLM:\n",
      "     |  \n",
      "     |  estimate_tweedie_power(self, mu, method='brentq', low=1.01, high=5.0)\n",
      "     |      Tweedie specific function to estimate scale and the variance parameter.\n",
      "     |      The variance parameter is also referred to as p, xi, or shape.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : array_like\n",
      "     |          Fitted mean response variable\n",
      "     |      method : str, defaults to 'brentq'\n",
      "     |          Scipy optimizer used to solve the Pearson equation. Only brentq\n",
      "     |          currently supported.\n",
      "     |      low : float, optional\n",
      "     |          Low end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 1.01.\n",
      "     |      high : float, optional\n",
      "     |          High end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 5.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      power : float\n",
      "     |          The estimated shape or power.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      fit the model subject to linear equality constraints\n",
      "     |      \n",
      "     |      The constraints are of the form   `R params = q`\n",
      "     |      where R is the constraint_matrix and q is the vector of\n",
      "     |      constraint_values.\n",
      "     |      \n",
      "     |      The estimation creates a new model with transformed design matrix,\n",
      "     |      exog, and converts the results back to the original parameterization.\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : formula expression or tuple\n",
      "     |          If it is a tuple, then the constraint needs to be given by two\n",
      "     |          arrays (constraint_matrix, constraint_value), i.e. (R, q).\n",
      "     |          Otherwise, the constraints can be given as strings or list of\n",
      "     |          strings.\n",
      "     |          see t_test for details\n",
      "     |      start_params : None or array_like\n",
      "     |          starting values for the optimization. `start_params` needs to be\n",
      "     |          given in the original parameter space and are internally\n",
      "     |          transformed.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the transformed model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale=None, exog=None, exposure=None, offset=None, var_weights=1.0, n_trials=1.0)\n",
      "     |      Return a instance of the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters.\n",
      "     |      scale : scalar\n",
      "     |          The scale parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      offset : array_like or None\n",
      "     |          Offset variable for predicted mean.\n",
      "     |      exposure : array_like or None\n",
      "     |          Log(exposure) will be added to the linear prediction.\n",
      "     |      var_weights : array_like\n",
      "     |          1d array of variance (analytic) weights. The default is None.\n",
      "     |      n_trials : int\n",
      "     |          Number of trials for the binomial distribution. The default is 1\n",
      "     |          which corresponds to a Bernoulli random variable.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Instance of a scipy frozen distribution based on estimated\n",
      "     |          parameters.\n",
      "     |          Use the ``rvs`` method to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``, the\n",
      "     |      returned random number generator must be called with ``gen.rvs(n)``\n",
      "     |      where ``n`` is the number of observations in the data set used\n",
      "     |      to fit the model.  If any other value is used for ``n``, misleading\n",
      "     |      results will be produced.\n",
      "     |  \n",
      "     |  hessian(self, params, scale=None, observed=None)\n",
      "     |      Hessian, second derivative of loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned (default).\n",
      "     |          If False, then the expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian, i.e. observed information, or expected information matrix.\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Weights for calculating Hessian\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian_factor : ndarray, 1d\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      "     |  \n",
      "     |  information(self, params, scale=None)\n",
      "     |      Fisher information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize a generalized linear model.\n",
      "     |  \n",
      "     |  loglike(self, params, scale=None)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  loglike_mu(self, mu, scale=1.0)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, linear=False)\n",
      "     |      Return predicted values for a design matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters / coefficients of a GLM.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Is exog is None, model exog is used.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Exposure time values, only can be used with the log link\n",
      "     |          function.  See notes for details.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset values.  See notes for details.\n",
      "     |      linear : bool\n",
      "     |          If True, returns the linear predicted values.  If False,\n",
      "     |          returns the value of the inverse of the model's link function at\n",
      "     |          the linear predicted values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Any `exposure` and `offset` provided here take precedence over\n",
      "     |      the `exposure` and `offset` used in the model fit.  If `exog`\n",
      "     |      is passed as an argument here, then any `exposure` and\n",
      "     |      `offset` values in the fit will be ignored.\n",
      "     |      \n",
      "     |      Exposure values must be strictly positive.\n",
      "     |  \n",
      "     |  score(self, params, scale=None)\n",
      "     |      score, first derivative of the loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray_1d\n",
      "     |          The first derivative of the loglikelihood function calculated as\n",
      "     |          the sum of `score_obs`\n",
      "     |  \n",
      "     |  score_factor(self, params, scale=None)\n",
      "     |      weights for score for each observation\n",
      "     |      \n",
      "     |      This can be considered as score residuals.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which score is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_factor : ndarray_1d\n",
      "     |          A 1d weight vector used in the calculation of the score_obs.\n",
      "     |          The score_obs are obtained by `score_factor[:, None] * exog`\n",
      "     |  \n",
      "     |  score_obs(self, params, scale=None)\n",
      "     |      score first derivative of the loglikelihood for each observation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_obs : ndarray, 2d\n",
      "     |          The first derivative of the loglikelihood function evaluated at\n",
      "     |          params for each observation.\n",
      "     |  \n",
      "     |  score_test(self, params_constrained, k_constraints=None, exog_extra=None, observed=True)\n",
      "     |      score test for restrictions or for omitted variables\n",
      "     |      \n",
      "     |      The covariance matrix for the score is based on the Hessian, i.e.\n",
      "     |      observed information matrix or optionally on the expected information\n",
      "     |      matrix..\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params_constrained : array_like\n",
      "     |          estimated parameter of the restricted model. This can be the\n",
      "     |          parameter estimate for the current when testing for omitted\n",
      "     |          variables.\n",
      "     |      k_constraints : int or None\n",
      "     |          Number of constraints that were used in the estimation of params\n",
      "     |          restricted relative to the number of exog in the model.\n",
      "     |          This must be provided if no exog_extra are given. If exog_extra is\n",
      "     |          not None, then k_constraints is assumed to be zero if it is None.\n",
      "     |      exog_extra : None or array_like\n",
      "     |          Explanatory variables that are jointly tested for inclusion in the\n",
      "     |          model, i.e. omitted variables.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is used in calculating the\n",
      "     |          covariance matrix of the score. If false then the expected\n",
      "     |          information matrix is used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chi2_stat : float\n",
      "     |          chisquare statistic for the score test\n",
      "     |      p-value : float\n",
      "     |          P-value of the score test based on the chisquare distribution.\n",
      "     |      df : int\n",
      "     |          Degrees of freedom used in the p-value calculation. This is equal\n",
      "     |          to the number of constraints.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      not yet verified for case with scale not equal to 1.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GLM(statsmodels.base.model.LikelihoodModel)\n",
      "     |  GLM(endog, exog, family=None, offset=None, exposure=None, freq_weights=None, var_weights=None, missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Generalized Linear Models\n",
      "     |  \n",
      "     |  GLM inherits from statsmodels.base.model.LikelihoodModel\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      1d array of endogenous response variable.  This array can be 1d or 2d.\n",
      "     |      Binomial family models accept a 2d array with two columns. If\n",
      "     |      supplied, each observation is expected to be [success, failure].\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user (models specified using a formula\n",
      "     |      include an intercept by default). See `statsmodels.tools.add_constant`.\n",
      "     |  family : family class instance\n",
      "     |      The default is Gaussian.  To specify the binomial distribution\n",
      "     |      family = sm.family.Binomial()\n",
      "     |      Each family can take a link instance as an argument.  See\n",
      "     |      statsmodels.family.family for more information.\n",
      "     |  offset : array_like or None\n",
      "     |      An offset to be included in the model.  If provided, must be\n",
      "     |      an array whose length is the number of rows in exog.\n",
      "     |  exposure : array_like or None\n",
      "     |      Log(exposure) will be added to the linear prediction in the model.\n",
      "     |      Exposure is only valid if the log link is used. If provided, it must be\n",
      "     |      an array with the same length as endog.\n",
      "     |  freq_weights : array_like\n",
      "     |      1d array of frequency weights. The default is None. If None is selected\n",
      "     |      or a blank value, then the algorithm will replace with an array of 1's\n",
      "     |      with length equal to the endog.\n",
      "     |      WARNING: Using weights is not verified yet for all possible options\n",
      "     |      and results, see Notes.\n",
      "     |  var_weights : array_like\n",
      "     |      1d array of variance (analytic) weights. The default is None. If None\n",
      "     |      is selected or a blank value, then the algorithm will replace with an\n",
      "     |      array of 1's with length equal to the endog.\n",
      "     |      WARNING: Using weights is not verified yet for all possible options\n",
      "     |      and results, see Notes.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  df_model : float\n",
      "     |      Model degrees of freedom is equal to p - 1, where p is the number\n",
      "     |      of regressors.  Note that the intercept is not reported as a\n",
      "     |      degree of freedom.\n",
      "     |  df_resid : float\n",
      "     |      Residual degrees of freedom is equal to the number of observation n\n",
      "     |      minus the number of regressors p.\n",
      "     |  endog : ndarray\n",
      "     |      See Notes.  Note that `endog` is a reference to the data so that if\n",
      "     |      data is already an array and it is changed, then `endog` changes\n",
      "     |      as well.\n",
      "     |  exposure : array_like\n",
      "     |      Include ln(exposure) in model with coefficient constrained to 1. Can\n",
      "     |      only be used if the link is the logarithm function.\n",
      "     |  exog : ndarray\n",
      "     |      See Notes.  Note that `exog` is a reference to the data so that if\n",
      "     |      data is already an array and it is changed, then `exog` changes\n",
      "     |      as well.\n",
      "     |  freq_weights : ndarray\n",
      "     |      See Notes. Note that `freq_weights` is a reference to the data so that\n",
      "     |      if data is already an array and it is changed, then `freq_weights`\n",
      "     |      changes as well.\n",
      "     |  var_weights : ndarray\n",
      "     |      See Notes. Note that `var_weights` is a reference to the data so that\n",
      "     |      if data is already an array and it is changed, then `var_weights`\n",
      "     |      changes as well.\n",
      "     |  iteration : int\n",
      "     |      The number of iterations that fit has run.  Initialized at 0.\n",
      "     |  family : family class instance\n",
      "     |      The distribution family of the model. Can be any family in\n",
      "     |      statsmodels.families.  Default is Gaussian.\n",
      "     |  mu : ndarray\n",
      "     |      The mean response of the transformed variable.  `mu` is the value of\n",
      "     |      the inverse of the link function at lin_pred, where lin_pred is the\n",
      "     |      linear predicted value of the WLS fit of the transformed variable.\n",
      "     |      `mu` is only available after fit is called.  See\n",
      "     |      statsmodels.families.family.fitted of the distribution family for more\n",
      "     |      information.\n",
      "     |  n_trials : ndarray\n",
      "     |      See Notes. Note that `n_trials` is a reference to the data so that if\n",
      "     |      data is already an array and it is changed, then `n_trials` changes\n",
      "     |      as well. `n_trials` is the number of binomial trials and only available\n",
      "     |      with that distribution. See statsmodels.families.Binomial for more\n",
      "     |      information.\n",
      "     |  normalized_cov_params : ndarray\n",
      "     |      The p x p normalized covariance of the design / exogenous data.\n",
      "     |      This is approximately equal to (X.T X)^(-1)\n",
      "     |  offset : array_like\n",
      "     |      Include offset in model with coefficient constrained to 1.\n",
      "     |  scale : float\n",
      "     |      The estimate of the scale / dispersion of the model fit.  Only\n",
      "     |      available after fit is called.  See GLM.fit and GLM.estimate_scale\n",
      "     |      for more information.\n",
      "     |  scaletype : str\n",
      "     |      The scaling used for fitting the model.  This is only available after\n",
      "     |      fit is called.  The default is None.  See GLM.fit for more information.\n",
      "     |  weights : ndarray\n",
      "     |      The value of the weights after the last iteration of fit.  Only\n",
      "     |      available after fit is called.  See statsmodels.families.family for\n",
      "     |      the specific distribution weighting functions.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> data = sm.datasets.scotland.load()\n",
      "     |  >>> data.exog = sm.add_constant(data.exog)\n",
      "     |  \n",
      "     |  Instantiate a gamma family model with the default link function.\n",
      "     |  \n",
      "     |  >>> gamma_model = sm.GLM(data.endog, data.exog,\n",
      "     |  ...                      family=sm.families.Gamma())\n",
      "     |  \n",
      "     |  >>> gamma_results = gamma_model.fit()\n",
      "     |  >>> gamma_results.params\n",
      "     |  array([-0.01776527,  0.00004962,  0.00203442, -0.00007181,  0.00011185,\n",
      "     |         -0.00000015, -0.00051868, -0.00000243])\n",
      "     |  >>> gamma_results.scale\n",
      "     |  0.0035842831734919055\n",
      "     |  >>> gamma_results.deviance\n",
      "     |  0.087388516416999198\n",
      "     |  >>> gamma_results.pearson_chi2\n",
      "     |  0.086022796163805704\n",
      "     |  >>> gamma_results.llf\n",
      "     |  -83.017202161073527\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.genmod.families.family.Family\n",
      "     |  :ref:`families`\n",
      "     |  :ref:`links`\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Only the following combinations make sense for family and link:\n",
      "     |  \n",
      "     |   ============= ===== === ===== ====== ======= === ==== ====== ====== ====\n",
      "     |   Family        ident log logit probit cloglog pow opow nbinom loglog logc\n",
      "     |   ============= ===== === ===== ====== ======= === ==== ====== ====== ====\n",
      "     |   Gaussian      x     x   x     x      x       x   x     x      x\n",
      "     |   inv Gaussian  x     x                        x\n",
      "     |   binomial      x     x   x     x      x       x   x           x      x\n",
      "     |   Poisson       x     x                        x\n",
      "     |   neg binomial  x     x                        x        x\n",
      "     |   gamma         x     x                        x\n",
      "     |   Tweedie       x     x                        x\n",
      "     |   ============= ===== === ===== ====== ======= === ==== ====== ====== ====\n",
      "     |  \n",
      "     |  Not all of these link functions are currently available.\n",
      "     |  \n",
      "     |  Endog and exog are references so that if the data they refer to are already\n",
      "     |  arrays and these arrays are changed, endog and exog will change.\n",
      "     |  \n",
      "     |  statsmodels supports two separate definitions of weights: frequency weights\n",
      "     |  and variance weights.\n",
      "     |  \n",
      "     |  Frequency weights produce the same results as repeating observations by the\n",
      "     |  frequencies (if those are integers). Frequency weights will keep the number\n",
      "     |  of observations consistent, but the degrees of freedom will change to\n",
      "     |  reflect the new weights.\n",
      "     |  \n",
      "     |  Variance weights (referred to in other packages as analytic weights) are\n",
      "     |  used when ``endog`` represents an an average or mean. This relies on the\n",
      "     |  assumption that that the inverse variance scales proportionally to the\n",
      "     |  weight--an observation that is deemed more credible should have less\n",
      "     |  variance and therefore have more weight. For the ``Poisson`` family--which\n",
      "     |  assumes that occurrences scale proportionally with time--a natural practice\n",
      "     |  would be to use the amount of time as the variance weight and set ``endog``\n",
      "     |  to be a rate (occurrences per period of time). Similarly, using a\n",
      "     |  compound Poisson family, namely ``Tweedie``, makes a similar assumption\n",
      "     |  about the rate (or frequency) of occurrences having variance proportional to\n",
      "     |  time.\n",
      "     |  \n",
      "     |  Both frequency and variance weights are verified for all basic results with\n",
      "     |  nonrobust or heteroscedasticity robust ``cov_type``. Other robust\n",
      "     |  covariance types have not yet been verified, and at least the small sample\n",
      "     |  correction is currently not based on the correct total frequency count.\n",
      "     |  \n",
      "     |  Currently, all residuals are not weighted by frequency, although they may\n",
      "     |  incorporate ``n_trials`` for ``Binomial`` and ``var_weights``\n",
      "     |  \n",
      "     |  +---------------+----------------------------------+\n",
      "     |  | Residual Type | Applicable weights               |\n",
      "     |  +===============+==================================+\n",
      "     |  | Anscombe      | ``var_weights``                  |\n",
      "     |  +---------------+----------------------------------+\n",
      "     |  | Deviance      | ``var_weights``                  |\n",
      "     |  +---------------+----------------------------------+\n",
      "     |  | Pearson       | ``var_weights`` and ``n_trials`` |\n",
      "     |  +---------------+----------------------------------+\n",
      "     |  | Reponse       | ``n_trials``                     |\n",
      "     |  +---------------+----------------------------------+\n",
      "     |  | Working       | ``n_trials``                     |\n",
      "     |  +---------------+----------------------------------+\n",
      "     |  \n",
      "     |  WARNING: Loglikelihood and deviance are not valid in models where\n",
      "     |  scale is equal to 1 (i.e., ``Binomial``, ``NegativeBinomial``, and\n",
      "     |  ``Poisson``). If variance weights are specified, then results such as\n",
      "     |  ``loglike`` and ``deviance`` are based on a quasi-likelihood\n",
      "     |  interpretation. The loglikelihood is not correctly specified in this case,\n",
      "     |  and statistics based on it, such AIC or likelihood ratio tests, are not\n",
      "     |  appropriate.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, family=None, offset=None, exposure=None, freq_weights=None, var_weights=None, missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  estimate_scale(self, mu)\n",
      "     |      Estimate the dispersion/scale.\n",
      "     |      \n",
      "     |      Type of scale can be chose in the fit method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : ndarray\n",
      "     |          mu is the mean response estimate\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Estimate of scale\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The default scale for Binomial, Poisson and Negative Binomial\n",
      "     |      families is 1.  The default for the other families is Pearson's\n",
      "     |      Chi-Square estimate.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.genmod.generalized_linear_model.GLM.fit\n",
      "     |  \n",
      "     |  estimate_tweedie_power(self, mu, method='brentq', low=1.01, high=5.0)\n",
      "     |      Tweedie specific function to estimate scale and the variance parameter.\n",
      "     |      The variance parameter is also referred to as p, xi, or shape.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : array_like\n",
      "     |          Fitted mean response variable\n",
      "     |      method : str, defaults to 'brentq'\n",
      "     |          Scipy optimizer used to solve the Pearson equation. Only brentq\n",
      "     |          currently supported.\n",
      "     |      low : float, optional\n",
      "     |          Low end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 1.01.\n",
      "     |      high : float, optional\n",
      "     |          High end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 5.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      power : float\n",
      "     |          The estimated shape or power.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, maxiter=100, method='IRLS', tol=1e-08, scale=None, cov_type='nonrobust', cov_kwds=None, use_t=None, full_output=True, disp=False, max_start_irls=3, **kwargs)\n",
      "     |      Fits a generalized linear model for a given family.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is family-specific and is given by the\n",
      "     |          ``family.starting_mu(endog)``. If start_params is given then the\n",
      "     |          initial mean will be calculated as ``np.dot(exog, start_params)``.\n",
      "     |      maxiter : int, optional\n",
      "     |          Default is 100.\n",
      "     |      method : str\n",
      "     |          Default is 'IRLS' for iteratively reweighted least squares.\n",
      "     |          Otherwise gradient optimization is used.\n",
      "     |      tol : float\n",
      "     |          Convergence tolerance.  Default is 1e-8.\n",
      "     |      scale : str or float, optional\n",
      "     |          `scale` can be 'X2', 'dev', or a float\n",
      "     |          The default value is None, which uses `X2` for Gamma, Gaussian,\n",
      "     |          and Inverse Gaussian.\n",
      "     |          `X2` is Pearson's chi-square divided by `df_resid`.\n",
      "     |          The default is 1 for the Binomial and Poisson families.\n",
      "     |          `dev` is the deviance divided by df_resid\n",
      "     |      cov_type : str\n",
      "     |          The type of parameter estimate covariance matrix to compute.\n",
      "     |      cov_kwds : dict-like\n",
      "     |          Extra arguments for calculating the covariance of the parameter\n",
      "     |          estimates.\n",
      "     |      use_t : bool\n",
      "     |          If True, the Student t-distribution is used for inference.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |          Not used if methhod is IRLS.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.  Not used if method is\n",
      "     |          IRLS.\n",
      "     |      max_start_irls : int\n",
      "     |          The number of IRLS iterations used to obtain starting\n",
      "     |          values for gradient optimization.  Only relevant if\n",
      "     |          `method` is set to something other than 'IRLS'.\n",
      "     |      atol : float, optional\n",
      "     |          (available with IRLS fits) The absolute tolerance criterion that\n",
      "     |          must be satisfied. Defaults to ``tol``. Convergence is attained\n",
      "     |          when: :math:`rtol * prior + atol > abs(current - prior)`\n",
      "     |      rtol : float, optional\n",
      "     |          (available with IRLS fits) The relative tolerance criterion that\n",
      "     |          must be satisfied. Defaults to 0 which means ``rtol`` is not used.\n",
      "     |          Convergence is attained when:\n",
      "     |          :math:`rtol * prior + atol > abs(current - prior)`\n",
      "     |      tol_criterion : str, optional\n",
      "     |          (available with IRLS fits) Defaults to ``'deviance'``. Can\n",
      "     |          optionally be ``'params'``.\n",
      "     |      wls_method : str, optional\n",
      "     |          (available with IRLS fits) options are 'lstsq', 'pinv' and 'qr'\n",
      "     |          specifies which linear algebra function to use for the irls\n",
      "     |          optimization. Default is `lstsq` which uses the same underlying\n",
      "     |          svd based approach as 'pinv', but is faster during iterations.\n",
      "     |          'lstsq' and 'pinv' regularize the estimate in singular and\n",
      "     |          near-singular cases by truncating small singular values based\n",
      "     |          on `rcond` of the respective numpy.linalg function. 'qr' is\n",
      "     |          only valid for cases that are not singular nor near-singular.\n",
      "     |      optim_hessian : {'eim', 'oim'}, optional\n",
      "     |          (available with scipy optimizer fits) When 'oim'--the default--the\n",
      "     |          observed Hessian is used in fitting. 'eim' is the expected Hessian.\n",
      "     |          This may provide more stable fits, but adds assumption that the\n",
      "     |          Hessian is correctly specified.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If method is 'IRLS', then an additional keyword 'attach_wls' is\n",
      "     |      available. This is currently for internal use only and might change\n",
      "     |      in future versions. If attach_wls' is true, then the final WLS\n",
      "     |      instance of the IRLS iteration is attached to the results instance\n",
      "     |      as `results_wls` attribute.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      fit the model subject to linear equality constraints\n",
      "     |      \n",
      "     |      The constraints are of the form   `R params = q`\n",
      "     |      where R is the constraint_matrix and q is the vector of\n",
      "     |      constraint_values.\n",
      "     |      \n",
      "     |      The estimation creates a new model with transformed design matrix,\n",
      "     |      exog, and converts the results back to the original parameterization.\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : formula expression or tuple\n",
      "     |          If it is a tuple, then the constraint needs to be given by two\n",
      "     |          arrays (constraint_matrix, constraint_value), i.e. (R, q).\n",
      "     |          Otherwise, the constraints can be given as strings or list of\n",
      "     |          strings.\n",
      "     |          see t_test for details\n",
      "     |      start_params : None or array_like\n",
      "     |          starting values for the optimization. `start_params` needs to be\n",
      "     |          given in the original parameter space and are internally\n",
      "     |          transformed.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the transformed model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |  \n",
      "     |  fit_regularized(self, method='elastic_net', alpha=0.0, start_params=None, refit=False, opt_method='bfgs', **kwargs)\n",
      "     |      Return a regularized fit to a linear regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'elastic_net'}\n",
      "     |          Only the `elastic_net` approach is currently implemented.\n",
      "     |      alpha : scalar or array_like\n",
      "     |          The penalty weight.  If a scalar, the same penalty weight\n",
      "     |          applies to all variables in the model.  If a vector, it\n",
      "     |          must have the same length as `params`, and contains a\n",
      "     |          penalty weight for each coefficient.\n",
      "     |      start_params : array_like\n",
      "     |          Starting values for `params`.\n",
      "     |      refit : bool\n",
      "     |          If True, the model is refit using only the variables that\n",
      "     |          have non-zero coefficients in the regularized fit.  The\n",
      "     |          refitted model is not regularized.\n",
      "     |      opt_method : string\n",
      "     |          The method used for numerical optimization.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GLMResults\n",
      "     |          An array or a GLMResults object, same type returned by `fit`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The penalty is the ``elastic net`` penalty, which is a\n",
      "     |      combination of L1 and L2 penalties.\n",
      "     |      \n",
      "     |      The function that is minimized is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          -loglike/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      "     |      \n",
      "     |      where :math:`|*|_1` and :math:`|*|_2` are the L1 and L2 norms.\n",
      "     |      \n",
      "     |      Post-estimation results are based on the same data used to\n",
      "     |      select variables, hence may be subject to overfitting biases.\n",
      "     |      \n",
      "     |      The elastic_net method uses the following keyword arguments:\n",
      "     |      \n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations\n",
      "     |      L1_wt  : float\n",
      "     |          Must be in [0, 1].  The L1 penalty has weight L1_wt and the\n",
      "     |          L2 penalty has weight 1 - L1_wt.\n",
      "     |      cnvrg_tol : float\n",
      "     |          Convergence threshold for maximum parameter change after\n",
      "     |          one sweep through all coefficients.\n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale=None, exog=None, exposure=None, offset=None, var_weights=1.0, n_trials=1.0)\n",
      "     |      Return a instance of the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters.\n",
      "     |      scale : scalar\n",
      "     |          The scale parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      offset : array_like or None\n",
      "     |          Offset variable for predicted mean.\n",
      "     |      exposure : array_like or None\n",
      "     |          Log(exposure) will be added to the linear prediction.\n",
      "     |      var_weights : array_like\n",
      "     |          1d array of variance (analytic) weights. The default is None.\n",
      "     |      n_trials : int\n",
      "     |          Number of trials for the binomial distribution. The default is 1\n",
      "     |          which corresponds to a Bernoulli random variable.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Instance of a scipy frozen distribution based on estimated\n",
      "     |          parameters.\n",
      "     |          Use the ``rvs`` method to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``, the\n",
      "     |      returned random number generator must be called with ``gen.rvs(n)``\n",
      "     |      where ``n`` is the number of observations in the data set used\n",
      "     |      to fit the model.  If any other value is used for ``n``, misleading\n",
      "     |      results will be produced.\n",
      "     |  \n",
      "     |  hessian(self, params, scale=None, observed=None)\n",
      "     |      Hessian, second derivative of loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned (default).\n",
      "     |          If False, then the expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian, i.e. observed information, or expected information matrix.\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Weights for calculating Hessian\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian_factor : ndarray, 1d\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      "     |  \n",
      "     |  information(self, params, scale=None)\n",
      "     |      Fisher information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize a generalized linear model.\n",
      "     |  \n",
      "     |  loglike(self, params, scale=None)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  loglike_mu(self, mu, scale=1.0)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, linear=False)\n",
      "     |      Return predicted values for a design matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters / coefficients of a GLM.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Is exog is None, model exog is used.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Exposure time values, only can be used with the log link\n",
      "     |          function.  See notes for details.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset values.  See notes for details.\n",
      "     |      linear : bool\n",
      "     |          If True, returns the linear predicted values.  If False,\n",
      "     |          returns the value of the inverse of the model's link function at\n",
      "     |          the linear predicted values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Any `exposure` and `offset` provided here take precedence over\n",
      "     |      the `exposure` and `offset` used in the model fit.  If `exog`\n",
      "     |      is passed as an argument here, then any `exposure` and\n",
      "     |      `offset` values in the fit will be ignored.\n",
      "     |      \n",
      "     |      Exposure values must be strictly positive.\n",
      "     |  \n",
      "     |  score(self, params, scale=None)\n",
      "     |      score, first derivative of the loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray_1d\n",
      "     |          The first derivative of the loglikelihood function calculated as\n",
      "     |          the sum of `score_obs`\n",
      "     |  \n",
      "     |  score_factor(self, params, scale=None)\n",
      "     |      weights for score for each observation\n",
      "     |      \n",
      "     |      This can be considered as score residuals.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which score is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_factor : ndarray_1d\n",
      "     |          A 1d weight vector used in the calculation of the score_obs.\n",
      "     |          The score_obs are obtained by `score_factor[:, None] * exog`\n",
      "     |  \n",
      "     |  score_obs(self, params, scale=None)\n",
      "     |      score first derivative of the loglikelihood for each observation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_obs : ndarray, 2d\n",
      "     |          The first derivative of the loglikelihood function evaluated at\n",
      "     |          params for each observation.\n",
      "     |  \n",
      "     |  score_test(self, params_constrained, k_constraints=None, exog_extra=None, observed=True)\n",
      "     |      score test for restrictions or for omitted variables\n",
      "     |      \n",
      "     |      The covariance matrix for the score is based on the Hessian, i.e.\n",
      "     |      observed information matrix or optionally on the expected information\n",
      "     |      matrix..\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params_constrained : array_like\n",
      "     |          estimated parameter of the restricted model. This can be the\n",
      "     |          parameter estimate for the current when testing for omitted\n",
      "     |          variables.\n",
      "     |      k_constraints : int or None\n",
      "     |          Number of constraints that were used in the estimation of params\n",
      "     |          restricted relative to the number of exog in the model.\n",
      "     |          This must be provided if no exog_extra are given. If exog_extra is\n",
      "     |          not None, then k_constraints is assumed to be zero if it is None.\n",
      "     |      exog_extra : None or array_like\n",
      "     |          Explanatory variables that are jointly tested for inclusion in the\n",
      "     |          model, i.e. omitted variables.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is used in calculating the\n",
      "     |          covariance matrix of the score. If false then the expected\n",
      "     |          information matrix is used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chi2_stat : float\n",
      "     |          chisquare statistic for the score test\n",
      "     |      p-value : float\n",
      "     |          P-value of the score test based on the chisquare distribution.\n",
      "     |      df : int\n",
      "     |          Degrees of freedom used in the p-value calculation. This is equal\n",
      "     |          to the number of constraints.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      not yet verified for case with scale not equal to 1.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GLMGam(statsmodels.base._penalized.PenalizedMixin, statsmodels.genmod.generalized_linear_model.GLM)\n",
      "     |  GLMGam(endog, exog=None, smoother=None, alpha=0, family=None, offset=None, exposure=None, missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Generalized Additive Models (GAM)\n",
      "     |  \n",
      "     |  This inherits from `GLM`.\n",
      "     |  \n",
      "     |  Warning: Not all inherited methods might take correctly account of the\n",
      "     |  penalization. Not all options including offset and exposure have been\n",
      "     |  verified yet.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The response variable.\n",
      "     |  exog : array_like or None\n",
      "     |      This explanatory variables are treated as linear. The model in this\n",
      "     |      case is a partial linear model.\n",
      "     |  smoother : instance of additive smoother class\n",
      "     |      Examples of smoother instances include Bsplines or CyclicCubicSplines.\n",
      "     |  alpha : float or list of floats\n",
      "     |      Penalization weights for smooth terms. The length of the list needs\n",
      "     |      to be the same as the number of smooth terms in the ``smoother``.\n",
      "     |  family : instance of GLM family\n",
      "     |      See GLM.\n",
      "     |  offset : None or array_like\n",
      "     |      See GLM.\n",
      "     |  exposure : None or array_like\n",
      "     |      See GLM.\n",
      "     |  missing : 'none'\n",
      "     |      Missing value handling is not supported in this class.\n",
      "     |  **kwargs\n",
      "     |      Extra keywords are used in call to the super classes.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Status: experimental. This has full unit test coverage for the core\n",
      "     |  results with Gaussian and Poisson (without offset and exposure). Other\n",
      "     |  options and additional results might not be correctly supported yet.\n",
      "     |  (Binomial with counts, i.e. with n_trials, is most likely wrong in pirls.\n",
      "     |  User specified var or freq weights are most likely also not correct for\n",
      "     |  all results.)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GLMGam\n",
      "     |      statsmodels.base._penalized.PenalizedMixin\n",
      "     |      statsmodels.genmod.generalized_linear_model.GLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, smoother=None, alpha=0, family=None, offset=None, exposure=None, missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, maxiter=1000, method='pirls', tol=1e-08, scale=None, cov_type='nonrobust', cov_kwds=None, use_t=None, full_output=True, disp=False, max_start_irls=3, **kwargs)\n",
      "     |      estimate parameters and create instance of GLMGamResults class\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      most parameters are the same as for GLM\n",
      "     |      method : optimization method\n",
      "     |          The special optimization method is \"pirls\" which uses a penalized\n",
      "     |          version of IRLS. Other methods are gradient optimizers as used in\n",
      "     |          base.model.LikelihoodModel.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : instance of wrapped GLMGamResults\n",
      "     |  \n",
      "     |  select_penweight(self, criterion='aic', start_params=None, start_model_params=None, method='basinhopping', **fit_kwds)\n",
      "     |      find alpha by minimizing results criterion\n",
      "     |      \n",
      "     |      The objective for the minimization can be results attributes like\n",
      "     |      ``gcv``, ``aic`` or ``bic`` where the latter are based on effective\n",
      "     |      degrees of freedom.\n",
      "     |      \n",
      "     |      Warning: In many case the optimization might converge to a local\n",
      "     |      optimum or near optimum. Different start_params or using a global\n",
      "     |      optimizer is recommended, default is basinhopping.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      criterion='aic'\n",
      "     |          name of results attribute to be minimized.\n",
      "     |          Default is 'aic', other options are 'gcv', 'cv' or 'bic'.\n",
      "     |      start_params : None or array\n",
      "     |          starting parameters for alpha in the penalization weight\n",
      "     |          minimization. The parameters are internally exponentiated and\n",
      "     |          the minimization is with respect to ``exp(alpha)``\n",
      "     |      start_model_params : None or array\n",
      "     |          starting parameter for the ``model._fit_pirls``.\n",
      "     |      method : 'basinhopping', 'nm' or 'minimize'\n",
      "     |          'basinhopping' and 'nm' directly use the underlying scipy.optimize\n",
      "     |          functions `basinhopping` and `fmin`. 'minimize' provides access\n",
      "     |          to the high level interface, `scipy.optimize.minimize`.\n",
      "     |      fit_kwds : keyword arguments\n",
      "     |          additional keyword arguments will be used in the call to the\n",
      "     |          scipy optimizer. Which keywords are supported depends on the\n",
      "     |          scipy optimization function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alpha : ndarray\n",
      "     |          penalization parameter found by minimizing the criterion.\n",
      "     |          Note that this can be only a local (near) optimum.\n",
      "     |      fit_res : tuple\n",
      "     |          results returned by the scipy optimization routine. The\n",
      "     |          parameters in the optimization problem are `log(alpha)`\n",
      "     |      history : dict\n",
      "     |          history of calls to pirls and contains alpha, the fit\n",
      "     |          criterion and the parameters to which pirls converged to for the\n",
      "     |          given alpha.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      In the test cases Nelder-Mead and bfgs often converge to local optima,\n",
      "     |      see also https://github.com/statsmodels/statsmodels/issues/5381.\n",
      "     |      \n",
      "     |      This does not use any analytical derivatives for the criterion\n",
      "     |      minimization.\n",
      "     |      \n",
      "     |      Status: experimental, It is possible that defaults change if there\n",
      "     |      is a better way to find a global optimum. API (e.g. type of return)\n",
      "     |      might also change.\n",
      "     |  \n",
      "     |  select_penweight_kfold(self, alphas=None, cv_iterator=None, cost=None, k_folds=5, k_grid=11)\n",
      "     |      find alphas by k-fold cross-validation\n",
      "     |      \n",
      "     |      Warning: This estimates ``k_folds`` models for each point in the\n",
      "     |          grid of alphas.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alphas : None or list of arrays\n",
      "     |      cv_iterator : instance\n",
      "     |          instance of a cross-validation iterator, by default this is a\n",
      "     |          KFold instance\n",
      "     |      cost : function\n",
      "     |          default is mean squared error. The cost function to evaluate the\n",
      "     |          prediction error for the left out sample. This should take two\n",
      "     |          arrays as argument and return one float.\n",
      "     |      k_folds : int\n",
      "     |          number of folds if default Kfold iterator is used.\n",
      "     |          This is ignored if ``cv_iterator`` is not None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alpha_cv : list of float\n",
      "     |          Best alpha in grid according to cross-validation\n",
      "     |      res_cv : instance of MultivariateGAMCVPath\n",
      "     |          The instance was used for cross-validation and holds the results\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The default alphas are defined as\n",
      "     |      ``alphas = [np.logspace(0, 7, k_grid) for _ in range(k_smooths)]``\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base._penalized.PenalizedMixin:\n",
      "     |  \n",
      "     |  hessian(self, params, pen_weight=None, **kwds)\n",
      "     |      Hessian of model at params\n",
      "     |  \n",
      "     |  hessian_numdiff(self, params, pen_weight=None, **kwds)\n",
      "     |      hessian based on finite difference derivative\n",
      "     |  \n",
      "     |  loglike(self, params, pen_weight=None, **kwds)\n",
      "     |      Log-likelihood of model at params\n",
      "     |  \n",
      "     |  loglikeobs(self, params, pen_weight=None, **kwds)\n",
      "     |      Log-likelihood of model observations at params\n",
      "     |  \n",
      "     |  score(self, params, pen_weight=None, **kwds)\n",
      "     |      Gradient of model at params\n",
      "     |  \n",
      "     |  score_numdiff(self, params, pen_weight=None, method='fd', **kwds)\n",
      "     |      score based on finite difference derivative\n",
      "     |  \n",
      "     |  score_obs(self, params, pen_weight=None, **kwds)\n",
      "     |      Gradient of model observations at params\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base._penalized.PenalizedMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.genmod.generalized_linear_model.GLM:\n",
      "     |  \n",
      "     |  estimate_scale(self, mu)\n",
      "     |      Estimate the dispersion/scale.\n",
      "     |      \n",
      "     |      Type of scale can be chose in the fit method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : ndarray\n",
      "     |          mu is the mean response estimate\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Estimate of scale\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The default scale for Binomial, Poisson and Negative Binomial\n",
      "     |      families is 1.  The default for the other families is Pearson's\n",
      "     |      Chi-Square estimate.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.genmod.generalized_linear_model.GLM.fit\n",
      "     |  \n",
      "     |  estimate_tweedie_power(self, mu, method='brentq', low=1.01, high=5.0)\n",
      "     |      Tweedie specific function to estimate scale and the variance parameter.\n",
      "     |      The variance parameter is also referred to as p, xi, or shape.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : array_like\n",
      "     |          Fitted mean response variable\n",
      "     |      method : str, defaults to 'brentq'\n",
      "     |          Scipy optimizer used to solve the Pearson equation. Only brentq\n",
      "     |          currently supported.\n",
      "     |      low : float, optional\n",
      "     |          Low end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 1.01.\n",
      "     |      high : float, optional\n",
      "     |          High end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 5.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      power : float\n",
      "     |          The estimated shape or power.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      fit the model subject to linear equality constraints\n",
      "     |      \n",
      "     |      The constraints are of the form   `R params = q`\n",
      "     |      where R is the constraint_matrix and q is the vector of\n",
      "     |      constraint_values.\n",
      "     |      \n",
      "     |      The estimation creates a new model with transformed design matrix,\n",
      "     |      exog, and converts the results back to the original parameterization.\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : formula expression or tuple\n",
      "     |          If it is a tuple, then the constraint needs to be given by two\n",
      "     |          arrays (constraint_matrix, constraint_value), i.e. (R, q).\n",
      "     |          Otherwise, the constraints can be given as strings or list of\n",
      "     |          strings.\n",
      "     |          see t_test for details\n",
      "     |      start_params : None or array_like\n",
      "     |          starting values for the optimization. `start_params` needs to be\n",
      "     |          given in the original parameter space and are internally\n",
      "     |          transformed.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the transformed model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |  \n",
      "     |  fit_regularized(self, method='elastic_net', alpha=0.0, start_params=None, refit=False, opt_method='bfgs', **kwargs)\n",
      "     |      Return a regularized fit to a linear regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'elastic_net'}\n",
      "     |          Only the `elastic_net` approach is currently implemented.\n",
      "     |      alpha : scalar or array_like\n",
      "     |          The penalty weight.  If a scalar, the same penalty weight\n",
      "     |          applies to all variables in the model.  If a vector, it\n",
      "     |          must have the same length as `params`, and contains a\n",
      "     |          penalty weight for each coefficient.\n",
      "     |      start_params : array_like\n",
      "     |          Starting values for `params`.\n",
      "     |      refit : bool\n",
      "     |          If True, the model is refit using only the variables that\n",
      "     |          have non-zero coefficients in the regularized fit.  The\n",
      "     |          refitted model is not regularized.\n",
      "     |      opt_method : string\n",
      "     |          The method used for numerical optimization.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GLMResults\n",
      "     |          An array or a GLMResults object, same type returned by `fit`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The penalty is the ``elastic net`` penalty, which is a\n",
      "     |      combination of L1 and L2 penalties.\n",
      "     |      \n",
      "     |      The function that is minimized is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          -loglike/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      "     |      \n",
      "     |      where :math:`|*|_1` and :math:`|*|_2` are the L1 and L2 norms.\n",
      "     |      \n",
      "     |      Post-estimation results are based on the same data used to\n",
      "     |      select variables, hence may be subject to overfitting biases.\n",
      "     |      \n",
      "     |      The elastic_net method uses the following keyword arguments:\n",
      "     |      \n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations\n",
      "     |      L1_wt  : float\n",
      "     |          Must be in [0, 1].  The L1 penalty has weight L1_wt and the\n",
      "     |          L2 penalty has weight 1 - L1_wt.\n",
      "     |      cnvrg_tol : float\n",
      "     |          Convergence threshold for maximum parameter change after\n",
      "     |          one sweep through all coefficients.\n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale=None, exog=None, exposure=None, offset=None, var_weights=1.0, n_trials=1.0)\n",
      "     |      Return a instance of the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters.\n",
      "     |      scale : scalar\n",
      "     |          The scale parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      offset : array_like or None\n",
      "     |          Offset variable for predicted mean.\n",
      "     |      exposure : array_like or None\n",
      "     |          Log(exposure) will be added to the linear prediction.\n",
      "     |      var_weights : array_like\n",
      "     |          1d array of variance (analytic) weights. The default is None.\n",
      "     |      n_trials : int\n",
      "     |          Number of trials for the binomial distribution. The default is 1\n",
      "     |          which corresponds to a Bernoulli random variable.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Instance of a scipy frozen distribution based on estimated\n",
      "     |          parameters.\n",
      "     |          Use the ``rvs`` method to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``, the\n",
      "     |      returned random number generator must be called with ``gen.rvs(n)``\n",
      "     |      where ``n`` is the number of observations in the data set used\n",
      "     |      to fit the model.  If any other value is used for ``n``, misleading\n",
      "     |      results will be produced.\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Weights for calculating Hessian\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian_factor : ndarray, 1d\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      "     |  \n",
      "     |  information(self, params, scale=None)\n",
      "     |      Fisher information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize a generalized linear model.\n",
      "     |  \n",
      "     |  loglike_mu(self, mu, scale=1.0)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, linear=False)\n",
      "     |      Return predicted values for a design matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters / coefficients of a GLM.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Is exog is None, model exog is used.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Exposure time values, only can be used with the log link\n",
      "     |          function.  See notes for details.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset values.  See notes for details.\n",
      "     |      linear : bool\n",
      "     |          If True, returns the linear predicted values.  If False,\n",
      "     |          returns the value of the inverse of the model's link function at\n",
      "     |          the linear predicted values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Any `exposure` and `offset` provided here take precedence over\n",
      "     |      the `exposure` and `offset` used in the model fit.  If `exog`\n",
      "     |      is passed as an argument here, then any `exposure` and\n",
      "     |      `offset` values in the fit will be ignored.\n",
      "     |      \n",
      "     |      Exposure values must be strictly positive.\n",
      "     |  \n",
      "     |  score_factor(self, params, scale=None)\n",
      "     |      weights for score for each observation\n",
      "     |      \n",
      "     |      This can be considered as score residuals.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which score is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_factor : ndarray_1d\n",
      "     |          A 1d weight vector used in the calculation of the score_obs.\n",
      "     |          The score_obs are obtained by `score_factor[:, None] * exog`\n",
      "     |  \n",
      "     |  score_test(self, params_constrained, k_constraints=None, exog_extra=None, observed=True)\n",
      "     |      score test for restrictions or for omitted variables\n",
      "     |      \n",
      "     |      The covariance matrix for the score is based on the Hessian, i.e.\n",
      "     |      observed information matrix or optionally on the expected information\n",
      "     |      matrix..\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params_constrained : array_like\n",
      "     |          estimated parameter of the restricted model. This can be the\n",
      "     |          parameter estimate for the current when testing for omitted\n",
      "     |          variables.\n",
      "     |      k_constraints : int or None\n",
      "     |          Number of constraints that were used in the estimation of params\n",
      "     |          restricted relative to the number of exog in the model.\n",
      "     |          This must be provided if no exog_extra are given. If exog_extra is\n",
      "     |          not None, then k_constraints is assumed to be zero if it is None.\n",
      "     |      exog_extra : None or array_like\n",
      "     |          Explanatory variables that are jointly tested for inclusion in the\n",
      "     |          model, i.e. omitted variables.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is used in calculating the\n",
      "     |          covariance matrix of the score. If false then the expected\n",
      "     |          information matrix is used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chi2_stat : float\n",
      "     |          chisquare statistic for the score test\n",
      "     |      p-value : float\n",
      "     |          P-value of the score test based on the chisquare distribution.\n",
      "     |      df : int\n",
      "     |          Degrees of freedom used in the p-value calculation. This is equal\n",
      "     |          to the number of constraints.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      not yet verified for case with scale not equal to 1.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "    \n",
      "    class GLS(RegressionModel)\n",
      "     |  GLS(endog, exog, sigma=None, missing='none', hasconst=None, **kwargs)\n",
      "     |  \n",
      "     |  Generalized Least Squares\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  sigma : scalar or array\n",
      "     |      The array or scalar `sigma` is the weighting matrix of the covariance.\n",
      "     |      The default is None for no scaling.  If `sigma` is a scalar, it is\n",
      "     |      assumed that `sigma` is an n x n diagonal matrix with the given\n",
      "     |      scalar, `sigma` as the value of each diagonal element.  If `sigma`\n",
      "     |      is an n-length vector, then `sigma` is assumed to be a diagonal\n",
      "     |      matrix with the given `sigma` on the diagonal.  This should be the\n",
      "     |      same as WLS.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  hasconst : None or bool\n",
      "     |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      "     |      a constant is not checked for and k_constant is set to 1 and all\n",
      "     |      result statistics are calculated as if a constant is present. If\n",
      "     |      False, a constant is not checked for and k_constant is set to 0.\n",
      "     |  **kwargs\n",
      "     |      Extra arguments that are used to set model properties when using the\n",
      "     |      formula interface.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  pinv_wexog : ndarray\n",
      "     |      `pinv_wexog` is the p x n Moore-Penrose pseudoinverse of `wexog`.\n",
      "     |  cholsimgainv : ndarray\n",
      "     |      The transpose of the Cholesky decomposition of the pseudoinverse.\n",
      "     |  df_model : float\n",
      "     |      p - 1, where p is the number of regressors including the intercept.\n",
      "     |      of freedom.\n",
      "     |  df_resid : float\n",
      "     |      Number of observations n less the number of parameters p.\n",
      "     |  llf : float\n",
      "     |      The value of the likelihood function of the fitted model.\n",
      "     |  nobs : float\n",
      "     |      The number of observations n.\n",
      "     |  normalized_cov_params : ndarray\n",
      "     |      p x p array :math:`(X^{T}\\Sigma^{-1}X)^{-1}`\n",
      "     |  results : RegressionResults instance\n",
      "     |      A property that returns the RegressionResults class if fit.\n",
      "     |  sigma : ndarray\n",
      "     |      `sigma` is the n x n covariance structure of the error terms.\n",
      "     |  wexog : ndarray\n",
      "     |      Design matrix whitened by `cholsigmainv`\n",
      "     |  wendog : ndarray\n",
      "     |      Response variable whitened by `cholsigmainv`\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  WLS : Fit a linear model using Weighted Least Squares.\n",
      "     |  OLS : Fit a linear model using Ordinary Least Squares.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If sigma is a function of the data making one of the regressors\n",
      "     |  a constant, then the current postestimation statistics will not be correct.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> data = sm.datasets.longley.load()\n",
      "     |  >>> data.exog = sm.add_constant(data.exog)\n",
      "     |  >>> ols_resid = sm.OLS(data.endog, data.exog).fit().resid\n",
      "     |  >>> res_fit = sm.OLS(ols_resid[1:], ols_resid[:-1]).fit()\n",
      "     |  >>> rho = res_fit.params\n",
      "     |  \n",
      "     |  `rho` is a consistent estimator of the correlation of the residuals from\n",
      "     |  an OLS fit of the longley data.  It is assumed that this is the true rho\n",
      "     |  of the AR process data.\n",
      "     |  \n",
      "     |  >>> from scipy.linalg import toeplitz\n",
      "     |  >>> order = toeplitz(np.arange(16))\n",
      "     |  >>> sigma = rho**order\n",
      "     |  \n",
      "     |  `sigma` is an n x n matrix of the autocorrelation structure of the\n",
      "     |  data.\n",
      "     |  \n",
      "     |  >>> gls_model = sm.GLS(data.endog, data.exog, sigma=sigma)\n",
      "     |  >>> gls_results = gls_model.fit()\n",
      "     |  >>> print(gls_results.summary())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GLS\n",
      "     |      RegressionModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, sigma=None, missing='none', hasconst=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      "     |      Return a regularized fit to a linear regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str\n",
      "     |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      "     |      alpha : scalar or array_like\n",
      "     |          The penalty weight.  If a scalar, the same penalty weight\n",
      "     |          applies to all variables in the model.  If a vector, it\n",
      "     |          must have the same length as `params`, and contains a\n",
      "     |          penalty weight for each coefficient.\n",
      "     |      L1_wt : scalar\n",
      "     |          The fraction of the penalty given to the L1 penalty term.\n",
      "     |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      "     |          ridge fit, if 1 it is a lasso fit.\n",
      "     |      start_params : array_like\n",
      "     |          Starting values for ``params``.\n",
      "     |      profile_scale : bool\n",
      "     |          If True the penalized fit is computed using the profile\n",
      "     |          (concentrated) log-likelihood for the Gaussian model.\n",
      "     |          Otherwise the fit uses the residual sum of squares.\n",
      "     |      refit : bool\n",
      "     |          If True, the model is refit using only the variables that\n",
      "     |          have non-zero coefficients in the regularized fit.  The\n",
      "     |          refitted model is not regularized.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      statsmodels.base.elastic_net.RegularizedResults\n",
      "     |          The regularized results.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The elastic net uses a combination of L1 and L2 penalties.\n",
      "     |      The implementation closely follows the glmnet package in R.\n",
      "     |      \n",
      "     |      The function that is minimized is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      "     |      \n",
      "     |      where RSS is the usual regression sum of squares, n is the\n",
      "     |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      "     |      norms.\n",
      "     |      \n",
      "     |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      "     |      exog data.\n",
      "     |      \n",
      "     |      Post-estimation results are based on the same data used to\n",
      "     |      select variables, hence may be subject to overfitting biases.\n",
      "     |      \n",
      "     |      The elastic_net method uses the following keyword arguments:\n",
      "     |      \n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations\n",
      "     |      cnvrg_tol : float\n",
      "     |          Convergence threshold for line searches\n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The square root lasso approach is a variation of the Lasso\n",
      "     |      that is largely self-tuning (the optimal tuning parameter\n",
      "     |      does not depend on the standard deviation of the regression\n",
      "     |      errors).  If the errors are Gaussian, the tuning parameter\n",
      "     |      can be taken to be\n",
      "     |      \n",
      "     |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      "     |      \n",
      "     |      where n is the sample size and p is the number of predictors.\n",
      "     |      \n",
      "     |      The square root lasso uses the following keyword arguments:\n",
      "     |      \n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The cvxopt module is required to estimate model using the square root\n",
      "     |      lasso.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      "     |         generalized linear models via coordinate descent.  Journal of\n",
      "     |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      "     |      \n",
      "     |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      "     |         pivotal recovery of sparse signals via conic programming.\n",
      "     |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Compute weights for calculating Hessian.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameter at which Hessian is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Compute the value of the Gaussian log-likelihood function at params.\n",
      "     |      \n",
      "     |      Given the whitened design matrix, the log-likelihood is evaluated\n",
      "     |      at the parameter vector `params` for the dependent variable `endog`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The value of the log-likelihood function for a GLS Model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The log-likelihood function for the normal distribution is\n",
      "     |      \n",
      "     |      .. math:: -\\frac{n}{2}\\log\\left(\\left(Y-\\hat{Y}\\right)^{\\prime}\n",
      "     |                 \\left(Y-\\hat{Y}\\right)\\right)\n",
      "     |                -\\frac{n}{2}\\left(1+\\log\\left(\\frac{2\\pi}{n}\\right)\\right)\n",
      "     |                -\\frac{1}{2}\\log\\left(\\left|\\Sigma\\right|\\right)\n",
      "     |      \n",
      "     |      Y and Y-hat are whitened.\n",
      "     |  \n",
      "     |  whiten(self, x)\n",
      "     |      GLS whiten method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          Data to be whitened.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The value np.dot(cholsigmainv,X).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      GLS : Fit a linear model using Generalized Least Squares.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RegressionModel:\n",
      "     |  \n",
      "     |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      "     |      Full fit of the model.\n",
      "     |      \n",
      "     |      The results include an estimate of covariance matrix, (whitened)\n",
      "     |      residuals and an estimate of scale.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str, optional\n",
      "     |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      "     |          to solve the least squares problem. \"qr\" uses the QR\n",
      "     |          factorization.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `regression.linear_model.RegressionResults` for a description\n",
      "     |          of the available covariance estimators.\n",
      "     |      cov_kwds : list or None, optional\n",
      "     |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      "     |          description required keywords for alternative covariance\n",
      "     |          estimators.\n",
      "     |      use_t : bool, optional\n",
      "     |          Flag indicating to use the Student's t distribution when computing\n",
      "     |          p-values.  Default behavior depends on cov_type. See\n",
      "     |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      "     |          implementation details.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      RegressionResults\n",
      "     |          The model estimation results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      RegressionResults\n",
      "     |          The results container.\n",
      "     |      RegressionResults.get_robustcov_results\n",
      "     |          A method to change the covariance estimator used when fitting the\n",
      "     |          model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      "     |      to solve the least squares minimization.\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      "     |      Construct a random number generator for the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters (regression coefficients).\n",
      "     |      scale : scalar\n",
      "     |          The variance parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      dist_class : class\n",
      "     |          A random number generator class.  Must take 'loc' and 'scale'\n",
      "     |          as arguments and return a random number generator implementing\n",
      "     |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Frozen random number generator object with mean and variance\n",
      "     |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      "     |          to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      "     |      the returned random number generator must be called with\n",
      "     |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      "     |      the data set used to fit the model.  If any other value is\n",
      "     |      used for ``n``, misleading results will be produced.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize model components.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return linear predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a linear model.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Model exog is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          An array of fitted values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the model has not yet been fit, params is not optional.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RegressionModel:\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      "     |      constant is included.\n",
      "     |  \n",
      "     |  df_resid\n",
      "     |      The residual degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the number of observations minus the rank of\n",
      "     |      the regressor matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GLSAR(GLS)\n",
      "     |  GLSAR(endog, exog=None, rho=1, missing='none', hasconst=None, **kwargs)\n",
      "     |  \n",
      "     |  Generalized Least Squares with AR covariance structure\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  rho : int\n",
      "     |      The order of the autoregressive covariance.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  hasconst : None or bool\n",
      "     |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      "     |      a constant is not checked for and k_constant is set to 1 and all\n",
      "     |      result statistics are calculated as if a constant is present. If\n",
      "     |      False, a constant is not checked for and k_constant is set to 0.\n",
      "     |  **kwargs\n",
      "     |      Extra arguments that are used to set model properties when using the\n",
      "     |      formula interface.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  GLSAR is considered to be experimental.\n",
      "     |  The linear autoregressive process of order p--AR(p)--is defined as:\n",
      "     |  TODO\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> X = range(1,8)\n",
      "     |  >>> X = sm.add_constant(X)\n",
      "     |  >>> Y = [1,3,4,5,8,10,9]\n",
      "     |  >>> model = sm.GLSAR(Y, X, rho=2)\n",
      "     |  >>> for i in range(6):\n",
      "     |  ...     results = model.fit()\n",
      "     |  ...     print(\"AR coefficients: {0}\".format(model.rho))\n",
      "     |  ...     rho, sigma = sm.regression.yule_walker(results.resid,\n",
      "     |  ...                                            order=model.order)\n",
      "     |  ...     model = sm.GLSAR(Y, X, rho)\n",
      "     |  ...\n",
      "     |  AR coefficients: [ 0.  0.]\n",
      "     |  AR coefficients: [-0.52571491 -0.84496178]\n",
      "     |  AR coefficients: [-0.6104153  -0.86656458]\n",
      "     |  AR coefficients: [-0.60439494 -0.857867  ]\n",
      "     |  AR coefficients: [-0.6048218  -0.85846157]\n",
      "     |  AR coefficients: [-0.60479146 -0.85841922]\n",
      "     |  >>> results.params\n",
      "     |  array([-0.66661205,  1.60850853])\n",
      "     |  >>> results.tvalues\n",
      "     |  array([ -2.10304127,  21.8047269 ])\n",
      "     |  >>> print(results.t_test([1, 0]))\n",
      "     |  <T test: effect=array([-0.66661205]), sd=array([[ 0.31697526]]), t=array([[-2.10304127]]), p=array([[ 0.06309969]]), df_denom=3>\n",
      "     |  >>> print(results.f_test(np.identity(2)))\n",
      "     |  <F test: F=array([[ 1815.23061844]]), p=[[ 0.00002372]], df_denom=3, df_num=2>\n",
      "     |  \n",
      "     |  Or, equivalently\n",
      "     |  \n",
      "     |  >>> model2 = sm.GLSAR(Y, X, rho=2)\n",
      "     |  >>> res = model2.iterative_fit(maxiter=6)\n",
      "     |  >>> model2.rho\n",
      "     |  array([-0.60479146, -0.85841922])\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GLSAR\n",
      "     |      GLS\n",
      "     |      RegressionModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, rho=1, missing='none', hasconst=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  iterative_fit(self, maxiter=3, rtol=0.0001, **kwargs)\n",
      "     |      Perform an iterative two-stage procedure to estimate a GLS model.\n",
      "     |      \n",
      "     |      The model is assumed to have AR(p) errors, AR(p) parameters and\n",
      "     |      regression coefficients are estimated iteratively.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxiter : int, optional\n",
      "     |          The number of iterations.\n",
      "     |      rtol : float, optional\n",
      "     |          Relative tolerance between estimated coefficients to stop the\n",
      "     |          estimation.  Stops if max(abs(last - current) / abs(last)) < rtol.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments passed to `fit`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      RegressionResults\n",
      "     |          The results computed using an iterative fit.\n",
      "     |  \n",
      "     |  whiten(self, x)\n",
      "     |      Whiten a series of columns according to an AR(p) covariance structure.\n",
      "     |      \n",
      "     |      Whitening using this method drops the initial p observations.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          The data to be whitened.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The whitened data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GLS:\n",
      "     |  \n",
      "     |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      "     |      Return a regularized fit to a linear regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str\n",
      "     |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      "     |      alpha : scalar or array_like\n",
      "     |          The penalty weight.  If a scalar, the same penalty weight\n",
      "     |          applies to all variables in the model.  If a vector, it\n",
      "     |          must have the same length as `params`, and contains a\n",
      "     |          penalty weight for each coefficient.\n",
      "     |      L1_wt : scalar\n",
      "     |          The fraction of the penalty given to the L1 penalty term.\n",
      "     |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      "     |          ridge fit, if 1 it is a lasso fit.\n",
      "     |      start_params : array_like\n",
      "     |          Starting values for ``params``.\n",
      "     |      profile_scale : bool\n",
      "     |          If True the penalized fit is computed using the profile\n",
      "     |          (concentrated) log-likelihood for the Gaussian model.\n",
      "     |          Otherwise the fit uses the residual sum of squares.\n",
      "     |      refit : bool\n",
      "     |          If True, the model is refit using only the variables that\n",
      "     |          have non-zero coefficients in the regularized fit.  The\n",
      "     |          refitted model is not regularized.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      statsmodels.base.elastic_net.RegularizedResults\n",
      "     |          The regularized results.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The elastic net uses a combination of L1 and L2 penalties.\n",
      "     |      The implementation closely follows the glmnet package in R.\n",
      "     |      \n",
      "     |      The function that is minimized is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      "     |      \n",
      "     |      where RSS is the usual regression sum of squares, n is the\n",
      "     |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      "     |      norms.\n",
      "     |      \n",
      "     |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      "     |      exog data.\n",
      "     |      \n",
      "     |      Post-estimation results are based on the same data used to\n",
      "     |      select variables, hence may be subject to overfitting biases.\n",
      "     |      \n",
      "     |      The elastic_net method uses the following keyword arguments:\n",
      "     |      \n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations\n",
      "     |      cnvrg_tol : float\n",
      "     |          Convergence threshold for line searches\n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The square root lasso approach is a variation of the Lasso\n",
      "     |      that is largely self-tuning (the optimal tuning parameter\n",
      "     |      does not depend on the standard deviation of the regression\n",
      "     |      errors).  If the errors are Gaussian, the tuning parameter\n",
      "     |      can be taken to be\n",
      "     |      \n",
      "     |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      "     |      \n",
      "     |      where n is the sample size and p is the number of predictors.\n",
      "     |      \n",
      "     |      The square root lasso uses the following keyword arguments:\n",
      "     |      \n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The cvxopt module is required to estimate model using the square root\n",
      "     |      lasso.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      "     |         generalized linear models via coordinate descent.  Journal of\n",
      "     |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      "     |      \n",
      "     |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      "     |         pivotal recovery of sparse signals via conic programming.\n",
      "     |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Compute weights for calculating Hessian.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameter at which Hessian is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Compute the value of the Gaussian log-likelihood function at params.\n",
      "     |      \n",
      "     |      Given the whitened design matrix, the log-likelihood is evaluated\n",
      "     |      at the parameter vector `params` for the dependent variable `endog`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The value of the log-likelihood function for a GLS Model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The log-likelihood function for the normal distribution is\n",
      "     |      \n",
      "     |      .. math:: -\\frac{n}{2}\\log\\left(\\left(Y-\\hat{Y}\\right)^{\\prime}\n",
      "     |                 \\left(Y-\\hat{Y}\\right)\\right)\n",
      "     |                -\\frac{n}{2}\\left(1+\\log\\left(\\frac{2\\pi}{n}\\right)\\right)\n",
      "     |                -\\frac{1}{2}\\log\\left(\\left|\\Sigma\\right|\\right)\n",
      "     |      \n",
      "     |      Y and Y-hat are whitened.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RegressionModel:\n",
      "     |  \n",
      "     |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      "     |      Full fit of the model.\n",
      "     |      \n",
      "     |      The results include an estimate of covariance matrix, (whitened)\n",
      "     |      residuals and an estimate of scale.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str, optional\n",
      "     |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      "     |          to solve the least squares problem. \"qr\" uses the QR\n",
      "     |          factorization.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `regression.linear_model.RegressionResults` for a description\n",
      "     |          of the available covariance estimators.\n",
      "     |      cov_kwds : list or None, optional\n",
      "     |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      "     |          description required keywords for alternative covariance\n",
      "     |          estimators.\n",
      "     |      use_t : bool, optional\n",
      "     |          Flag indicating to use the Student's t distribution when computing\n",
      "     |          p-values.  Default behavior depends on cov_type. See\n",
      "     |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      "     |          implementation details.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      RegressionResults\n",
      "     |          The model estimation results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      RegressionResults\n",
      "     |          The results container.\n",
      "     |      RegressionResults.get_robustcov_results\n",
      "     |          A method to change the covariance estimator used when fitting the\n",
      "     |          model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      "     |      to solve the least squares minimization.\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      "     |      Construct a random number generator for the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters (regression coefficients).\n",
      "     |      scale : scalar\n",
      "     |          The variance parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      dist_class : class\n",
      "     |          A random number generator class.  Must take 'loc' and 'scale'\n",
      "     |          as arguments and return a random number generator implementing\n",
      "     |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Frozen random number generator object with mean and variance\n",
      "     |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      "     |          to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      "     |      the returned random number generator must be called with\n",
      "     |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      "     |      the data set used to fit the model.  If any other value is\n",
      "     |      used for ``n``, misleading results will be produced.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize model components.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return linear predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a linear model.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Model exog is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          An array of fitted values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the model has not yet been fit, params is not optional.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RegressionModel:\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      "     |      constant is included.\n",
      "     |  \n",
      "     |  df_resid\n",
      "     |      The residual degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the number of observations minus the rank of\n",
      "     |      the regressor matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GeneralizedPoisson(CountModel)\n",
      "     |  GeneralizedPoisson(endog, exog, p=1, offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |  \n",
      "     |  Generalized Poisson Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  \n",
      "     |  p : scalar\n",
      "     |      P denotes parameterizations for GP regression. p=1 for GP-1 and\n",
      "     |      p=2 for GP-2. Default is p=1.\n",
      "     |  offset : array_like\n",
      "     |      Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |  exposure : array_like\n",
      "     |      Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  check_rank : bool\n",
      "     |      Check exog rank to determine model degrees of freedom. Default is\n",
      "     |      True. Setting to False reduces model initialization time when\n",
      "     |      exog.shape[1] is large.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GeneralizedPoisson\n",
      "     |      CountModel\n",
      "     |      DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, p=1, offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='bfgs', maxiter=35, full_output=1, disp=1, callback=None, use_transparams=False, cov_type='nonrobust', cov_kwds=None, use_t=None, optim_kwds_prelim=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |      \n",
      "     |              use_transparams : bool\n",
      "     |                  This parameter enable internal transformation to impose\n",
      "     |                  non-negativity. True to enable. Default is False.\n",
      "     |                  use_transparams=True imposes the no underdispersion (alpha > 0)\n",
      "     |                  constraint. In case use_transparams=True and method=\"newton\" or\n",
      "     |                  \"ncg\" transformation is ignored.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Generalized Poisson model Hessian matrix of the loglikelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (k_vars, k_vars)\n",
      "     |          The Hessian, second derivative of loglikelihood function,\n",
      "     |          evaluated at `params`\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood of Generalized Poisson model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\sum_{i=1}^{n}\\left[\\mu_{i}+(y_{i}-1)*ln(\\mu_{i}+\n",
      "     |          \\alpha*\\mu_{i}^{p-1}*y_{i})-y_{i}*ln(1+\\alpha*\\mu_{i}^{p-1})-\n",
      "     |          ln(y_{i}!)-\\frac{\\mu_{i}+\\alpha*\\mu_{i}^{p-1}*y_{i}}{1+\\alpha*\n",
      "     |          \\mu_{i}^{p-1}}\\right]\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Loglikelihood for observations of Generalized Poisson model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : ndarray\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\sum_{i=1}^{n}\\left[\\mu_{i}+(y_{i}-1)*ln(\\mu_{i}+\n",
      "     |          \\alpha*\\mu_{i}^{p-1}*y_{i})-y_{i}*ln(1+\\alpha*\\mu_{i}^{p-1})-\n",
      "     |          ln(y_{i}!)-\\frac{\\mu_{i}+\\alpha*\\mu_{i}^{p-1}*y_{i}}{1+\\alpha*\n",
      "     |          \\mu_{i}^{p-1}}\\right]\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, which='mean')\n",
      "     |      Predict response variable of a count model given exogenous variables.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If exposure is specified, then it will be logged by the method.\n",
      "     |      The user does not need to log it first.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DiscreteModel:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      The cumulative distribution function of the model.\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      The probability density (mass) function of the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Logit(BinaryModel)\n",
      "     |  Logit(endog, exog, check_rank=True, **kwargs)\n",
      "     |  \n",
      "     |  Logit Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  check_rank : bool\n",
      "     |      Check exog rank to determine model degrees of freedom. Default is\n",
      "     |      True. Setting to False reduces model initialization time when\n",
      "     |      exog.shape[1] is large.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Logit\n",
      "     |      BinaryModel\n",
      "     |      DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      The logistic cumulative distribution function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          `X` is the linear predictor of the logit model.  See notes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      1/(1 + exp(-X))\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      In the logit model,\n",
      "     |      \n",
      "     |      .. math:: \\Lambda\\left(x^{\\prime}\\beta\\right)=\n",
      "     |                \\text{Prob}\\left(Y=1|x\\right)=\n",
      "     |                \\frac{e^{x^{\\prime}\\beta}}{1+e^{x^{\\prime}\\beta}}\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='newton', maxiter=35, full_output=1, disp=1, callback=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Logit model Hessian matrix of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (k_vars, k_vars)\n",
      "     |          The Hessian, second derivative of loglikelihood function,\n",
      "     |          evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial^{2}\\ln L}{\\partial\\beta\\partial\\beta^{\\prime}}=-\\sum_{i}\\Lambda_{i}\\left(1-\\Lambda_{i}\\right)x_{i}x_{i}^{\\prime}\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of logit model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the logit model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math::\n",
      "     |      \n",
      "     |         \\ln L=\\sum_{i}\\ln\\Lambda\n",
      "     |         \\left(q_{i}x_{i}^{\\prime}\\beta\\right)\n",
      "     |      \n",
      "     |      Where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      "     |      logistic distribution is symmetric.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Log-likelihood of logit model for each observation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the logit model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : ndarray\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math::\n",
      "     |      \n",
      "     |         \\ln L=\\sum_{i}\\ln\\Lambda\n",
      "     |         \\left(q_{i}x_{i}^{\\prime}\\beta\\right)\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |      \n",
      "     |      where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      "     |      logistic distribution is symmetric.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      The logistic probability density function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          `X` is the linear predictor of the logit model.  See notes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pdf : ndarray\n",
      "     |          The value of the Logit probability mass function, PMF, for each\n",
      "     |          point of X. ``np.exp(-x)/(1+np.exp(-X))**2``\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      In the logit model,\n",
      "     |      \n",
      "     |      .. math:: \\lambda\\left(x^{\\prime}\\beta\\right)=\\frac{e^{-x^{\\prime}\\beta}}{\\left(1+e^{-x^{\\prime}\\beta}\\right)^{2}}\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Logit model score (gradient) vector of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L}{\\partial\\beta}=\\sum_{i=1}^{n}\\left(y_{i}-\\Lambda_{i}\\right)x_{i}\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Logit model Jacobian of the log-likelihood for each observation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jac : array_like\n",
      "     |          The derivative of the loglikelihood for each observation evaluated\n",
      "     |          at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L_{i}}{\\partial\\beta}=\\left(y_{i}-\\Lambda_{i}\\right)x_{i}\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BinaryModel:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, check_rank=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, linear=False)\n",
      "     |      Predict response variable of a model given exogenous variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Fitted parameters of the model.\n",
      "     |      exog : array_like\n",
      "     |          1d or 2d array of exogenous values.  If not supplied, the\n",
      "     |          whole exog attribute of the model is used.\n",
      "     |      linear : bool, optional\n",
      "     |          If True, returns the linear predictor dot(exog,params).  Else,\n",
      "     |          returns the value of the cdf at the linear predictor.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array\n",
      "     |          Fitted values at exog.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DiscreteModel:\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MANOVA(statsmodels.base.model.Model)\n",
      "     |  MANOVA(endog, exog, missing='none', hasconst=None, **kwargs)\n",
      "     |  \n",
      "     |  Multivariate Analysis of Variance\n",
      "     |  \n",
      "     |  The implementation of MANOVA is based on multivariate regression and does\n",
      "     |  not assume that the explanatory variables are categorical. Any type of\n",
      "     |  variables as in regression is allowed.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      Dependent variables. A nobs x k_endog array where nobs is\n",
      "     |      the number of observations and k_endog is the number of dependent\n",
      "     |      variables.\n",
      "     |  exog : array_like\n",
      "     |      Independent variables. A nobs x k_exog array where nobs is the\n",
      "     |      number of observations and k_exog is the number of independent\n",
      "     |      variables. An intercept is not included by default and should be added\n",
      "     |      by the user. Models specified using a formula include an intercept by\n",
      "     |      default.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      See Parameters.\n",
      "     |  exog : ndarray\n",
      "     |      See Parameters.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  MANOVA is used though the `mv_test` function, and `fit` is not used.\n",
      "     |  \n",
      "     |  The ``from_formula`` interface is the recommended method to specify\n",
      "     |  a model and simplifies testing without needing to manually configure\n",
      "     |  the contrast matrices.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [*] ftp://public.dhe.ibm.com/software/analytics/spss/documentation/\n",
      "     |     statistics/20.0/en/client/Manuals/IBM_SPSS_Statistics_Algorithms.pdf\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MANOVA\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, missing='none', hasconst=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self)\n",
      "     |      Fit a model to data.\n",
      "     |  \n",
      "     |  mv_test(self, hypotheses=None)\n",
      "     |          Linear hypotheses testing\n",
      "     |      \n",
      "     |          Parameters\n",
      "     |          ----------\n",
      "     |          hypotheses : list[tuple]\n",
      "     |      Hypothesis `L*B*M = C` to be tested where B is the parameters in\n",
      "     |      regression Y = X*B. Each element is a tuple of length 2, 3, or 4:\n",
      "     |      \n",
      "     |        * (name, contrast_L)\n",
      "     |        * (name, contrast_L, transform_M)\n",
      "     |        * (name, contrast_L, transform_M, constant_C)\n",
      "     |      \n",
      "     |      containing a string `name`, the contrast matrix L, the transform\n",
      "     |      matrix M (for transforming dependent variables), and right-hand side\n",
      "     |      constant matrix constant_C, respectively.\n",
      "     |      \n",
      "     |      contrast_L : 2D array or an array of strings\n",
      "     |          Left-hand side contrast matrix for hypotheses testing.\n",
      "     |          If 2D array, each row is an hypotheses and each column is an\n",
      "     |          independent variable. At least 1 row\n",
      "     |          (1 by k_exog, the number of independent variables) is required.\n",
      "     |          If an array of strings, it will be passed to\n",
      "     |          patsy.DesignInfo().linear_constraint.\n",
      "     |      \n",
      "     |      transform_M : 2D array or an array of strings or None, optional\n",
      "     |          Left hand side transform matrix.\n",
      "     |          If `None` or left out, it is set to a k_endog by k_endog\n",
      "     |          identity matrix (i.e. do not transform y matrix).\n",
      "     |          If an array of strings, it will be passed to\n",
      "     |          patsy.DesignInfo().linear_constraint.\n",
      "     |      \n",
      "     |      constant_C : 2D array or None, optional\n",
      "     |          Right-hand side constant matrix.\n",
      "     |          if `None` or left out it is set to a matrix of zeros\n",
      "     |          Must has the same number of rows as contrast_L and the same\n",
      "     |          number of columns as transform_M\n",
      "     |      \n",
      "     |      If `hypotheses` is None: 1) the effect of each independent variable\n",
      "     |      on the dependent variables will be tested. Or 2) if model is created\n",
      "     |      using a formula,  `hypotheses` will be created according to\n",
      "     |      `design_info`. 1) and 2) is equivalent if no additional variables\n",
      "     |      are created by the formula (e.g. dummy variables for categorical\n",
      "     |      variables and interaction terms)\n",
      "     |      \n",
      "     |      \n",
      "     |          Returns\n",
      "     |          -------\n",
      "     |          results: MultivariateTestResults\n",
      "     |      \n",
      "     |          Notes\n",
      "     |          -----\n",
      "     |          Testing the linear hypotheses\n",
      "     |      \n",
      "     |              L * params * M = 0\n",
      "     |      \n",
      "     |          where `params` is the regression coefficient matrix for the\n",
      "     |          linear model y = x * params\n",
      "     |      \n",
      "     |          If the model is not specified using the formula interfact, then the\n",
      "     |          hypotheses test each included exogenous variable, one at a time. In\n",
      "     |          most applications with categorical variables, the ``from_formula``\n",
      "     |          interface should be preferred when specifying a model since it\n",
      "     |          provides knowledge about the model when specifying the hypotheses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MI(builtins.object)\n",
      "     |  MI(imp, model, model_args_fn=None, model_kwds_fn=None, formula=None, fit_args=None, fit_kwds=None, xfunc=None, burn=100, nrep=20, skip=10)\n",
      "     |  \n",
      "     |  MI performs multiple imputation using a provided imputer object.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  imp : object\n",
      "     |      An imputer class, such as BayesGaussMI.\n",
      "     |  model : model class\n",
      "     |      Any statsmodels model class.\n",
      "     |  model_args_fn : function\n",
      "     |      A function taking an imputed dataset as input and returning\n",
      "     |      endog, exog.  If the model is fit using a formula, returns\n",
      "     |      a DataFrame used to build the model.  Optional when a formula\n",
      "     |      is used.\n",
      "     |  model_kwds_fn : function, optional\n",
      "     |      A function taking an imputed dataset as input and returning\n",
      "     |      a dictionary of model keyword arguments.\n",
      "     |  formula : str, optional\n",
      "     |      If provided, the model is constructed using the `from_formula`\n",
      "     |      class method, otherwise the `__init__` method is used.\n",
      "     |  fit_args : list-like, optional\n",
      "     |      List of arguments to be passed to the fit method\n",
      "     |  fit_kwds : dict-like, optional\n",
      "     |      Keyword arguments to be passed to the fit method\n",
      "     |  xfunc : function mapping ndarray to ndarray\n",
      "     |      A function that is applied to the complete data matrix\n",
      "     |      prior to fitting the model\n",
      "     |  burn : int\n",
      "     |      Number of burn-in iterations\n",
      "     |  nrep : int\n",
      "     |      Number of imputed data sets to use in the analysis\n",
      "     |  skip : int\n",
      "     |      Number of Gibbs iterations to skip between successive\n",
      "     |      multiple imputation fits.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The imputer object must have an 'update' method, and a 'data'\n",
      "     |  attribute that contains the current imputed dataset.\n",
      "     |  \n",
      "     |  xfunc can be used to introduce domain constraints, e.g. when\n",
      "     |  imputing binary data the imputed continuous values can be rounded\n",
      "     |  to 0/1.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, imp, model, model_args_fn=None, model_kwds_fn=None, formula=None, fit_args=None, fit_kwds=None, xfunc=None, burn=100, nrep=20, skip=10)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, results_cb=None)\n",
      "     |      Impute datasets, fit models, and pool results.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      results_cb : function, optional\n",
      "     |          If provided, each results instance r is passed through `results_cb`,\n",
      "     |          then appended to the `results` attribute of the MIResults object.\n",
      "     |          To save complete results, use `results_cb=lambda x: x`.  The default\n",
      "     |          behavior is to save no results.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A MIResults object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MICE(builtins.object)\n",
      "     |  MICE(model_formula, model_class, data, n_skip=3, init_kwds=None, fit_kwds=None)\n",
      "     |  \n",
      "     |  Multiple Imputation with Chained Equations.\n",
      "     |  \n",
      "     |  This class can be used to fit most statsmodels models to data sets\n",
      "     |  with missing values using the 'multiple imputation with chained\n",
      "     |  equations' (MICE) approach..\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  model_formula : str\n",
      "     |      The model formula to be fit to the imputed data sets.  This\n",
      "     |      formula is for the 'analysis model'.\n",
      "     |  model_class : statsmodels model\n",
      "     |      The model to be fit to the imputed data sets.  This model\n",
      "     |      class if for the 'analysis model'.\n",
      "     |  data : MICEData instance\n",
      "     |      MICEData object containing the data set for which\n",
      "     |      missing values will be imputed\n",
      "     |  n_skip : int\n",
      "     |      The number of imputed datasets to skip between consecutive\n",
      "     |      imputed datasets that are used for analysis.\n",
      "     |  init_kwds : dict-like\n",
      "     |      Dictionary of keyword arguments passed to the init method\n",
      "     |      of the analysis model.\n",
      "     |  fit_kwds : dict-like\n",
      "     |      Dictionary of keyword arguments passed to the fit method\n",
      "     |      of the analysis model.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Run all MICE steps and obtain results:\n",
      "     |  \n",
      "     |  >>> imp = mice.MICEData(data)\n",
      "     |  >>> fml = 'y ~ x1 + x2 + x3 + x4'\n",
      "     |  >>> mice = mice.MICE(fml, sm.OLS, imp)\n",
      "     |  >>> results = mice.fit(10, 10)\n",
      "     |  >>> print(results.summary())\n",
      "     |  \n",
      "     |  .. literalinclude:: ../plots/mice_example_1.txt\n",
      "     |  \n",
      "     |  \n",
      "     |  Obtain a sequence of fitted analysis models without combining\n",
      "     |  to obtain summary::\n",
      "     |  \n",
      "     |  >>> imp = mice.MICEData(data)\n",
      "     |  >>> fml = 'y ~ x1 + x2 + x3 + x4'\n",
      "     |  >>> mice = mice.MICE(fml, sm.OLS, imp)\n",
      "     |  >>> results = []\n",
      "     |  >>> for k in range(10):\n",
      "     |  >>>     x = mice.next_sample()\n",
      "     |  >>>     results.append(x)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, model_formula, model_class, data, n_skip=3, init_kwds=None, fit_kwds=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  combine(self)\n",
      "     |      Pools MICE imputation results.\n",
      "     |      \n",
      "     |      This method can only be used after the `run` method has been\n",
      "     |      called.  Returns estimates and standard errors of the analysis\n",
      "     |      model parameters.\n",
      "     |      \n",
      "     |      Returns a MICEResults instance.\n",
      "     |  \n",
      "     |  fit(self, n_burnin=10, n_imputations=10)\n",
      "     |      Fit a model using MICE.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n_burnin : int\n",
      "     |          The number of burn-in cycles to skip.\n",
      "     |      n_imputations : int\n",
      "     |          The number of data sets to impute\n",
      "     |  \n",
      "     |  next_sample(self)\n",
      "     |      Perform one complete MICE iteration.\n",
      "     |      \n",
      "     |      A single MICE iteration updates all missing values using their\n",
      "     |      respective imputation models, then fits the analysis model to\n",
      "     |      the imputed data.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          The model parameters for the analysis model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This function fits the analysis model and returns its\n",
      "     |      parameter estimate.  The parameter vector is not stored by the\n",
      "     |      class and is not used in any subsequent calls to `combine`.\n",
      "     |      Use `fit` to run all MICE steps together and obtain summary\n",
      "     |      results.\n",
      "     |      \n",
      "     |      The complete cycle of missing value imputation followed by\n",
      "     |      fitting the analysis model is repeated `n_skip + 1` times and\n",
      "     |      the analysis model parameters from the final fit are returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MICEData(builtins.object)\n",
      "     |  MICEData(data, perturbation_method='gaussian', k_pmm=20, history_callback=None)\n",
      "     |  \n",
      "     |  Wrap a data set to allow missing data handling with MICE.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : Pandas data frame\n",
      "     |      The data set, which is copied internally.\n",
      "     |  perturbation_method : str\n",
      "     |      The default perturbation method\n",
      "     |  k_pmm : int\n",
      "     |      The number of nearest neighbors to use during predictive mean\n",
      "     |      matching.  Can also be specified in `fit`.\n",
      "     |  history_callback : function\n",
      "     |      A function that is called after each complete imputation\n",
      "     |      cycle.  The return value is appended to `history`.  The\n",
      "     |      MICEData object is passed as the sole argument to\n",
      "     |      `history_callback`.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Allowed perturbation methods are 'gaussian' (the model parameters\n",
      "     |  are set to a draw from the Gaussian approximation to the posterior\n",
      "     |  distribution), and 'boot' (the model parameters are set to the\n",
      "     |  estimated values obtained when fitting a bootstrapped version of\n",
      "     |  the data set).\n",
      "     |  \n",
      "     |  `history_callback` can be implemented to have side effects such as\n",
      "     |  saving the current imputed data set to disk.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Draw 20 imputations from a data set called `data` and save them in\n",
      "     |  separate files with filename pattern `dataXX.csv`.  The variables\n",
      "     |  other than `x1` are imputed using linear models fit with OLS, with\n",
      "     |  mean structures containing main effects of all other variables in\n",
      "     |  `data`.  The variable named `x1` has a conditional mean structure\n",
      "     |  that includes an additional term for x2^2.\n",
      "     |  \n",
      "     |  >>> imp = mice.MICEData(data)\n",
      "     |  >>> imp.set_imputer('x1', formula='x2 + np.square(x2) + x3')\n",
      "     |  >>> for j in range(20):\n",
      "     |  ...     imp.update_all()\n",
      "     |  ...     imp.data.to_csv('data%02d.csv' % j)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data, perturbation_method='gaussian', k_pmm=20, history_callback=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_fitting_data(self, vname)\n",
      "     |      Return the data needed to fit a model for imputation.\n",
      "     |      \n",
      "     |      The data is used to impute variable `vname`, and therefore\n",
      "     |      only includes cases for which `vname` is observed.\n",
      "     |      \n",
      "     |      Values of type `PatsyFormula` in `init_kwds` or `fit_kwds` are\n",
      "     |      processed through Patsy and subset to align with the model's\n",
      "     |      endog and exog.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      vname : str\n",
      "     |         The variable for which the fitting data is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      endog : DataFrame\n",
      "     |          Observed values of `vname`.\n",
      "     |      exog : DataFrame\n",
      "     |          Regression design matrix for imputing `vname`.\n",
      "     |      init_kwds : dict-like\n",
      "     |          The init keyword arguments for `vname`, processed through Patsy\n",
      "     |          as required.\n",
      "     |      fit_kwds : dict-like\n",
      "     |          The fit keyword arguments for `vname`, processed through Patsy\n",
      "     |          as required.\n",
      "     |  \n",
      "     |  get_split_data(self, vname)\n",
      "     |      Return endog and exog for imputation of a given variable.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      vname : str\n",
      "     |         The variable for which the split data is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      endog_obs : DataFrame\n",
      "     |          Observed values of the variable to be imputed.\n",
      "     |      exog_obs : DataFrame\n",
      "     |          Current values of the predictors where the variable to be\n",
      "     |          imputed is observed.\n",
      "     |      exog_miss : DataFrame\n",
      "     |          Current values of the predictors where the variable to be\n",
      "     |          Imputed is missing.\n",
      "     |      init_kwds : dict-like\n",
      "     |          The init keyword arguments for `vname`, processed through Patsy\n",
      "     |          as required.\n",
      "     |      fit_kwds : dict-like\n",
      "     |          The fit keyword arguments for `vname`, processed through Patsy\n",
      "     |          as required.\n",
      "     |  \n",
      "     |  impute(self, vname)\n",
      "     |  \n",
      "     |  impute_pmm(self, vname)\n",
      "     |      Use predictive mean matching to impute missing values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The `perturb_params` method must be called first to define the\n",
      "     |      model.\n",
      "     |  \n",
      "     |  next_sample(self)\n",
      "     |      Returns the next imputed dataset in the imputation process.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : array_like\n",
      "     |          An imputed dataset from the MICE chain.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `MICEData` does not have a `skip` parameter.  Consecutive\n",
      "     |      values returned by `next_sample` are immediately consecutive\n",
      "     |      in the imputation chain.\n",
      "     |      \n",
      "     |      The returned value is a reference to the data attribute of\n",
      "     |      the class and should be copied before making any changes.\n",
      "     |  \n",
      "     |  perturb_params(self, vname)\n",
      "     |  \n",
      "     |  plot_bivariate(self, col1_name, col2_name, lowess_args=None, lowess_min_n=40, jitter=None, plot_points=True, ax=None)\n",
      "     |      Plot observed and imputed values for two variables.\n",
      "     |      \n",
      "     |      Displays a scatterplot of one variable against another.  The\n",
      "     |      points are colored according to whether the values are\n",
      "     |      observed or imputed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col1_name : str\n",
      "     |          The variable to be plotted on the horizontal axis.\n",
      "     |      col2_name : str\n",
      "     |          The variable to be plotted on the vertical axis.\n",
      "     |      lowess_args : dictionary\n",
      "     |          A dictionary of dictionaries, keys are 'ii', 'io', 'oi'\n",
      "     |          and 'oo', where 'o' denotes 'observed' and 'i' denotes\n",
      "     |          imputed.  See Notes for details.\n",
      "     |      lowess_min_n : int\n",
      "     |          Minimum sample size to plot a lowess fit\n",
      "     |      jitter : float or tuple\n",
      "     |          Standard deviation for jittering points in the plot.\n",
      "     |          Either a single scalar applied to both axes, or a tuple\n",
      "     |          containing x-axis jitter and y-axis jitter, respectively.\n",
      "     |      plot_points : bool\n",
      "     |          If True, the data points are plotted.\n",
      "     |      ax : AxesSubplot\n",
      "     |          Axes on which to plot, created if not provided.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The matplotlib figure on which the plot id drawn.\n",
      "     |  \n",
      "     |  plot_fit_obs(self, col_name, lowess_args=None, lowess_min_n=40, jitter=None, plot_points=True, ax=None)\n",
      "     |      Plot fitted versus imputed or observed values as a scatterplot.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str\n",
      "     |          The variable to be plotted on the horizontal axis.\n",
      "     |      lowess_args : dict-like\n",
      "     |          Keyword arguments passed to lowess fit.  A dictionary of\n",
      "     |          dictionaries, keys are 'o' and 'i' denoting 'observed' and\n",
      "     |          'imputed', respectively.\n",
      "     |      lowess_min_n : int\n",
      "     |          Minimum sample size to plot a lowess fit\n",
      "     |      jitter : float or tuple\n",
      "     |          Standard deviation for jittering points in the plot.\n",
      "     |          Either a single scalar applied to both axes, or a tuple\n",
      "     |          containing x-axis jitter and y-axis jitter, respectively.\n",
      "     |      plot_points : bool\n",
      "     |          If True, the data points are plotted.\n",
      "     |      ax : AxesSubplot\n",
      "     |          Axes on which to plot, created if not provided.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The matplotlib figure on which the plot is drawn.\n",
      "     |  \n",
      "     |  plot_imputed_hist(self, col_name, ax=None, imp_hist_args=None, obs_hist_args=None, all_hist_args=None)\n",
      "     |      Display imputed values for one variable as a histogram.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      col_name : str\n",
      "     |          The name of the variable to be plotted.\n",
      "     |      ax : AxesSubplot\n",
      "     |          An axes on which to draw the histograms.  If not provided,\n",
      "     |          one is created.\n",
      "     |      imp_hist_args : dict\n",
      "     |          Keyword arguments to be passed to pyplot.hist when\n",
      "     |          creating the histogram for imputed values.\n",
      "     |      obs_hist_args : dict\n",
      "     |          Keyword arguments to be passed to pyplot.hist when\n",
      "     |          creating the histogram for observed values.\n",
      "     |      all_hist_args : dict\n",
      "     |          Keyword arguments to be passed to pyplot.hist when\n",
      "     |          creating the histogram for all values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The matplotlib figure on which the histograms were drawn\n",
      "     |  \n",
      "     |  plot_missing_pattern(self, ax=None, row_order='pattern', column_order='pattern', hide_complete_rows=False, hide_complete_columns=False, color_row_patterns=True)\n",
      "     |      Generate an image showing the missing data pattern.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ax : AxesSubplot\n",
      "     |          Axes on which to draw the plot.\n",
      "     |      row_order : str\n",
      "     |          The method for ordering the rows.  Must be one of 'pattern',\n",
      "     |          'proportion', or 'raw'.\n",
      "     |      column_order : str\n",
      "     |          The method for ordering the columns.  Must be one of 'pattern',\n",
      "     |          'proportion', or 'raw'.\n",
      "     |      hide_complete_rows : bool\n",
      "     |          If True, rows with no missing values are not drawn.\n",
      "     |      hide_complete_columns : bool\n",
      "     |          If True, columns with no missing values are not drawn.\n",
      "     |      color_row_patterns : bool\n",
      "     |          If True, color the unique row patterns, otherwise use grey\n",
      "     |          and white as colors.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A figure containing a plot of the missing data pattern.\n",
      "     |  \n",
      "     |  set_imputer(self, endog_name, formula=None, model_class=None, init_kwds=None, fit_kwds=None, predict_kwds=None, k_pmm=20, perturbation_method=None, regularized=False)\n",
      "     |      Specify the imputation process for a single variable.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog_name : str\n",
      "     |          Name of the variable to be imputed.\n",
      "     |      formula : str\n",
      "     |          Conditional formula for imputation. Defaults to a formula\n",
      "     |          with main effects for all other variables in dataset.  The\n",
      "     |          formula should only include an expression for the mean\n",
      "     |          structure, e.g. use 'x1 + x2' not 'x4 ~ x1 + x2'.\n",
      "     |      model_class : statsmodels model\n",
      "     |          Conditional model for imputation. Defaults to OLS.  See below\n",
      "     |          for more information.\n",
      "     |      init_kwds : dit-like\n",
      "     |          Keyword arguments passed to the model init method.\n",
      "     |      fit_kwds : dict-like\n",
      "     |          Keyword arguments passed to the model fit method.\n",
      "     |      predict_kwds : dict-like\n",
      "     |          Keyword arguments passed to the model predict method.\n",
      "     |      k_pmm : int\n",
      "     |          Determines number of neighboring observations from which\n",
      "     |          to randomly sample when using predictive mean matching.\n",
      "     |      perturbation_method : str\n",
      "     |          Either 'gaussian' or 'bootstrap'. Determines the method\n",
      "     |          for perturbing parameters in the imputation model.  If\n",
      "     |          None, uses the default specified at class initialization.\n",
      "     |      regularized : dict\n",
      "     |          If regularized[name]=True, `fit_regularized` rather than\n",
      "     |          `fit` is called when fitting imputation models for this\n",
      "     |          variable.  When regularized[name]=True for any variable,\n",
      "     |          perturbation_method must be set to boot.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The model class must meet the following conditions:\n",
      "     |          * A model must have a 'fit' method that returns an object.\n",
      "     |          * The object returned from `fit` must have a `params` attribute\n",
      "     |            that is an array-like object.\n",
      "     |          * The object returned from `fit` must have a cov_params method\n",
      "     |            that returns a square array-like object.\n",
      "     |          * The model must have a `predict` method.\n",
      "     |  \n",
      "     |  update(self, vname)\n",
      "     |      Impute missing values for a single variable.\n",
      "     |      \n",
      "     |      This is a two-step process in which first the parameters are\n",
      "     |      perturbed, then the missing values are re-imputed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      vname : str\n",
      "     |          The name of the variable to be updated.\n",
      "     |  \n",
      "     |  update_all(self, n_iter=1)\n",
      "     |      Perform a specified number of MICE iterations.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n_iter : int\n",
      "     |          The number of updates to perform.  Only the result of the\n",
      "     |          final update will be available.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The imputed values are stored in the class attribute `self.data`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MNLogit(MultinomialModel)\n",
      "     |  MNLogit(endog, exog, check_rank=True, **kwargs)\n",
      "     |  \n",
      "     |  Multinomial Logit Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      `endog` is an 1-d vector of the endogenous response.  `endog` can\n",
      "     |      contain strings, ints, or floats or may be a pandas Categorical Series.\n",
      "     |      Note that if it contains strings, every distinct string will be a\n",
      "     |      category.  No stripping of whitespace is done.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See `statsmodels.tools.add_constant`.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  check_rank : bool\n",
      "     |      Check exog rank to determine model degrees of freedom. Default is\n",
      "     |      True. Setting to False reduces model initialization time when\n",
      "     |      exog.shape[1] is large.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  J : float\n",
      "     |      The number of choices for the endogenous variable. Note that this\n",
      "     |      is zero-indexed.\n",
      "     |  K : float\n",
      "     |      The actual number of parameters for the exogenous design.  Includes\n",
      "     |      the constant if the design has one.\n",
      "     |  names : dict\n",
      "     |      A dictionary mapping the column number in `wendog` to the variables\n",
      "     |      in `endog`.\n",
      "     |  wendog : ndarray\n",
      "     |      An n x j array where j is the number of unique categories in `endog`.\n",
      "     |      Each column of j is a dummy variable indicating the category of\n",
      "     |      each observation. See `names` for a dictionary mapping each column to\n",
      "     |      its category.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  See developer notes for further information on `MNLogit` internals.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MNLogit\n",
      "     |      MultinomialModel\n",
      "     |      BinaryModel\n",
      "     |      DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, check_rank=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      Multinomial logit cumulative distribution function.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray\n",
      "     |          The linear predictor of the model XB.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cdf : ndarray\n",
      "     |          The cdf evaluated at `X`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      In the multinomial logit model.\n",
      "     |      .. math:: \\frac{\\exp\\left(\\beta_{j}^{\\prime}x_{i}\\right)}{\\sum_{k=0}^{J}\\exp\\left(\\beta_{k}^{\\prime}x_{i}\\right)}\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Multinomial logit Hessian matrix of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (J*K, J*K)\n",
      "     |          The Hessian, second derivative of loglikelihood function with\n",
      "     |          respect to the flattened parameters, evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial^{2}\\ln L}{\\partial\\beta_{j}\\partial\\beta_{l}}=-\\sum_{i=1}^{n}\\frac{\\exp\\left(\\beta_{j}^{\\prime}x_{i}\\right)}{\\sum_{k=0}^{J}\\exp\\left(\\beta_{k}^{\\prime}x_{i}\\right)}\\left[\\boldsymbol{1}\\left(j=l\\right)-\\frac{\\exp\\left(\\beta_{l}^{\\prime}x_{i}\\right)}{\\sum_{k=0}^{J}\\exp\\left(\\beta_{k}^{\\prime}x_{i}\\right)}\\right]x_{i}x_{l}^{\\prime}\n",
      "     |      \n",
      "     |      where\n",
      "     |      :math:`\\boldsymbol{1}\\left(j=l\\right)` equals 1 if `j` = `l` and 0\n",
      "     |      otherwise.\n",
      "     |      \n",
      "     |      The actual Hessian matrix has J**2 * K x K elements. Our Hessian\n",
      "     |      is reshaped to be square (J*K, J*K) so that the solvers can use it.\n",
      "     |      \n",
      "     |      This implementation does not take advantage of the symmetry of\n",
      "     |      the Hessian and could probably be refactored for speed.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of the multinomial logit model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the multinomial logit model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math::\n",
      "     |      \n",
      "     |         \\ln L=\\sum_{i=1}^{n}\\sum_{j=0}^{J}d_{ij}\\ln\n",
      "     |         \\left(\\frac{\\exp\\left(\\beta_{j}^{\\prime}x_{i}\\right)}\n",
      "     |         {\\sum_{k=0}^{J}\n",
      "     |         \\exp\\left(\\beta_{k}^{\\prime}x_{i}\\right)}\\right)\n",
      "     |      \n",
      "     |      where :math:`d_{ij}=1` if individual `i` chose alternative `j` and 0\n",
      "     |      if not.\n",
      "     |  \n",
      "     |  loglike_and_score(self, params)\n",
      "     |      Returns log likelihood and score, efficiently reusing calculations.\n",
      "     |      \n",
      "     |      Note that both of these returned quantities will need to be negated\n",
      "     |      before being minimized by the maximum likelihood fitting machinery.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Log-likelihood of the multinomial logit model for each observation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the multinomial logit model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : array_like\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math::\n",
      "     |      \n",
      "     |         \\ln L_{i}=\\sum_{j=0}^{J}d_{ij}\\ln\n",
      "     |         \\left(\\frac{\\exp\\left(\\beta_{j}^{\\prime}x_{i}\\right)}\n",
      "     |         {\\sum_{k=0}^{J}\n",
      "     |         \\exp\\left(\\beta_{k}^{\\prime}x_{i}\\right)}\\right)\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |      \n",
      "     |      where :math:`d_{ij}=1` if individual `i` chose alternative `j` and 0\n",
      "     |      if not.\n",
      "     |  \n",
      "     |  pdf(self, eXB)\n",
      "     |      NotImplemented\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score matrix for multinomial logit model log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters of the multinomial logit model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, (K * (J-1),)\n",
      "     |          The 2-d score vector, i.e. the first derivative of the\n",
      "     |          loglikelihood function, of the multinomial logit model evaluated at\n",
      "     |          `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L}{\\partial\\beta_{j}}=\\sum_{i}\\left(d_{ij}-\\frac{\\exp\\left(\\beta_{j}^{\\prime}x_{i}\\right)}{\\sum_{k=0}^{J}\\exp\\left(\\beta_{k}^{\\prime}x_{i}\\right)}\\right)x_{i}\n",
      "     |      \n",
      "     |      for :math:`j=1,...,J`\n",
      "     |      \n",
      "     |      In the multinomial model the score matrix is K x J-1 but is returned\n",
      "     |      as a flattened array to work with the solvers.\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Jacobian matrix for multinomial logit model log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters of the multinomial logit model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jac : array_like\n",
      "     |          The derivative of the loglikelihood for each observation evaluated\n",
      "     |          at `params` .\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L_{i}}{\\partial\\beta_{j}}=\\left(d_{ij}-\\frac{\\exp\\left(\\beta_{j}^{\\prime}x_{i}\\right)}{\\sum_{k=0}^{J}\\exp\\left(\\beta_{k}^{\\prime}x_{i}\\right)}\\right)x_{i}\n",
      "     |      \n",
      "     |      for :math:`j=1,...,J`, for observations :math:`i=1,...,n`\n",
      "     |      \n",
      "     |      In the multinomial model the score vector is K x (J-1) but is returned\n",
      "     |      as a flattened array. The Jacobian has the observations in rows and\n",
      "     |      the flattened array of derivatives in columns.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MultinomialModel:\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='newton', maxiter=35, full_output=1, disp=1, callback=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Preprocesses the data for MNLogit.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, linear=False)\n",
      "     |      Predict response variable of a model given exogenous variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          2d array of fitted parameters of the model. Should be in the\n",
      "     |          order returned from the model.\n",
      "     |      exog : array_like\n",
      "     |          1d or 2d array of exogenous values.  If not supplied, the\n",
      "     |          whole exog attribute of the model is used. If a 1d array is given\n",
      "     |          it assumed to be 1 row of exogenous variables. If you only have\n",
      "     |          one regressor and would like to do prediction, you must provide\n",
      "     |          a 2d array with shape[1] == 1.\n",
      "     |      linear : bool, optional\n",
      "     |          If True, returns the linear predictor dot(exog,params).  Else,\n",
      "     |          returns the value of the cdf at the linear predictor.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Column 0 is the base case, the rest conform to the rows of params\n",
      "     |      shifted up one for the base case.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DiscreteModel:\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MixedLM(statsmodels.base.model.LikelihoodModel)\n",
      "     |  MixedLM(endog, exog, groups, exog_re=None, exog_vc=None, use_sqrt=True, missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Linear Mixed Effects Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : 1d array_like\n",
      "     |      The dependent variable\n",
      "     |  exog : 2d array_like\n",
      "     |      A matrix of covariates used to determine the\n",
      "     |      mean structure (the \"fixed effects\" covariates).\n",
      "     |  groups : 1d array_like\n",
      "     |      A vector of labels determining the groups -- data from\n",
      "     |      different groups are independent\n",
      "     |  exog_re : 2d array_like\n",
      "     |      A matrix of covariates used to determine the variance and\n",
      "     |      covariance structure (the \"random effects\" covariates).  If\n",
      "     |      None, defaults to a random intercept for each group.\n",
      "     |  exog_vc : VCSpec instance or dict-like (deprecated)\n",
      "     |      A VCSPec instance defines the structure of the variance\n",
      "     |      components in the model.  Alternatively, see notes below\n",
      "     |      for a dictionary-based format.  The dictionary format is\n",
      "     |      deprecated and may be removed at some point in the future.\n",
      "     |  use_sqrt : bool\n",
      "     |      If True, optimization is carried out using the lower\n",
      "     |      triangle of the square root of the random effects\n",
      "     |      covariance matrix, otherwise it is carried out using the\n",
      "     |      lower triangle of the random effects covariance matrix.\n",
      "     |  missing : str\n",
      "     |      The approach to missing data handling\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If `exog_vc` is not a `VCSpec` instance, then it must be a\n",
      "     |  dictionary of dictionaries.  Specifically, `exog_vc[a][g]` is a\n",
      "     |  matrix whose columns are linearly combined using independent\n",
      "     |  random coefficients.  This random term then contributes to the\n",
      "     |  variance structure of the data for group `g`.  The random\n",
      "     |  coefficients all have mean zero, and have the same variance.  The\n",
      "     |  matrix must be `m x k`, where `m` is the number of observations in\n",
      "     |  group `g`.  The number of columns may differ among the top-level\n",
      "     |  groups.\n",
      "     |  \n",
      "     |  The covariates in `exog`, `exog_re` and `exog_vc` may (but need\n",
      "     |  not) partially or wholly overlap.\n",
      "     |  \n",
      "     |  `use_sqrt` should almost always be set to True.  The main use case\n",
      "     |  for use_sqrt=False is when complicated patterns of fixed values in\n",
      "     |  the covariance structure are set (using the `free` argument to\n",
      "     |  `fit`) that cannot be expressed in terms of the Cholesky factor L.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  A basic mixed model with fixed effects for the columns of\n",
      "     |  ``exog`` and a random intercept for each distinct value of\n",
      "     |  ``group``:\n",
      "     |  \n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups)\n",
      "     |  >>> result = model.fit()\n",
      "     |  \n",
      "     |  A mixed model with fixed effects for the columns of ``exog`` and\n",
      "     |  correlated random coefficients for the columns of ``exog_re``:\n",
      "     |  \n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups, exog_re=exog_re)\n",
      "     |  >>> result = model.fit()\n",
      "     |  \n",
      "     |  A mixed model with fixed effects for the columns of ``exog`` and\n",
      "     |  independent random coefficients for the columns of ``exog_re``:\n",
      "     |  \n",
      "     |  >>> free = MixedLMParams.from_components(\n",
      "     |                   fe_params=np.ones(exog.shape[1]),\n",
      "     |                   cov_re=np.eye(exog_re.shape[1]))\n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups, exog_re=exog_re)\n",
      "     |  >>> result = model.fit(free=free)\n",
      "     |  \n",
      "     |  A different way to specify independent random coefficients for the\n",
      "     |  columns of ``exog_re``.  In this example ``groups`` must be a\n",
      "     |  Pandas Series with compatible indexing with ``exog_re``, and\n",
      "     |  ``exog_re`` has two columns.\n",
      "     |  \n",
      "     |  >>> g = pd.groupby(groups, by=groups).groups\n",
      "     |  >>> vc = {}\n",
      "     |  >>> vc['1'] = {k : exog_re.loc[g[k], 0] for k in g}\n",
      "     |  >>> vc['2'] = {k : exog_re.loc[g[k], 1] for k in g}\n",
      "     |  >>> model = sm.MixedLM(endog, exog, groups, vcomp=vc)\n",
      "     |  >>> result = model.fit()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MixedLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, groups, exog_re=None, exog_vc=None, use_sqrt=True, missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, reml=True, niter_sa=0, do_cg=True, fe_pen=None, cov_pen=None, free=None, full_output=False, method=None, **fit_kwargs)\n",
      "     |      Fit a linear mixed model to the data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like or MixedLMParams\n",
      "     |          Starting values for the profile log-likelihood.  If not a\n",
      "     |          `MixedLMParams` instance, this should be an array\n",
      "     |          containing the packed parameters for the profile\n",
      "     |          log-likelihood, including the fixed effects\n",
      "     |          parameters.\n",
      "     |      reml : bool\n",
      "     |          If true, fit according to the REML likelihood, else\n",
      "     |          fit the standard likelihood using ML.\n",
      "     |      niter_sa : int\n",
      "     |          Currently this argument is ignored and has no effect\n",
      "     |          on the results.\n",
      "     |      cov_pen : CovariancePenalty object\n",
      "     |          A penalty for the random effects covariance matrix\n",
      "     |      do_cg : bool, defaults to True\n",
      "     |          If False, the optimization is skipped and a results\n",
      "     |          object at the given (or default) starting values is\n",
      "     |          returned.\n",
      "     |      fe_pen : Penalty object\n",
      "     |          A penalty on the fixed effects\n",
      "     |      free : MixedLMParams object\n",
      "     |          If not `None`, this is a mask that allows parameters to be\n",
      "     |          held fixed at specified values.  A 1 indicates that the\n",
      "     |          corresponding parameter is estimated, a 0 indicates that\n",
      "     |          it is fixed at its starting value.  Setting the `cov_re`\n",
      "     |          component to the identity matrix fits a model with\n",
      "     |          independent random effects.  Note that some optimization\n",
      "     |          methods do not respect this constraint (bfgs and lbfgs both\n",
      "     |          work).\n",
      "     |      full_output : bool\n",
      "     |          If true, attach iteration history to results\n",
      "     |      method : str\n",
      "     |          Optimization method.  Can be a scipy.optimize method name,\n",
      "     |          or a list of such names to be tried in sequence.\n",
      "     |      **fit_kwargs\n",
      "     |          Additional keyword arguments passed to fit.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A MixedLMResults instance.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', alpha=0, ceps=0.0001, ptol=1e-06, maxit=200, **fit_kwargs)\n",
      "     |      Fit a model in which the fixed effects parameters are\n",
      "     |      penalized.  The dependence parameters are held fixed at their\n",
      "     |      estimated values in the unpenalized model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str of Penalty object\n",
      "     |          Method for regularization.  If a string, must be 'l1'.\n",
      "     |      alpha : array_like\n",
      "     |          Scalar or vector of penalty weights.  If a scalar, the\n",
      "     |          same weight is applied to all coefficients; if a vector,\n",
      "     |          it contains a weight for each coefficient.  If method is a\n",
      "     |          Penalty object, the weights are scaled by alpha.  For L1\n",
      "     |          regularization, the weights are used directly.\n",
      "     |      ceps : positive real scalar\n",
      "     |          Fixed effects parameters smaller than this value\n",
      "     |          in magnitude are treated as being zero.\n",
      "     |      ptol : positive real scalar\n",
      "     |          Convergence occurs when the sup norm difference\n",
      "     |          between successive values of `fe_params` is less than\n",
      "     |          `ptol`.\n",
      "     |      maxit : int\n",
      "     |          The maximum number of iterations.\n",
      "     |      **fit_kwargs\n",
      "     |          Additional keyword arguments passed to fit.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A MixedLMResults instance containing the results.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The covariance structure is not updated as the fixed effects\n",
      "     |      parameters are varied.\n",
      "     |      \n",
      "     |      The algorithm used here for L1 regularization is a\"shooting\"\n",
      "     |      or cyclic coordinate descent algorithm.\n",
      "     |      \n",
      "     |      If method is 'l1', then `fe_pen` and `cov_pen` are used to\n",
      "     |      obtain the covariance structure, but are ignored during the\n",
      "     |      L1-penalized fitting.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Friedman, J. H., Hastie, T. and Tibshirani, R. Regularized\n",
      "     |      Paths for Generalized Linear Models via Coordinate\n",
      "     |      Descent. Journal of Statistical Software, 33(1) (2008)\n",
      "     |      http://www.jstatsoft.org/v33/i01/paper\n",
      "     |      \n",
      "     |      http://statweb.stanford.edu/~tibs/stat315a/Supplements/fuse.pdf\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale, exog)\n",
      "     |  \n",
      "     |  get_fe_params(self, cov_re, vcomp, tol=1e-10)\n",
      "     |      Use GLS to update the fixed effects parameter estimates.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cov_re : array_like (2d)\n",
      "     |          The covariance matrix of the random effects.\n",
      "     |      vcomp : array_like (1d)\n",
      "     |          The variance components.\n",
      "     |      tol : float\n",
      "     |          A tolerance parameter to determine when covariances\n",
      "     |          are singular.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : ndarray\n",
      "     |          The GLS estimates of the fixed effects parameters.\n",
      "     |      singular : bool\n",
      "     |          True if the covariance is singular\n",
      "     |  \n",
      "     |  get_scale(self, fe_params, cov_re, vcomp)\n",
      "     |      Returns the estimated error variance based on given estimates\n",
      "     |      of the slopes and random effects covariance matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fe_params : array_like\n",
      "     |          The regression slope estimates\n",
      "     |      cov_re : 2d array_like\n",
      "     |          Estimate of the random effects covariance matrix\n",
      "     |      vcomp : array_like\n",
      "     |          Estimate of the variance components\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scale : float\n",
      "     |          The estimated error variance.\n",
      "     |  \n",
      "     |  group_list(self, array)\n",
      "     |      Returns `array` split into subarrays corresponding to the\n",
      "     |      grouping structure.\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Returns the model's Hessian matrix.\n",
      "     |      \n",
      "     |      Calculates the Hessian matrix for the linear mixed effects\n",
      "     |      model with respect to the parameterization in which the\n",
      "     |      covariance matrix is represented directly (without square-root\n",
      "     |      transformation).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams or array_like\n",
      "     |          The model parameters at which the Hessian is calculated.\n",
      "     |          If array-like, must contain the packed parameters in a\n",
      "     |          form that is compatible with this model instance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : 2d ndarray\n",
      "     |          The Hessian matrix, evaluated at `params`.\n",
      "     |      sing : boolean\n",
      "     |          If True, the covariance matrix is singular and a\n",
      "     |          pseudo-inverse is returned.\n",
      "     |  \n",
      "     |  loglike(self, params, profile_fe=True)\n",
      "     |      Evaluate the (profile) log-likelihood of the linear mixed\n",
      "     |      effects model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams, or array_like.\n",
      "     |          The parameter value.  If array-like, must be a packed\n",
      "     |          parameter vector containing only the covariance\n",
      "     |          parameters.\n",
      "     |      profile_fe : bool\n",
      "     |          If True, replace the provided value of `fe_params` with\n",
      "     |          the GLS estimates.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The log-likelihood value at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The scale parameter `scale` is always profiled out of the\n",
      "     |      log-likelihood.  In addition, if `profile_fe` is true the\n",
      "     |      fixed effects parameters are also profiled out.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a mixed linear model.  Can be either a\n",
      "     |          MixedLMParams instance, or a vector containing the packed\n",
      "     |          model parameters in which the fixed effects parameters are\n",
      "     |          at the beginning of the vector, or a vector containing\n",
      "     |          only the fixed effects parameters.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data for the fixed effects. Model exog\n",
      "     |          is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values.  Note that these predicted values\n",
      "     |      only reflect the fixed effects mean structure of the model.\n",
      "     |  \n",
      "     |  score(self, params, profile_fe=True)\n",
      "     |      Returns the score vector of the profile log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The score vector that is returned is computed with respect to\n",
      "     |      the parameterization defined by this model instance's\n",
      "     |      `use_sqrt` attribute.\n",
      "     |  \n",
      "     |  score_full(self, params, calc_fe)\n",
      "     |      Returns the score with respect to untransformed parameters.\n",
      "     |      \n",
      "     |      Calculates the score vector for the profiled log-likelihood of\n",
      "     |      the mixed effects model with respect to the parameterization\n",
      "     |      in which the random effects covariance matrix is represented\n",
      "     |      in its full form (not using the Cholesky factor).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams or array_like\n",
      "     |          The parameter at which the score function is evaluated.\n",
      "     |          If array-like, must contain the packed random effects\n",
      "     |          parameters (cov_re and vcomp) without fe_params.\n",
      "     |      calc_fe : bool\n",
      "     |          If True, calculate the score vector for the fixed effects\n",
      "     |          parameters.  If False, this vector is not calculated, and\n",
      "     |          a vector of zeros is returned in its place.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_fe : array_like\n",
      "     |          The score vector with respect to the fixed effects\n",
      "     |          parameters.\n",
      "     |      score_re : array_like\n",
      "     |          The score vector with respect to the random effects\n",
      "     |          parameters (excluding variance components parameters).\n",
      "     |      score_vc : array_like\n",
      "     |          The score vector with respect to variance components\n",
      "     |          parameters.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `score_re` is taken with respect to the parameterization in\n",
      "     |      which `cov_re` is represented through its lower triangle\n",
      "     |      (without taking the Cholesky square root).\n",
      "     |  \n",
      "     |  score_sqrt(self, params, calc_fe=True)\n",
      "     |      Returns the score with respect to transformed parameters.\n",
      "     |      \n",
      "     |      Calculates the score vector with respect to the\n",
      "     |      parameterization in which the random effects covariance matrix\n",
      "     |      is represented through its Cholesky square root.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : MixedLMParams or array_like\n",
      "     |          The model parameters.  If array-like must contain packed\n",
      "     |          parameters that are compatible with this model instance.\n",
      "     |      calc_fe : bool\n",
      "     |          If True, calculate the score vector for the fixed effects\n",
      "     |          parameters.  If False, this vector is not calculated, and\n",
      "     |          a vector of zeros is returned in its place.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_fe : array_like\n",
      "     |          The score vector with respect to the fixed effects\n",
      "     |          parameters.\n",
      "     |      score_re : array_like\n",
      "     |          The score vector with respect to the random effects\n",
      "     |          parameters (excluding variance components parameters).\n",
      "     |      score_vc : array_like\n",
      "     |          The score vector with respect to variance components\n",
      "     |          parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, data, re_formula=None, vc_formula=None, subset=None, use_sparse=False, missing='none', *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      re_formula : str\n",
      "     |          A one-sided formula defining the variance structure of the\n",
      "     |          model.  The default gives a random intercept for each\n",
      "     |          group.\n",
      "     |      vc_formula : dict-like\n",
      "     |          Formulas describing variance components.  `vc_formula[vc]` is\n",
      "     |          the formula for the component with variance parameter named\n",
      "     |          `vc`.  The formula is processed into a matrix, and the columns\n",
      "     |          of this matrix are linearly combined with independent random\n",
      "     |          coefficients having mean zero and a common variance.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index\n",
      "     |          values that indicate the subset of df to use in the\n",
      "     |          model. Assumes df is a `pandas.DataFrame`\n",
      "     |      missing : str\n",
      "     |          Either 'none' or 'drop'\n",
      "     |      args : extra arguments\n",
      "     |          These are passed to the model\n",
      "     |      kwargs : extra keyword arguments\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : Model instance\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `data` must define __getitem__ with the keys in the formula\n",
      "     |      terms args and kwargs are passed on to the model\n",
      "     |      instantiation. E.g., a numpy structured or rec array, a\n",
      "     |      dictionary, or a pandas DataFrame.\n",
      "     |      \n",
      "     |      If the variance component is intended to produce random\n",
      "     |      intercepts for disjoint subsets of a group, specified by\n",
      "     |      string labels or a categorical data value, always use '0 +' in\n",
      "     |      the formula so that no overall intercept is included.\n",
      "     |      \n",
      "     |      If the variance components specify random slopes and you do\n",
      "     |      not also want a random group-level intercept in the model,\n",
      "     |      then use '0 +' in the formula to exclude the intercept.\n",
      "     |      \n",
      "     |      The variance components formulas are processed separately for\n",
      "     |      each group.  If a variable is categorical the results will not\n",
      "     |      be affected by whether the group labels are distinct or\n",
      "     |      re-used over the top-level groups.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Suppose we have data from an educational study with students\n",
      "     |      nested in classrooms nested in schools.  The students take a\n",
      "     |      test, and we want to relate the test scores to the students'\n",
      "     |      ages, while accounting for the effects of classrooms and\n",
      "     |      schools.  The school will be the top-level group, and the\n",
      "     |      classroom is a nested group that is specified as a variance\n",
      "     |      component.  Note that the schools may have different number of\n",
      "     |      classrooms, and the classroom labels may (but need not be)\n",
      "     |      different across the schools.\n",
      "     |      \n",
      "     |      >>> vc = {'classroom': '0 + C(classroom)'}\n",
      "     |      >>> MixedLM.from_formula('test_score ~ age', vc_formula=vc,                                   re_formula='1', groups='school', data=data)\n",
      "     |      \n",
      "     |      Now suppose we also have a previous test score called\n",
      "     |      'pretest'.  If we want the relationship between pretest\n",
      "     |      scores and the current test to vary by classroom, we can\n",
      "     |      specify a random slope for the pretest score\n",
      "     |      \n",
      "     |      >>> vc = {'classroom': '0 + C(classroom)', 'pretest': '0 + pretest'}\n",
      "     |      >>> MixedLM.from_formula('test_score ~ age + pretest', vc_formula=vc,                                   re_formula='1', groups='school', data=data)\n",
      "     |      \n",
      "     |      The following model is almost equivalent to the previous one,\n",
      "     |      but here the classroom random intercept and pretest slope may\n",
      "     |      be correlated.\n",
      "     |      \n",
      "     |      >>> vc = {'classroom': '0 + C(classroom)'}\n",
      "     |      >>> MixedLM.from_formula('test_score ~ age + pretest', vc_formula=vc,                                   re_formula='1 + pretest', groups='school',                                   data=data)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NegativeBinomial(CountModel)\n",
      "     |  NegativeBinomial(endog, exog, loglike_method='nb2', offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |  \n",
      "     |  Negative Binomial Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  loglike_method : str\n",
      "     |      Log-likelihood type. 'nb2','nb1', or 'geometric'.\n",
      "     |      Fitted value :math:`\\mu`\n",
      "     |      Heterogeneity parameter :math:`\\alpha`\n",
      "     |  \n",
      "     |      - nb2: Variance equal to :math:`\\mu + \\alpha\\mu^2` (most common)\n",
      "     |      - nb1: Variance equal to :math:`\\mu + \\alpha\\mu`\n",
      "     |      - geometric: Variance equal to :math:`\\mu + \\mu^2`\n",
      "     |  offset : array_like\n",
      "     |      Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |  exposure : array_like\n",
      "     |      Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  check_rank : bool\n",
      "     |      Check exog rank to determine model degrees of freedom. Default is\n",
      "     |      True. Setting to False reduces model initialization time when\n",
      "     |      exog.shape[1] is large.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Greene, W. 2008. \"Functional forms for the negative binomial model\n",
      "     |      for count data\". Economics Letters. Volume 99, Number 3, pp.585-590.\n",
      "     |  Hilbe, J.M. 2011. \"Negative binomial regression\". Cambridge University\n",
      "     |      Press.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NegativeBinomial\n",
      "     |      CountModel\n",
      "     |      DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      # Workaround to pickle instance methods\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, loglike_method='nb2', offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __setstate__(self, indict)\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='bfgs', maxiter=35, full_output=1, disp=1, callback=None, cov_type='nonrobust', cov_kwds=None, use_t=None, optim_kwds_prelim=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood for negative binomial model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model. If `loglike_method` is nb1 or\n",
      "     |          nb2, then the ancillary parameter is expected to be the\n",
      "     |          last element.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      llf : float\n",
      "     |          The loglikelihood value at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Following notation in Greene (2008), with negative binomial\n",
      "     |      heterogeneity parameter :math:`\\alpha`:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |         \\lambda_i &= exp(X\\beta) \\\\\n",
      "     |         \\theta &= 1 / \\alpha \\\\\n",
      "     |         g_i &= \\theta \\lambda_i^Q \\\\\n",
      "     |         w_i &= g_i/(g_i + \\lambda_i) \\\\\n",
      "     |         r_i &= \\theta / (\\theta+\\lambda_i) \\\\\n",
      "     |         ln \\mathcal{L}_i &= ln \\Gamma(y_i+g_i) - ln \\Gamma(1+y_i) + g_iln (r_i) + y_i ln(1-r_i)\n",
      "     |      \n",
      "     |      where :math`Q=0` for NB2 and geometric and :math:`Q=1` for NB1.\n",
      "     |      For the geometric, :math:`\\alpha=0` as well.\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      #TODO: replace this with analytic where is it used?\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CountModel:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, linear=False)\n",
      "     |      Predict response variable of a count model given exogenous variables\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Model parameters\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Is exog is None, model exog is used.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Log(exposure) is added to the linear prediction with\n",
      "     |          coefficient equal to 1. If exposure is not provided and exog\n",
      "     |          is None, uses the model's exposure if present.  If not, uses\n",
      "     |          0 as the default value.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset is added to the linear prediction with coefficient\n",
      "     |          equal to 1. If offset is not provided and exog\n",
      "     |          is None, uses the model's offset if present.  If not, uses\n",
      "     |          0 as the default value.\n",
      "     |      linear : bool\n",
      "     |          If True, returns the linear predicted values.  If False,\n",
      "     |          returns the exponential of the linear predicted value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If exposure is specified, then it will be logged by the method.\n",
      "     |      The user does not need to log it first.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DiscreteModel:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      The cumulative distribution function of the model.\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      The probability density (mass) function of the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NegativeBinomialP(CountModel)\n",
      "     |  NegativeBinomialP(endog, exog, p=2, offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |  \n",
      "     |  Generalized Negative Binomial (NB-P) Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  p : scalar\n",
      "     |      P denotes parameterizations for NB regression. p=1 for NB-1 and\n",
      "     |      p=2 for NB-2. Default is p=2.\n",
      "     |  offset : array_like\n",
      "     |      Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |  exposure : array_like\n",
      "     |      Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.\n",
      "     |      missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  check_rank : bool\n",
      "     |      Check exog rank to determine model degrees of freedom. Default is\n",
      "     |      True. Setting to False reduces model initialization time when\n",
      "     |      exog.shape[1] is large.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  p : scalar\n",
      "     |      P denotes parameterizations for NB-P regression. p=1 for NB-1 and\n",
      "     |      p=2 for NB-2. Default is p=1.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NegativeBinomialP\n",
      "     |      CountModel\n",
      "     |      DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, p=2, offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  convert_params(self, params, mu)\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='bfgs', maxiter=35, full_output=1, disp=1, callback=None, use_transparams=False, cov_type='nonrobust', cov_kwds=None, use_t=None, optim_kwds_prelim=None, **kwargs)\n",
      "     |              use_transparams : bool\n",
      "     |                  This parameter enable internal transformation to impose\n",
      "     |                  non-negativity. True to enable. Default is False.\n",
      "     |                  use_transparams=True imposes the no underdispersion (alpha > 0)\n",
      "     |                  constraint. In case use_transparams=True and method=\"newton\" or\n",
      "     |                  \"ncg\" transformation is ignored.\n",
      "     |      \n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Generalized Negative Binomial (NB-P) model hessian maxtrix of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray, 2-D\n",
      "     |          The hessian matrix of the model.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood of Generalized Negative Binomial (NB-P) model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Loglikelihood for observations of Generalized Negative Binomial (NB-P) model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : ndarray\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, which='mean')\n",
      "     |      Predict response variable of a model given exogenous variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          2d array of fitted parameters of the model. Should be in the\n",
      "     |          order returned from the model.\n",
      "     |      exog : array_like, optional\n",
      "     |          1d or 2d array of exogenous values.  If not supplied, the\n",
      "     |          whole exog attribute of the model is used. If a 1d array is given\n",
      "     |          it assumed to be 1 row of exogenous variables. If you only have\n",
      "     |          one regressor and would like to do prediction, you must provide\n",
      "     |          a 2d array with shape[1] == 1.\n",
      "     |      linear : bool, optional\n",
      "     |          If True, returns the linear predictor dot(exog,params).  Else,\n",
      "     |          returns the value of the cdf at the linear predictor.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.\n",
      "     |      which : 'mean', 'linear', 'prob', optional.\n",
      "     |          'mean' returns the exp of linear predictor exp(dot(exog,params)).\n",
      "     |          'linear' returns the linear predictor dot(exog,params).\n",
      "     |          'prob' return probabilities for counts from 0 to max(endog).\n",
      "     |          Default is 'mean'.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Generalized Negative Binomial (NB-P) model score (gradient) vector of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Generalized Negative Binomial (NB-P) model score (gradient) vector of the log-likelihood for each observations.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DiscreteModel:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      The cumulative distribution function of the model.\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      The probability density (mass) function of the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NominalGEE(GEE)\n",
      "     |  NominalGEE(endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs)\n",
      "     |  \n",
      "     |  Nominal Response Marginal Regression Model using GEE.\n",
      "     |  \n",
      "     |  Marginal regression model fit using Generalized Estimating Equations.\n",
      "     |  \n",
      "     |  GEE can be used to fit Generalized Linear Models (GLMs) when the\n",
      "     |  data have a grouped structure, and the observations are possibly\n",
      "     |  correlated within groups but not between groups.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      1d array of endogenous values (i.e. responses, outcomes,\n",
      "     |      dependent variables, or 'Y' values).\n",
      "     |  exog : array_like\n",
      "     |      2d array of exogeneous values (i.e. covariates, predictors,\n",
      "     |      independent variables, regressors, or 'X' values). A `nobs x\n",
      "     |      k` array where `nobs` is the number of observations and `k` is\n",
      "     |      the number of regressors. An intercept is not included by\n",
      "     |      default and should be added by the user. See\n",
      "     |      `statsmodels.tools.add_constant`.\n",
      "     |  groups : array_like\n",
      "     |      A 1d array of length `nobs` containing the group labels.\n",
      "     |  time : array_like\n",
      "     |      A 2d array of time (or other index) values, used by some\n",
      "     |      dependence structures to define similarity relationships among\n",
      "     |      observations within a cluster.\n",
      "     |  family : family class instance\n",
      "     |      The default value `None` uses a multinomial logit family\n",
      "     |      specifically designed for use with GEE.  Setting this\n",
      "     |      argument to a non-default value is not currently supported.\n",
      "     |  cov_struct : CovStruct class instance\n",
      "     |      The default is Independence.  To specify an exchangeable\n",
      "     |      structure use cov_struct = Exchangeable().  See\n",
      "     |      statsmodels.genmod.cov_struct.CovStruct for more\n",
      "     |      information.\n",
      "     |  offset : array_like\n",
      "     |      An offset to be included in the fit.  If provided, must be\n",
      "     |      an array whose length is the number of rows in exog.\n",
      "     |  dep_data : array_like\n",
      "     |      Additional data passed to the dependence structure.\n",
      "     |  constraint : (ndarray, ndarray)\n",
      "     |      If provided, the constraint is a tuple (L, R) such that the\n",
      "     |      model parameters are estimated under the constraint L *\n",
      "     |      param = R, where L is a q x p matrix and R is a\n",
      "     |      q-dimensional vector.  If constraint is provided, a score\n",
      "     |      test is performed to compare the constrained model to the\n",
      "     |      unconstrained model.\n",
      "     |  update_dep : bool\n",
      "     |      If true, the dependence parameters are optimized, otherwise\n",
      "     |      they are held fixed at their starting values.\n",
      "     |  weights : array_like\n",
      "     |      An array of case weights to use in the analysis.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.genmod.families.family\n",
      "     |  :ref:`families`\n",
      "     |  :ref:`links`\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Only the following combinations make sense for family and link ::\n",
      "     |  \n",
      "     |                 + ident log logit probit cloglog pow opow nbinom loglog logc\n",
      "     |    Gaussian     |   x    x                        x\n",
      "     |    inv Gaussian |   x    x                        x\n",
      "     |    binomial     |   x    x    x     x       x     x    x           x      x\n",
      "     |    Poisson      |   x    x                        x\n",
      "     |    neg binomial |   x    x                        x          x\n",
      "     |    gamma        |   x    x                        x\n",
      "     |  \n",
      "     |  Not all of these link functions are currently available.\n",
      "     |  \n",
      "     |  Endog and exog are references so that if the data they refer\n",
      "     |  to are already arrays and these arrays are changed, endog and\n",
      "     |  exog will change.\n",
      "     |  \n",
      "     |  The \"robust\" covariance type is the standard \"sandwich estimator\"\n",
      "     |  (e.g. Liang and Zeger (1986)).  It is the default here and in most\n",
      "     |  other packages.  The \"naive\" estimator gives smaller standard\n",
      "     |  errors, but is only correct if the working correlation structure\n",
      "     |  is correctly specified.  The \"bias reduced\" estimator of Mancl and\n",
      "     |  DeRouen (Biometrics, 2001) reduces the downward bias of the robust\n",
      "     |  estimator.\n",
      "     |  \n",
      "     |  The robust covariance provided here follows Liang and Zeger (1986)\n",
      "     |  and agrees with R's gee implementation.  To obtain the robust\n",
      "     |  standard errors reported in Stata, multiply by sqrt(N / (N - g)),\n",
      "     |  where N is the total sample size, and g is the average group size.\n",
      "     |  \n",
      "     |  The nominal and ordinal GEE models should not have an intercept\n",
      "     |  (either implicit or explicit).  Use \"0 + \" in a formula to\n",
      "     |  suppress the intercept.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  Fit a nominal regression model using GEE:\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> import statsmodels.formula.api as smf\n",
      "     |  >>> gor = sm.cov_struct.GlobalOddsRatio(\"nominal\")\n",
      "     |  >>> model = sm.NominalGEE(endog, exog, groups, cov_struct=gor)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Using formulas:\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> model = sm.NominalGEE.from_formula(\"y ~ 0 + x1 + x2\", groups,\n",
      "     |                   data, cov_struct=gor)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Using the formula API:\n",
      "     |  \n",
      "     |  >>> import statsmodels.formula.api as smf\n",
      "     |  >>> model = smf.nominal_gee(\"y ~ 0 + x1 + x2\", groups, data,\n",
      "     |                              cov_struct=gor)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NominalGEE\n",
      "     |      GEE\n",
      "     |      statsmodels.genmod.generalized_linear_model.GLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust')\n",
      "     |      Fits a marginal regression model using generalized estimating\n",
      "     |      equations (GEE).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxiter : int\n",
      "     |          The maximum number of iterations\n",
      "     |      ctol : float\n",
      "     |          The convergence criterion for stopping the Gauss-Seidel\n",
      "     |          iterations\n",
      "     |      start_params : array_like\n",
      "     |          A vector of starting values for the regression\n",
      "     |          coefficients.  If None, a default is chosen.\n",
      "     |      params_niter : int\n",
      "     |          The number of Gauss-Seidel updates of the mean structure\n",
      "     |          parameters that take place prior to each update of the\n",
      "     |          dependence structure.\n",
      "     |      first_dep_update : int\n",
      "     |          No dependence structure updates occur before this\n",
      "     |          iteration number.\n",
      "     |      cov_type : str\n",
      "     |          One of \"robust\", \"naive\", or \"bias_reduced\".\n",
      "     |      ddof_scale : scalar or None\n",
      "     |          The scale parameter is estimated as the sum of squared\n",
      "     |          Pearson residuals divided by `N - ddof_scale`, where N\n",
      "     |          is the total sample size.  If `ddof_scale` is None, the\n",
      "     |          number of covariates (including an intercept if present)\n",
      "     |          is used.\n",
      "     |      scaling_factor : scalar\n",
      "     |          The estimated covariance of the parameter estimates is\n",
      "     |          scaled by this value.  Default is 1, Stata uses N / (N - g),\n",
      "     |          where N is the total sample size and g is the average group\n",
      "     |          size.\n",
      "     |      scale : str or float, optional\n",
      "     |          `scale` can be None, 'X2', or a float\n",
      "     |          If a float, its value is used as the scale parameter.\n",
      "     |          The default value is None, which uses `X2` (Pearson's\n",
      "     |          chi-square) for Gamma, Gaussian, and Inverse Gaussian.\n",
      "     |          The default is 1 for the Binomial and Poisson families.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An instance of the GEEResults class or subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If convergence difficulties occur, increase the values of\n",
      "     |      `first_dep_update` and/or `params_niter`.  Setting\n",
      "     |      `first_dep_update` to a greater value (e.g. ~10-20) causes the\n",
      "     |      algorithm to move close to the GLM solution before attempting\n",
      "     |      to identify the dependence structure.\n",
      "     |      \n",
      "     |      For the Gaussian family, there is no benefit to setting\n",
      "     |      `params_niter` to a value greater than 1, since the mean\n",
      "     |      structure parameters converge in one step.\n",
      "     |  \n",
      "     |  mean_deriv(self, exog, lin_pred)\n",
      "     |      Derivative of the expected endog with respect to the parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array_like\n",
      "     |         The exogeneous data at which the derivative is computed,\n",
      "     |         number of rows must be a multiple of `ncut`.\n",
      "     |      lin_pred : array_like\n",
      "     |         The values of the linear predictor, length must be multiple\n",
      "     |         of `ncut`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The derivative of the expected endog with respect to the\n",
      "     |      parameters.\n",
      "     |  \n",
      "     |  mean_deriv_exog(self, exog, params, offset_exposure=None)\n",
      "     |      Derivative of the expected endog with respect to exog for the\n",
      "     |      multinomial model, used in analyzing marginal effects.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array_like\n",
      "     |         The exogeneous data at which the derivative is computed,\n",
      "     |         number of rows must be a multiple of `ncut`.\n",
      "     |      lpr : array_like\n",
      "     |         The linear predictor values, length must be multiple of\n",
      "     |         `ncut`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The value of the derivative of the expected endog with respect\n",
      "     |      to exog.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      offset_exposure must be set at None for the multinomial family.\n",
      "     |  \n",
      "     |  setup_nominal(self, endog, exog, groups, time, offset)\n",
      "     |      Restructure nominal data as binary indicators so that they can\n",
      "     |      be analyzed using Generalized Estimating Equations.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GEE:\n",
      "     |  \n",
      "     |  cluster_list(self, array)\n",
      "     |      Returns `array` split into subarrays corresponding to the\n",
      "     |      cluster structure.\n",
      "     |  \n",
      "     |  compare_score_test(self, submodel)\n",
      "     |      Perform a score test for the given submodel against this model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      submodel : GEEResults instance\n",
      "     |          A fitted GEE model that is a submodel of this model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A dictionary with keys \"statistic\", \"p-value\", and \"df\",\n",
      "     |      containing the score test statistic, its chi^2 p-value,\n",
      "     |      and the degrees of freedom used to compute the p-value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The score test can be performed without calling 'fit' on the\n",
      "     |      larger model.  The provided submodel must be obtained from a\n",
      "     |      fitted GEE.\n",
      "     |      \n",
      "     |      This method performs the same score test as can be obtained by\n",
      "     |      fitting the GEE with a linear constraint and calling `score_test`\n",
      "     |      on the results.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Xu Guo and Wei Pan (2002). \"Small sample performance of the score\n",
      "     |      test in GEE\".\n",
      "     |      http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\n",
      "     |  \n",
      "     |  estimate_scale(self)\n",
      "     |      Estimate the dispersion/scale.\n",
      "     |  \n",
      "     |  fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None)\n",
      "     |      Regularized estimation for GEE.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pen_wt : float\n",
      "     |          The penalty weight (a non-negative scalar).\n",
      "     |      scad_param : float\n",
      "     |          Non-negative scalar determining the shape of the Scad\n",
      "     |          penalty.\n",
      "     |      maxiter : int\n",
      "     |          The maximum number of iterations.\n",
      "     |      ddof_scale : int\n",
      "     |          Value to subtract from `nobs` when calculating the\n",
      "     |          denominator degrees of freedom for t-statistics, defaults\n",
      "     |          to the number of columns in `exog`.\n",
      "     |      update_assoc : int\n",
      "     |          The dependence parameters are updated every `update_assoc`\n",
      "     |          iterations of the mean structure parameter updates.\n",
      "     |      ctol : float\n",
      "     |          Convergence criterion, default is one order of magnitude\n",
      "     |          smaller than proposed in section 3.1 of Wang et al.\n",
      "     |      ztol : float\n",
      "     |          Coefficients smaller than this value are treated as\n",
      "     |          being zero, default is based on section 5 of Wang et al.\n",
      "     |      eps : non-negative scalar\n",
      "     |          Numerical constant, see section 3.2 of Wang et al.\n",
      "     |      scale : float or string\n",
      "     |          If a float, this value is used as the scale parameter.\n",
      "     |          If \"X2\", the scale parameter is always estimated using\n",
      "     |          Pearson's chi-square method (e.g. as in a quasi-Poisson\n",
      "     |          analysis).  If None, the default approach for the family\n",
      "     |          is used to estimate the scale parameter.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GEEResults instance.  Note that not all methods of the results\n",
      "     |      class make sense when the model has been fit with regularization.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This implementation assumes that the link is canonical.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\n",
      "     |      equations for high-dimensional longitudinal data analysis.\n",
      "     |      Biometrics. 2012 Jun;68(2):353-60.\n",
      "     |      doi: 10.1111/j.1541-0420.2011.01678.x.\n",
      "     |      https://www.ncbi.nlm.nih.gov/pubmed/21955051\n",
      "     |      http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\n",
      "     |  \n",
      "     |  qic(self, params, scale, cov_params, n_step=1000)\n",
      "     |      Returns quasi-information criteria and quasi-likelihood values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The GEE estimates of the regression parameters.\n",
      "     |      scale : scalar\n",
      "     |          Estimated scale parameter\n",
      "     |      cov_params : array_like\n",
      "     |          An estimate of the covariance matrix for the\n",
      "     |          model parameters.  Conventionally this is the robust\n",
      "     |          covariance matrix.\n",
      "     |      n_step : integer\n",
      "     |          The number of points in the trapezoidal approximation\n",
      "     |          to the quasi-likelihood function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ql : scalar\n",
      "     |          The quasi-likelihood value\n",
      "     |      qic : scalar\n",
      "     |          A QIC that can be used to compare the mean and covariance\n",
      "     |          structures of the model.\n",
      "     |      qicu : scalar\n",
      "     |          A simplified QIC that can be used to compare mean structures\n",
      "     |          but not covariance structures\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The quasi-likelihood used here is obtained by numerically evaluating\n",
      "     |      Wedderburn's integral representation of the quasi-likelihood function.\n",
      "     |      This approach is valid for all families and  links.  Many other\n",
      "     |      packages use analytical expressions for quasi-likelihoods that are\n",
      "     |      valid in special cases where the link function is canonical.  These\n",
      "     |      analytical expressions may omit additive constants that only depend\n",
      "     |      on the data.  Therefore, the numerical values of our QL and QIC values\n",
      "     |      will differ from the values reported by other packages.  However only\n",
      "     |      the differences between two QIC values calculated for different models\n",
      "     |      using the same data are meaningful.  Our QIC should produce the same\n",
      "     |      QIC differences as other software.\n",
      "     |      \n",
      "     |      When using the QIC for models with unknown scale parameter, use a\n",
      "     |      common estimate of the scale parameter for all models being compared.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] W. Pan (2001).  Akaike's information criterion in generalized\n",
      "     |             estimating equations.  Biometrics (57) 1.\n",
      "     |  \n",
      "     |  update_cached_means(self, mean_params)\n",
      "     |      cached_means should always contain the most recent calculation\n",
      "     |      of the group-wise mean vectors.  This function should be\n",
      "     |      called every time the regression parameters are changed, to\n",
      "     |      keep the cached means up to date.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from GEE:\n",
      "     |  \n",
      "     |  from_formula(formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from GEE:\n",
      "     |  \n",
      "     |  cached_means = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.genmod.generalized_linear_model.GLM:\n",
      "     |  \n",
      "     |  estimate_tweedie_power(self, mu, method='brentq', low=1.01, high=5.0)\n",
      "     |      Tweedie specific function to estimate scale and the variance parameter.\n",
      "     |      The variance parameter is also referred to as p, xi, or shape.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : array_like\n",
      "     |          Fitted mean response variable\n",
      "     |      method : str, defaults to 'brentq'\n",
      "     |          Scipy optimizer used to solve the Pearson equation. Only brentq\n",
      "     |          currently supported.\n",
      "     |      low : float, optional\n",
      "     |          Low end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 1.01.\n",
      "     |      high : float, optional\n",
      "     |          High end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 5.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      power : float\n",
      "     |          The estimated shape or power.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      fit the model subject to linear equality constraints\n",
      "     |      \n",
      "     |      The constraints are of the form   `R params = q`\n",
      "     |      where R is the constraint_matrix and q is the vector of\n",
      "     |      constraint_values.\n",
      "     |      \n",
      "     |      The estimation creates a new model with transformed design matrix,\n",
      "     |      exog, and converts the results back to the original parameterization.\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : formula expression or tuple\n",
      "     |          If it is a tuple, then the constraint needs to be given by two\n",
      "     |          arrays (constraint_matrix, constraint_value), i.e. (R, q).\n",
      "     |          Otherwise, the constraints can be given as strings or list of\n",
      "     |          strings.\n",
      "     |          see t_test for details\n",
      "     |      start_params : None or array_like\n",
      "     |          starting values for the optimization. `start_params` needs to be\n",
      "     |          given in the original parameter space and are internally\n",
      "     |          transformed.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the transformed model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale=None, exog=None, exposure=None, offset=None, var_weights=1.0, n_trials=1.0)\n",
      "     |      Return a instance of the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters.\n",
      "     |      scale : scalar\n",
      "     |          The scale parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      offset : array_like or None\n",
      "     |          Offset variable for predicted mean.\n",
      "     |      exposure : array_like or None\n",
      "     |          Log(exposure) will be added to the linear prediction.\n",
      "     |      var_weights : array_like\n",
      "     |          1d array of variance (analytic) weights. The default is None.\n",
      "     |      n_trials : int\n",
      "     |          Number of trials for the binomial distribution. The default is 1\n",
      "     |          which corresponds to a Bernoulli random variable.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Instance of a scipy frozen distribution based on estimated\n",
      "     |          parameters.\n",
      "     |          Use the ``rvs`` method to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``, the\n",
      "     |      returned random number generator must be called with ``gen.rvs(n)``\n",
      "     |      where ``n`` is the number of observations in the data set used\n",
      "     |      to fit the model.  If any other value is used for ``n``, misleading\n",
      "     |      results will be produced.\n",
      "     |  \n",
      "     |  hessian(self, params, scale=None, observed=None)\n",
      "     |      Hessian, second derivative of loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned (default).\n",
      "     |          If False, then the expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian, i.e. observed information, or expected information matrix.\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Weights for calculating Hessian\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian_factor : ndarray, 1d\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      "     |  \n",
      "     |  information(self, params, scale=None)\n",
      "     |      Fisher information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize a generalized linear model.\n",
      "     |  \n",
      "     |  loglike(self, params, scale=None)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  loglike_mu(self, mu, scale=1.0)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, linear=False)\n",
      "     |      Return predicted values for a design matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters / coefficients of a GLM.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Is exog is None, model exog is used.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Exposure time values, only can be used with the log link\n",
      "     |          function.  See notes for details.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset values.  See notes for details.\n",
      "     |      linear : bool\n",
      "     |          If True, returns the linear predicted values.  If False,\n",
      "     |          returns the value of the inverse of the model's link function at\n",
      "     |          the linear predicted values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Any `exposure` and `offset` provided here take precedence over\n",
      "     |      the `exposure` and `offset` used in the model fit.  If `exog`\n",
      "     |      is passed as an argument here, then any `exposure` and\n",
      "     |      `offset` values in the fit will be ignored.\n",
      "     |      \n",
      "     |      Exposure values must be strictly positive.\n",
      "     |  \n",
      "     |  score(self, params, scale=None)\n",
      "     |      score, first derivative of the loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray_1d\n",
      "     |          The first derivative of the loglikelihood function calculated as\n",
      "     |          the sum of `score_obs`\n",
      "     |  \n",
      "     |  score_factor(self, params, scale=None)\n",
      "     |      weights for score for each observation\n",
      "     |      \n",
      "     |      This can be considered as score residuals.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which score is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_factor : ndarray_1d\n",
      "     |          A 1d weight vector used in the calculation of the score_obs.\n",
      "     |          The score_obs are obtained by `score_factor[:, None] * exog`\n",
      "     |  \n",
      "     |  score_obs(self, params, scale=None)\n",
      "     |      score first derivative of the loglikelihood for each observation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_obs : ndarray, 2d\n",
      "     |          The first derivative of the loglikelihood function evaluated at\n",
      "     |          params for each observation.\n",
      "     |  \n",
      "     |  score_test(self, params_constrained, k_constraints=None, exog_extra=None, observed=True)\n",
      "     |      score test for restrictions or for omitted variables\n",
      "     |      \n",
      "     |      The covariance matrix for the score is based on the Hessian, i.e.\n",
      "     |      observed information matrix or optionally on the expected information\n",
      "     |      matrix..\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params_constrained : array_like\n",
      "     |          estimated parameter of the restricted model. This can be the\n",
      "     |          parameter estimate for the current when testing for omitted\n",
      "     |          variables.\n",
      "     |      k_constraints : int or None\n",
      "     |          Number of constraints that were used in the estimation of params\n",
      "     |          restricted relative to the number of exog in the model.\n",
      "     |          This must be provided if no exog_extra are given. If exog_extra is\n",
      "     |          not None, then k_constraints is assumed to be zero if it is None.\n",
      "     |      exog_extra : None or array_like\n",
      "     |          Explanatory variables that are jointly tested for inclusion in the\n",
      "     |          model, i.e. omitted variables.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is used in calculating the\n",
      "     |          covariance matrix of the score. If false then the expected\n",
      "     |          information matrix is used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chi2_stat : float\n",
      "     |          chisquare statistic for the score test\n",
      "     |      p-value : float\n",
      "     |          P-value of the score test based on the chisquare distribution.\n",
      "     |      df : int\n",
      "     |          Degrees of freedom used in the p-value calculation. This is equal\n",
      "     |          to the number of constraints.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      not yet verified for case with scale not equal to 1.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class OLS(WLS)\n",
      "     |  OLS(endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      "     |  \n",
      "     |  Ordinary Least Squares\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  hasconst : None or bool\n",
      "     |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      "     |      a constant is not checked for and k_constant is set to 1 and all\n",
      "     |      result statistics are calculated as if a constant is present. If\n",
      "     |      False, a constant is not checked for and k_constant is set to 0.\n",
      "     |  **kwargs\n",
      "     |      Extra arguments that are used to set model properties when using the\n",
      "     |      formula interface.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  weights : scalar\n",
      "     |      Has an attribute weights = array(1.0) due to inheritance from WLS.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  WLS : Fit a linear model using Weighted Least Squares.\n",
      "     |  GLS : Fit a linear model using Generalized Least Squares.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  No constant is added by the model unless you are using formulas.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> duncan_prestige = sm.datasets.get_rdataset(\"Duncan\", \"carData\")\n",
      "     |  >>> Y = duncan_prestige.data['income']\n",
      "     |  >>> X = duncan_prestige.data['education']\n",
      "     |  >>> X = sm.add_constant(X)\n",
      "     |  >>> model = sm.OLS(Y,X)\n",
      "     |  >>> results = model.fit()\n",
      "     |  >>> results.params\n",
      "     |  const        10.603498\n",
      "     |  education     0.594859\n",
      "     |  dtype: float64\n",
      "     |  \n",
      "     |  >>> results.tvalues\n",
      "     |  const        2.039813\n",
      "     |  education    6.892802\n",
      "     |  dtype: float64\n",
      "     |  \n",
      "     |  >>> print(results.t_test([1, 0]))\n",
      "     |                               Test for Constraints\n",
      "     |  ==============================================================================\n",
      "     |                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "     |  ------------------------------------------------------------------------------\n",
      "     |  c0            10.6035      5.198      2.040      0.048       0.120      21.087\n",
      "     |  ==============================================================================\n",
      "     |  \n",
      "     |  >>> print(results.f_test(np.identity(2)))\n",
      "     |  <F test: F=array([[159.63031026]]), p=1.2607168903696672e-20, df_denom=43, df_num=2>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OLS\n",
      "     |      WLS\n",
      "     |      RegressionModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      "     |      Return a regularized fit to a linear regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str\n",
      "     |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      "     |      alpha : scalar or array_like\n",
      "     |          The penalty weight.  If a scalar, the same penalty weight\n",
      "     |          applies to all variables in the model.  If a vector, it\n",
      "     |          must have the same length as `params`, and contains a\n",
      "     |          penalty weight for each coefficient.\n",
      "     |      L1_wt : scalar\n",
      "     |          The fraction of the penalty given to the L1 penalty term.\n",
      "     |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      "     |          ridge fit, if 1 it is a lasso fit.\n",
      "     |      start_params : array_like\n",
      "     |          Starting values for ``params``.\n",
      "     |      profile_scale : bool\n",
      "     |          If True the penalized fit is computed using the profile\n",
      "     |          (concentrated) log-likelihood for the Gaussian model.\n",
      "     |          Otherwise the fit uses the residual sum of squares.\n",
      "     |      refit : bool\n",
      "     |          If True, the model is refit using only the variables that\n",
      "     |          have non-zero coefficients in the regularized fit.  The\n",
      "     |          refitted model is not regularized.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      statsmodels.base.elastic_net.RegularizedResults\n",
      "     |          The regularized results.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The elastic net uses a combination of L1 and L2 penalties.\n",
      "     |      The implementation closely follows the glmnet package in R.\n",
      "     |      \n",
      "     |      The function that is minimized is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      "     |      \n",
      "     |      where RSS is the usual regression sum of squares, n is the\n",
      "     |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      "     |      norms.\n",
      "     |      \n",
      "     |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      "     |      exog data.\n",
      "     |      \n",
      "     |      Post-estimation results are based on the same data used to\n",
      "     |      select variables, hence may be subject to overfitting biases.\n",
      "     |      \n",
      "     |      The elastic_net method uses the following keyword arguments:\n",
      "     |      \n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations\n",
      "     |      cnvrg_tol : float\n",
      "     |          Convergence threshold for line searches\n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The square root lasso approach is a variation of the Lasso\n",
      "     |      that is largely self-tuning (the optimal tuning parameter\n",
      "     |      does not depend on the standard deviation of the regression\n",
      "     |      errors).  If the errors are Gaussian, the tuning parameter\n",
      "     |      can be taken to be\n",
      "     |      \n",
      "     |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      "     |      \n",
      "     |      where n is the sample size and p is the number of predictors.\n",
      "     |      \n",
      "     |      The square root lasso uses the following keyword arguments:\n",
      "     |      \n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The cvxopt module is required to estimate model using the square root\n",
      "     |      lasso.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      "     |         generalized linear models via coordinate descent.  Journal of\n",
      "     |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      "     |      \n",
      "     |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      "     |         pivotal recovery of sparse signals via conic programming.\n",
      "     |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      "     |  \n",
      "     |  hessian(self, params, scale=None)\n",
      "     |      Evaluate the Hessian function at a given point.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameter vector at which the Hessian is computed.\n",
      "     |      scale : float or None\n",
      "     |          If None, return the profile (concentrated) log likelihood\n",
      "     |          (profiled over the scale parameter), else return the\n",
      "     |          log-likelihood using the given scale value.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The Hessian matrix.\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Calculate the weights for the Hessian.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameter at which Hessian is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      "     |  \n",
      "     |  loglike(self, params, scale=None)\n",
      "     |      The likelihood function for the OLS model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The coefficients with which to estimate the log-likelihood.\n",
      "     |      scale : float or None\n",
      "     |          If None, return the profile (concentrated) log likelihood\n",
      "     |          (profiled over the scale parameter), else return the\n",
      "     |          log-likelihood using the given scale value.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The likelihood function evaluated at params.\n",
      "     |  \n",
      "     |  score(self, params, scale=None)\n",
      "     |      Evaluate the score function at a given point.\n",
      "     |      \n",
      "     |      The score corresponds to the profile (concentrated)\n",
      "     |      log-likelihood in which the scale parameter has been profiled\n",
      "     |      out.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameter vector at which the score function is\n",
      "     |          computed.\n",
      "     |      scale : float or None\n",
      "     |          If None, return the profile (concentrated) log likelihood\n",
      "     |          (profiled over the scale parameter), else return the\n",
      "     |          log-likelihood using the given scale value.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector.\n",
      "     |  \n",
      "     |  whiten(self, x)\n",
      "     |      OLS model whitener does nothing.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          Data to be whitened.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          The input array unmodified.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      OLS : Fit a linear model using Ordinary Least Squares.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RegressionModel:\n",
      "     |  \n",
      "     |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      "     |      Full fit of the model.\n",
      "     |      \n",
      "     |      The results include an estimate of covariance matrix, (whitened)\n",
      "     |      residuals and an estimate of scale.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str, optional\n",
      "     |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      "     |          to solve the least squares problem. \"qr\" uses the QR\n",
      "     |          factorization.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `regression.linear_model.RegressionResults` for a description\n",
      "     |          of the available covariance estimators.\n",
      "     |      cov_kwds : list or None, optional\n",
      "     |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      "     |          description required keywords for alternative covariance\n",
      "     |          estimators.\n",
      "     |      use_t : bool, optional\n",
      "     |          Flag indicating to use the Student's t distribution when computing\n",
      "     |          p-values.  Default behavior depends on cov_type. See\n",
      "     |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      "     |          implementation details.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      RegressionResults\n",
      "     |          The model estimation results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      RegressionResults\n",
      "     |          The results container.\n",
      "     |      RegressionResults.get_robustcov_results\n",
      "     |          A method to change the covariance estimator used when fitting the\n",
      "     |          model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      "     |      to solve the least squares minimization.\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      "     |      Construct a random number generator for the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters (regression coefficients).\n",
      "     |      scale : scalar\n",
      "     |          The variance parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      dist_class : class\n",
      "     |          A random number generator class.  Must take 'loc' and 'scale'\n",
      "     |          as arguments and return a random number generator implementing\n",
      "     |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Frozen random number generator object with mean and variance\n",
      "     |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      "     |          to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      "     |      the returned random number generator must be called with\n",
      "     |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      "     |      the data set used to fit the model.  If any other value is\n",
      "     |      used for ``n``, misleading results will be produced.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize model components.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return linear predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a linear model.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Model exog is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          An array of fitted values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the model has not yet been fit, params is not optional.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RegressionModel:\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      "     |      constant is included.\n",
      "     |  \n",
      "     |  df_resid\n",
      "     |      The residual degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the number of observations minus the rank of\n",
      "     |      the regressor matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class OrdinalGEE(GEE)\n",
      "     |  OrdinalGEE(endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs)\n",
      "     |  \n",
      "     |  Ordinal Response Marginal Regression Model using GEE\n",
      "     |  \n",
      "     |  Marginal regression model fit using Generalized Estimating Equations.\n",
      "     |  \n",
      "     |  GEE can be used to fit Generalized Linear Models (GLMs) when the\n",
      "     |  data have a grouped structure, and the observations are possibly\n",
      "     |  correlated within groups but not between groups.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      1d array of endogenous values (i.e. responses, outcomes,\n",
      "     |      dependent variables, or 'Y' values).\n",
      "     |  exog : array_like\n",
      "     |      2d array of exogeneous values (i.e. covariates, predictors,\n",
      "     |      independent variables, regressors, or 'X' values). A `nobs x\n",
      "     |      k` array where `nobs` is the number of observations and `k` is\n",
      "     |      the number of regressors. An intercept is not included by\n",
      "     |      default and should be added by the user. See\n",
      "     |      `statsmodels.tools.add_constant`.\n",
      "     |  groups : array_like\n",
      "     |      A 1d array of length `nobs` containing the group labels.\n",
      "     |  time : array_like\n",
      "     |      A 2d array of time (or other index) values, used by some\n",
      "     |      dependence structures to define similarity relationships among\n",
      "     |      observations within a cluster.\n",
      "     |  family : family class instance\n",
      "     |      The only family supported is `Binomial`.  The default `Logit`\n",
      "     |      link may be replaced with `probit` if desired.\n",
      "     |  cov_struct : CovStruct class instance\n",
      "     |      The default is Independence.  To specify an exchangeable\n",
      "     |      structure use cov_struct = Exchangeable().  See\n",
      "     |      statsmodels.genmod.cov_struct.CovStruct for more\n",
      "     |      information.\n",
      "     |  offset : array_like\n",
      "     |      An offset to be included in the fit.  If provided, must be\n",
      "     |      an array whose length is the number of rows in exog.\n",
      "     |  dep_data : array_like\n",
      "     |      Additional data passed to the dependence structure.\n",
      "     |  constraint : (ndarray, ndarray)\n",
      "     |      If provided, the constraint is a tuple (L, R) such that the\n",
      "     |      model parameters are estimated under the constraint L *\n",
      "     |      param = R, where L is a q x p matrix and R is a\n",
      "     |      q-dimensional vector.  If constraint is provided, a score\n",
      "     |      test is performed to compare the constrained model to the\n",
      "     |      unconstrained model.\n",
      "     |  update_dep : bool\n",
      "     |      If true, the dependence parameters are optimized, otherwise\n",
      "     |      they are held fixed at their starting values.\n",
      "     |  weights : array_like\n",
      "     |      An array of case weights to use in the analysis.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.genmod.families.family\n",
      "     |  :ref:`families`\n",
      "     |  :ref:`links`\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Only the following combinations make sense for family and link ::\n",
      "     |  \n",
      "     |                 + ident log logit probit cloglog pow opow nbinom loglog logc\n",
      "     |    Gaussian     |   x    x                        x\n",
      "     |    inv Gaussian |   x    x                        x\n",
      "     |    binomial     |   x    x    x     x       x     x    x           x      x\n",
      "     |    Poisson      |   x    x                        x\n",
      "     |    neg binomial |   x    x                        x          x\n",
      "     |    gamma        |   x    x                        x\n",
      "     |  \n",
      "     |  Not all of these link functions are currently available.\n",
      "     |  \n",
      "     |  Endog and exog are references so that if the data they refer\n",
      "     |  to are already arrays and these arrays are changed, endog and\n",
      "     |  exog will change.\n",
      "     |  \n",
      "     |  The \"robust\" covariance type is the standard \"sandwich estimator\"\n",
      "     |  (e.g. Liang and Zeger (1986)).  It is the default here and in most\n",
      "     |  other packages.  The \"naive\" estimator gives smaller standard\n",
      "     |  errors, but is only correct if the working correlation structure\n",
      "     |  is correctly specified.  The \"bias reduced\" estimator of Mancl and\n",
      "     |  DeRouen (Biometrics, 2001) reduces the downward bias of the robust\n",
      "     |  estimator.\n",
      "     |  \n",
      "     |  The robust covariance provided here follows Liang and Zeger (1986)\n",
      "     |  and agrees with R's gee implementation.  To obtain the robust\n",
      "     |  standard errors reported in Stata, multiply by sqrt(N / (N - g)),\n",
      "     |  where N is the total sample size, and g is the average group size.\n",
      "     |  \n",
      "     |  The nominal and ordinal GEE models should not have an intercept\n",
      "     |  (either implicit or explicit).  Use \"0 + \" in a formula to\n",
      "     |  suppress the intercept.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  Fit an ordinal regression model using GEE, with \"global\n",
      "     |  odds ratio\" dependence:\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> gor = sm.cov_struct.GlobalOddsRatio(\"ordinal\")\n",
      "     |  >>> model = sm.OrdinalGEE(endog, exog, groups, cov_struct=gor)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Using formulas:\n",
      "     |  \n",
      "     |  >>> import statsmodels.formula.api as smf\n",
      "     |  >>> model = smf.ordinal_gee(\"y ~ 0 + x1 + x2\", groups, data,\n",
      "     |                                  cov_struct=gor)\n",
      "     |  >>> result = model.fit()\n",
      "     |  >>> print(result.summary())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OrdinalGEE\n",
      "     |      GEE\n",
      "     |      statsmodels.genmod.generalized_linear_model.GLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust')\n",
      "     |      Fits a marginal regression model using generalized estimating\n",
      "     |      equations (GEE).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxiter : int\n",
      "     |          The maximum number of iterations\n",
      "     |      ctol : float\n",
      "     |          The convergence criterion for stopping the Gauss-Seidel\n",
      "     |          iterations\n",
      "     |      start_params : array_like\n",
      "     |          A vector of starting values for the regression\n",
      "     |          coefficients.  If None, a default is chosen.\n",
      "     |      params_niter : int\n",
      "     |          The number of Gauss-Seidel updates of the mean structure\n",
      "     |          parameters that take place prior to each update of the\n",
      "     |          dependence structure.\n",
      "     |      first_dep_update : int\n",
      "     |          No dependence structure updates occur before this\n",
      "     |          iteration number.\n",
      "     |      cov_type : str\n",
      "     |          One of \"robust\", \"naive\", or \"bias_reduced\".\n",
      "     |      ddof_scale : scalar or None\n",
      "     |          The scale parameter is estimated as the sum of squared\n",
      "     |          Pearson residuals divided by `N - ddof_scale`, where N\n",
      "     |          is the total sample size.  If `ddof_scale` is None, the\n",
      "     |          number of covariates (including an intercept if present)\n",
      "     |          is used.\n",
      "     |      scaling_factor : scalar\n",
      "     |          The estimated covariance of the parameter estimates is\n",
      "     |          scaled by this value.  Default is 1, Stata uses N / (N - g),\n",
      "     |          where N is the total sample size and g is the average group\n",
      "     |          size.\n",
      "     |      scale : str or float, optional\n",
      "     |          `scale` can be None, 'X2', or a float\n",
      "     |          If a float, its value is used as the scale parameter.\n",
      "     |          The default value is None, which uses `X2` (Pearson's\n",
      "     |          chi-square) for Gamma, Gaussian, and Inverse Gaussian.\n",
      "     |          The default is 1 for the Binomial and Poisson families.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An instance of the GEEResults class or subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If convergence difficulties occur, increase the values of\n",
      "     |      `first_dep_update` and/or `params_niter`.  Setting\n",
      "     |      `first_dep_update` to a greater value (e.g. ~10-20) causes the\n",
      "     |      algorithm to move close to the GLM solution before attempting\n",
      "     |      to identify the dependence structure.\n",
      "     |      \n",
      "     |      For the Gaussian family, there is no benefit to setting\n",
      "     |      `params_niter` to a value greater than 1, since the mean\n",
      "     |      structure parameters converge in one step.\n",
      "     |  \n",
      "     |  setup_ordinal(self, endog, exog, groups, time, offset)\n",
      "     |      Restructure ordinal data as binary indicators so that they can\n",
      "     |      be analyzed using Generalized Estimating Equations.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GEE:\n",
      "     |  \n",
      "     |  cluster_list(self, array)\n",
      "     |      Returns `array` split into subarrays corresponding to the\n",
      "     |      cluster structure.\n",
      "     |  \n",
      "     |  compare_score_test(self, submodel)\n",
      "     |      Perform a score test for the given submodel against this model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      submodel : GEEResults instance\n",
      "     |          A fitted GEE model that is a submodel of this model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A dictionary with keys \"statistic\", \"p-value\", and \"df\",\n",
      "     |      containing the score test statistic, its chi^2 p-value,\n",
      "     |      and the degrees of freedom used to compute the p-value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The score test can be performed without calling 'fit' on the\n",
      "     |      larger model.  The provided submodel must be obtained from a\n",
      "     |      fitted GEE.\n",
      "     |      \n",
      "     |      This method performs the same score test as can be obtained by\n",
      "     |      fitting the GEE with a linear constraint and calling `score_test`\n",
      "     |      on the results.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Xu Guo and Wei Pan (2002). \"Small sample performance of the score\n",
      "     |      test in GEE\".\n",
      "     |      http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\n",
      "     |  \n",
      "     |  estimate_scale(self)\n",
      "     |      Estimate the dispersion/scale.\n",
      "     |  \n",
      "     |  fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None)\n",
      "     |      Regularized estimation for GEE.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pen_wt : float\n",
      "     |          The penalty weight (a non-negative scalar).\n",
      "     |      scad_param : float\n",
      "     |          Non-negative scalar determining the shape of the Scad\n",
      "     |          penalty.\n",
      "     |      maxiter : int\n",
      "     |          The maximum number of iterations.\n",
      "     |      ddof_scale : int\n",
      "     |          Value to subtract from `nobs` when calculating the\n",
      "     |          denominator degrees of freedom for t-statistics, defaults\n",
      "     |          to the number of columns in `exog`.\n",
      "     |      update_assoc : int\n",
      "     |          The dependence parameters are updated every `update_assoc`\n",
      "     |          iterations of the mean structure parameter updates.\n",
      "     |      ctol : float\n",
      "     |          Convergence criterion, default is one order of magnitude\n",
      "     |          smaller than proposed in section 3.1 of Wang et al.\n",
      "     |      ztol : float\n",
      "     |          Coefficients smaller than this value are treated as\n",
      "     |          being zero, default is based on section 5 of Wang et al.\n",
      "     |      eps : non-negative scalar\n",
      "     |          Numerical constant, see section 3.2 of Wang et al.\n",
      "     |      scale : float or string\n",
      "     |          If a float, this value is used as the scale parameter.\n",
      "     |          If \"X2\", the scale parameter is always estimated using\n",
      "     |          Pearson's chi-square method (e.g. as in a quasi-Poisson\n",
      "     |          analysis).  If None, the default approach for the family\n",
      "     |          is used to estimate the scale parameter.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      GEEResults instance.  Note that not all methods of the results\n",
      "     |      class make sense when the model has been fit with regularization.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This implementation assumes that the link is canonical.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\n",
      "     |      equations for high-dimensional longitudinal data analysis.\n",
      "     |      Biometrics. 2012 Jun;68(2):353-60.\n",
      "     |      doi: 10.1111/j.1541-0420.2011.01678.x.\n",
      "     |      https://www.ncbi.nlm.nih.gov/pubmed/21955051\n",
      "     |      http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\n",
      "     |  \n",
      "     |  mean_deriv(self, exog, lin_pred)\n",
      "     |      Derivative of the expected endog with respect to the parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array_like\n",
      "     |         The exogeneous data at which the derivative is computed.\n",
      "     |      lin_pred : array_like\n",
      "     |         The values of the linear predictor.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The value of the derivative of the expected endog with respect\n",
      "     |      to the parameter vector.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If there is an offset or exposure, it should be added to\n",
      "     |      `lin_pred` prior to calling this function.\n",
      "     |  \n",
      "     |  mean_deriv_exog(self, exog, params, offset_exposure=None)\n",
      "     |      Derivative of the expected endog with respect to exog.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array_like\n",
      "     |          Values of the independent variables at which the derivative\n",
      "     |          is calculated.\n",
      "     |      params : array_like\n",
      "     |          Parameter values at which the derivative is calculated.\n",
      "     |      offset_exposure : array_like, optional\n",
      "     |          Combined offset and exposure.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The derivative of the expected endog with respect to exog.\n",
      "     |  \n",
      "     |  qic(self, params, scale, cov_params, n_step=1000)\n",
      "     |      Returns quasi-information criteria and quasi-likelihood values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The GEE estimates of the regression parameters.\n",
      "     |      scale : scalar\n",
      "     |          Estimated scale parameter\n",
      "     |      cov_params : array_like\n",
      "     |          An estimate of the covariance matrix for the\n",
      "     |          model parameters.  Conventionally this is the robust\n",
      "     |          covariance matrix.\n",
      "     |      n_step : integer\n",
      "     |          The number of points in the trapezoidal approximation\n",
      "     |          to the quasi-likelihood function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ql : scalar\n",
      "     |          The quasi-likelihood value\n",
      "     |      qic : scalar\n",
      "     |          A QIC that can be used to compare the mean and covariance\n",
      "     |          structures of the model.\n",
      "     |      qicu : scalar\n",
      "     |          A simplified QIC that can be used to compare mean structures\n",
      "     |          but not covariance structures\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The quasi-likelihood used here is obtained by numerically evaluating\n",
      "     |      Wedderburn's integral representation of the quasi-likelihood function.\n",
      "     |      This approach is valid for all families and  links.  Many other\n",
      "     |      packages use analytical expressions for quasi-likelihoods that are\n",
      "     |      valid in special cases where the link function is canonical.  These\n",
      "     |      analytical expressions may omit additive constants that only depend\n",
      "     |      on the data.  Therefore, the numerical values of our QL and QIC values\n",
      "     |      will differ from the values reported by other packages.  However only\n",
      "     |      the differences between two QIC values calculated for different models\n",
      "     |      using the same data are meaningful.  Our QIC should produce the same\n",
      "     |      QIC differences as other software.\n",
      "     |      \n",
      "     |      When using the QIC for models with unknown scale parameter, use a\n",
      "     |      common estimate of the scale parameter for all models being compared.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] W. Pan (2001).  Akaike's information criterion in generalized\n",
      "     |             estimating equations.  Biometrics (57) 1.\n",
      "     |  \n",
      "     |  update_cached_means(self, mean_params)\n",
      "     |      cached_means should always contain the most recent calculation\n",
      "     |      of the group-wise mean vectors.  This function should be\n",
      "     |      called every time the regression parameters are changed, to\n",
      "     |      keep the cached means up to date.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from GEE:\n",
      "     |  \n",
      "     |  from_formula(formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from GEE:\n",
      "     |  \n",
      "     |  cached_means = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.genmod.generalized_linear_model.GLM:\n",
      "     |  \n",
      "     |  estimate_tweedie_power(self, mu, method='brentq', low=1.01, high=5.0)\n",
      "     |      Tweedie specific function to estimate scale and the variance parameter.\n",
      "     |      The variance parameter is also referred to as p, xi, or shape.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : array_like\n",
      "     |          Fitted mean response variable\n",
      "     |      method : str, defaults to 'brentq'\n",
      "     |          Scipy optimizer used to solve the Pearson equation. Only brentq\n",
      "     |          currently supported.\n",
      "     |      low : float, optional\n",
      "     |          Low end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 1.01.\n",
      "     |      high : float, optional\n",
      "     |          High end of the bracketing interval [a,b] to be used in the search\n",
      "     |          for the power. Defaults to 5.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      power : float\n",
      "     |          The estimated shape or power.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      fit the model subject to linear equality constraints\n",
      "     |      \n",
      "     |      The constraints are of the form   `R params = q`\n",
      "     |      where R is the constraint_matrix and q is the vector of\n",
      "     |      constraint_values.\n",
      "     |      \n",
      "     |      The estimation creates a new model with transformed design matrix,\n",
      "     |      exog, and converts the results back to the original parameterization.\n",
      "     |      \n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : formula expression or tuple\n",
      "     |          If it is a tuple, then the constraint needs to be given by two\n",
      "     |          arrays (constraint_matrix, constraint_value), i.e. (R, q).\n",
      "     |          Otherwise, the constraints can be given as strings or list of\n",
      "     |          strings.\n",
      "     |          see t_test for details\n",
      "     |      start_params : None or array_like\n",
      "     |          starting values for the optimization. `start_params` needs to be\n",
      "     |          given in the original parameter space and are internally\n",
      "     |          transformed.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the transformed model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale=None, exog=None, exposure=None, offset=None, var_weights=1.0, n_trials=1.0)\n",
      "     |      Return a instance of the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters.\n",
      "     |      scale : scalar\n",
      "     |          The scale parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      offset : array_like or None\n",
      "     |          Offset variable for predicted mean.\n",
      "     |      exposure : array_like or None\n",
      "     |          Log(exposure) will be added to the linear prediction.\n",
      "     |      var_weights : array_like\n",
      "     |          1d array of variance (analytic) weights. The default is None.\n",
      "     |      n_trials : int\n",
      "     |          Number of trials for the binomial distribution. The default is 1\n",
      "     |          which corresponds to a Bernoulli random variable.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Instance of a scipy frozen distribution based on estimated\n",
      "     |          parameters.\n",
      "     |          Use the ``rvs`` method to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``, the\n",
      "     |      returned random number generator must be called with ``gen.rvs(n)``\n",
      "     |      where ``n`` is the number of observations in the data set used\n",
      "     |      to fit the model.  If any other value is used for ``n``, misleading\n",
      "     |      results will be produced.\n",
      "     |  \n",
      "     |  hessian(self, params, scale=None, observed=None)\n",
      "     |      Hessian, second derivative of loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned (default).\n",
      "     |          If False, then the expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian, i.e. observed information, or expected information matrix.\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Weights for calculating Hessian\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian_factor : ndarray, 1d\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      "     |  \n",
      "     |  information(self, params, scale=None)\n",
      "     |      Fisher information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize a generalized linear model.\n",
      "     |  \n",
      "     |  loglike(self, params, scale=None)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  loglike_mu(self, mu, scale=1.0)\n",
      "     |      Evaluate the log-likelihood for a generalized linear model.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, linear=False)\n",
      "     |      Return predicted values for a design matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters / coefficients of a GLM.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Is exog is None, model exog is used.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Exposure time values, only can be used with the log link\n",
      "     |          function.  See notes for details.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset values.  See notes for details.\n",
      "     |      linear : bool\n",
      "     |          If True, returns the linear predicted values.  If False,\n",
      "     |          returns the value of the inverse of the model's link function at\n",
      "     |          the linear predicted values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Any `exposure` and `offset` provided here take precedence over\n",
      "     |      the `exposure` and `offset` used in the model fit.  If `exog`\n",
      "     |      is passed as an argument here, then any `exposure` and\n",
      "     |      `offset` values in the fit will be ignored.\n",
      "     |      \n",
      "     |      Exposure values must be strictly positive.\n",
      "     |  \n",
      "     |  score(self, params, scale=None)\n",
      "     |      score, first derivative of the loglikelihood function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray_1d\n",
      "     |          The first derivative of the loglikelihood function calculated as\n",
      "     |          the sum of `score_obs`\n",
      "     |  \n",
      "     |  score_factor(self, params, scale=None)\n",
      "     |      weights for score for each observation\n",
      "     |      \n",
      "     |      This can be considered as score residuals.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which score is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_factor : ndarray_1d\n",
      "     |          A 1d weight vector used in the calculation of the score_obs.\n",
      "     |          The score_obs are obtained by `score_factor[:, None] * exog`\n",
      "     |  \n",
      "     |  score_obs(self, params, scale=None)\n",
      "     |      score first derivative of the loglikelihood for each observation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter at which score is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_obs : ndarray, 2d\n",
      "     |          The first derivative of the loglikelihood function evaluated at\n",
      "     |          params for each observation.\n",
      "     |  \n",
      "     |  score_test(self, params_constrained, k_constraints=None, exog_extra=None, observed=True)\n",
      "     |      score test for restrictions or for omitted variables\n",
      "     |      \n",
      "     |      The covariance matrix for the score is based on the Hessian, i.e.\n",
      "     |      observed information matrix or optionally on the expected information\n",
      "     |      matrix..\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params_constrained : array_like\n",
      "     |          estimated parameter of the restricted model. This can be the\n",
      "     |          parameter estimate for the current when testing for omitted\n",
      "     |          variables.\n",
      "     |      k_constraints : int or None\n",
      "     |          Number of constraints that were used in the estimation of params\n",
      "     |          restricted relative to the number of exog in the model.\n",
      "     |          This must be provided if no exog_extra are given. If exog_extra is\n",
      "     |          not None, then k_constraints is assumed to be zero if it is None.\n",
      "     |      exog_extra : None or array_like\n",
      "     |          Explanatory variables that are jointly tested for inclusion in the\n",
      "     |          model, i.e. omitted variables.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is used in calculating the\n",
      "     |          covariance matrix of the score. If false then the expected\n",
      "     |          information matrix is used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      chi2_stat : float\n",
      "     |          chisquare statistic for the score test\n",
      "     |      p-value : float\n",
      "     |          P-value of the score test based on the chisquare distribution.\n",
      "     |      df : int\n",
      "     |          Degrees of freedom used in the p-value calculation. This is equal\n",
      "     |          to the number of constraints.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      not yet verified for case with scale not equal to 1.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class PCA(builtins.object)\n",
      "     |  PCA(data, ncomp=None, standardize=True, demean=True, normalize=True, gls=False, weights=None, method='svd', missing=None, tol=5e-08, max_iter=1000, tol_em=5e-08, max_em_iter=100, svd_full_matrices=False)\n",
      "     |  \n",
      "     |  Principal Component Analysis\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : array_like\n",
      "     |      Variables in columns, observations in rows.\n",
      "     |  ncomp : int, optional\n",
      "     |      Number of components to return.  If None, returns the as many as the\n",
      "     |      smaller of the number of rows or columns in data.\n",
      "     |  standardize : bool, optional\n",
      "     |      Flag indicating to use standardized data with mean 0 and unit\n",
      "     |      variance.  standardized being True implies demean.  Using standardized\n",
      "     |      data is equivalent to computing principal components from the\n",
      "     |      correlation matrix of data.\n",
      "     |  demean : bool, optional\n",
      "     |      Flag indicating whether to demean data before computing principal\n",
      "     |      components.  demean is ignored if standardize is True. Demeaning data\n",
      "     |      but not standardizing is equivalent to computing principal components\n",
      "     |      from the covariance matrix of data.\n",
      "     |  normalize : bool , optional\n",
      "     |      Indicates whether to normalize the factors to have unit inner product.\n",
      "     |      If False, the loadings will have unit inner product.\n",
      "     |  gls : bool, optional\n",
      "     |      Flag indicating to implement a two-step GLS estimator where\n",
      "     |      in the first step principal components are used to estimate residuals,\n",
      "     |      and then the inverse residual variance is used as a set of weights to\n",
      "     |      estimate the final principal components.  Setting gls to True requires\n",
      "     |      ncomp to be less then the min of the number of rows or columns.\n",
      "     |  weights : ndarray, optional\n",
      "     |      Series weights to use after transforming data according to standardize\n",
      "     |      or demean when computing the principal components.\n",
      "     |  method : str, optional\n",
      "     |      Sets the linear algebra routine used to compute eigenvectors:\n",
      "     |  \n",
      "     |      * 'svd' uses a singular value decomposition (default).\n",
      "     |      * 'eig' uses an eigenvalue decomposition of a quadratic form\n",
      "     |      * 'nipals' uses the NIPALS algorithm and can be faster than SVD when\n",
      "     |        ncomp is small and nvars is large. See notes about additional changes\n",
      "     |        when using NIPALS.\n",
      "     |  missing : {str, None}\n",
      "     |      Method for missing data.  Choices are:\n",
      "     |  \n",
      "     |      * 'drop-row' - drop rows with missing values.\n",
      "     |      * 'drop-col' - drop columns with missing values.\n",
      "     |      * 'drop-min' - drop either rows or columns, choosing by data retention.\n",
      "     |      * 'fill-em' - use EM algorithm to fill missing value.  ncomp should be\n",
      "     |        set to the number of factors required.\n",
      "     |      * `None` raises if data contains NaN values.\n",
      "     |  tol : float, optional\n",
      "     |      Tolerance to use when checking for convergence when using NIPALS.\n",
      "     |  max_iter : int, optional\n",
      "     |      Maximum iterations when using NIPALS.\n",
      "     |  tol_em : float\n",
      "     |      Tolerance to use when checking for convergence of the EM algorithm.\n",
      "     |  max_em_iter : int\n",
      "     |      Maximum iterations for the EM algorithm.\n",
      "     |  svd_full_matrices : bool, optional\n",
      "     |      If the 'svd' method is selected, this flag is used to set the parameter\n",
      "     |      'full_matrices' in the singular value decomposition method. Is set to\n",
      "     |      False by default.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  factors : array or DataFrame\n",
      "     |      nobs by ncomp array of principal components (scores)\n",
      "     |  scores :  array or DataFrame\n",
      "     |      nobs by ncomp array of principal components - identical to factors\n",
      "     |  loadings : array or DataFrame\n",
      "     |      ncomp by nvar array of principal component loadings for constructing\n",
      "     |      the factors\n",
      "     |  coeff : array or DataFrame\n",
      "     |      nvar by ncomp array of principal component loadings for constructing\n",
      "     |      the projections\n",
      "     |  projection : array or DataFrame\n",
      "     |      nobs by var array containing the projection of the data onto the ncomp\n",
      "     |      estimated factors\n",
      "     |  rsquare : array or Series\n",
      "     |      ncomp array where the element in the ith position is the R-square\n",
      "     |      of including the fist i principal components.  Note: values are\n",
      "     |      calculated on the transformed data, not the original data\n",
      "     |  ic : array or DataFrame\n",
      "     |      ncomp by 3 array containing the Bai and Ng (2003) Information\n",
      "     |      criteria.  Each column is a different criteria, and each row\n",
      "     |      represents the number of included factors.\n",
      "     |  eigenvals : array or Series\n",
      "     |      nvar array of eigenvalues\n",
      "     |  eigenvecs : array or DataFrame\n",
      "     |      nvar by nvar array of eigenvectors\n",
      "     |  weights : ndarray\n",
      "     |      nvar array of weights used to compute the principal components,\n",
      "     |      normalized to unit length\n",
      "     |  transformed_data : ndarray\n",
      "     |      Standardized, demeaned and weighted data used to compute\n",
      "     |      principal components and related quantities\n",
      "     |  cols : ndarray\n",
      "     |      Array of indices indicating columns used in the PCA\n",
      "     |  rows : ndarray\n",
      "     |      Array of indices indicating rows used in the PCA\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The default options perform principal component analysis on the\n",
      "     |  demeaned, unit variance version of data.  Setting standardize to False\n",
      "     |  will instead only demean, and setting both standardized and\n",
      "     |  demean to False will not alter the data.\n",
      "     |  \n",
      "     |  Once the data have been transformed, the following relationships hold when\n",
      "     |  the number of components (ncomp) is the same as tne minimum of the number\n",
      "     |  of observation or the number of variables.\n",
      "     |  \n",
      "     |  .. math:\n",
      "     |  \n",
      "     |      X' X = V \\Lambda V'\n",
      "     |  \n",
      "     |  .. math:\n",
      "     |  \n",
      "     |      F = X V\n",
      "     |  \n",
      "     |  .. math:\n",
      "     |  \n",
      "     |      X = F V'\n",
      "     |  \n",
      "     |  where X is the `data`, F is the array of principal components (`factors`\n",
      "     |  or `scores`), and V is the array of eigenvectors (`loadings`) and V' is\n",
      "     |  the array of factor coefficients (`coeff`).\n",
      "     |  \n",
      "     |  When weights are provided, the principal components are computed from the\n",
      "     |  modified data\n",
      "     |  \n",
      "     |  .. math:\n",
      "     |  \n",
      "     |      \\Omega^{-\\frac{1}{2}} X\n",
      "     |  \n",
      "     |  where :math:`\\Omega` is a diagonal matrix composed of the weights. For\n",
      "     |  example, when using the GLS version of PCA, the elements of :math:`\\Omega`\n",
      "     |  will be the inverse of the variances of the residuals from\n",
      "     |  \n",
      "     |  .. math:\n",
      "     |  \n",
      "     |      X - F V'\n",
      "     |  \n",
      "     |  where the number of factors is less than the rank of X\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [*] J. Bai and S. Ng, \"Determining the number of factors in approximate\n",
      "     |     factor models,\" Econometrica, vol. 70, number 1, pp. 191-221, 2002\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Basic PCA using the correlation matrix of the data\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from statsmodels.multivariate.pca import PCA\n",
      "     |  >>> x = np.random.randn(100)[:, None]\n",
      "     |  >>> x = x + np.random.randn(100, 100)\n",
      "     |  >>> pc = PCA(x)\n",
      "     |  \n",
      "     |  Note that the principal components are computed using a SVD and so the\n",
      "     |  correlation matrix is never constructed, unless method='eig'.\n",
      "     |  \n",
      "     |  PCA using the covariance matrix of the data\n",
      "     |  \n",
      "     |  >>> pc = PCA(x, standardize=False)\n",
      "     |  \n",
      "     |  Limiting the number of factors returned to 1 computed using NIPALS\n",
      "     |  \n",
      "     |  >>> pc = PCA(x, ncomp=1, method='nipals')\n",
      "     |  >>> pc.factors.shape\n",
      "     |  (100, 1)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data, ncomp=None, standardize=True, demean=True, normalize=True, gls=False, weights=None, method='svd', missing=None, tol=5e-08, max_iter=1000, tol_em=5e-08, max_em_iter=100, svd_full_matrices=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  plot_rsquare(self, ncomp=None, ax=None)\n",
      "     |      Box plots of the individual series R-square against the number of PCs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ncomp : int, optional\n",
      "     |          Number of components ot include in the plot.  If None, will\n",
      "     |          plot the minimum of 10 or the number of computed components.\n",
      "     |      ax : AxesSubplot, optional\n",
      "     |          An axes on which to draw the graph.  If omitted, new a figure\n",
      "     |          is created.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      matplotlib.figure.Figure\n",
      "     |          The handle to the figure.\n",
      "     |  \n",
      "     |  plot_scree(self, ncomp=None, log_scale=True, cumulative=False, ax=None)\n",
      "     |      Plot of the ordered eigenvalues\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ncomp : int, optional\n",
      "     |          Number of components ot include in the plot.  If None, will\n",
      "     |          included the same as the number of components computed\n",
      "     |      log_scale : boot, optional\n",
      "     |          Flag indicating whether ot use a log scale for the y-axis\n",
      "     |      cumulative : bool, optional\n",
      "     |          Flag indicating whether to plot the eigenvalues or cumulative\n",
      "     |          eigenvalues\n",
      "     |      ax : AxesSubplot, optional\n",
      "     |          An axes on which to draw the graph.  If omitted, new a figure\n",
      "     |          is created\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      matplotlib.figure.Figure\n",
      "     |          The handle to the figure.\n",
      "     |  \n",
      "     |  project(self, ncomp=None, transform=True, unweight=True)\n",
      "     |      Project series onto a specific number of factors.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ncomp : int, optional\n",
      "     |          Number of components to use.  If omitted, all components\n",
      "     |          initially computed are used.\n",
      "     |      transform : bool, optional\n",
      "     |          Flag indicating whether to return the projection in the original\n",
      "     |          space of the data (True, default) or in the space of the\n",
      "     |          standardized/demeaned data.\n",
      "     |      unweight : bool, optional\n",
      "     |          Flag indicating whether to undo the effects of the estimation\n",
      "     |          weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          The nobs by nvar array of the projection onto ncomp factors.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class PHReg(statsmodels.base.model.LikelihoodModel)\n",
      "     |  PHReg(endog, exog, status=None, entry=None, strata=None, offset=None, ties='breslow', missing='drop', **kwargs)\n",
      "     |  \n",
      "     |  Cox Proportional Hazards Regression Model\n",
      "     |  \n",
      "     |  The Cox PH Model is for right censored data.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The observed times (event or censoring)\n",
      "     |  exog : 2D array_like\n",
      "     |      The covariates or exogeneous variables\n",
      "     |  status : array_like\n",
      "     |      The censoring status values; status=1 indicates that an\n",
      "     |      event occurred (e.g. failure or death), status=0 indicates\n",
      "     |      that the observation was right censored. If None, defaults\n",
      "     |      to status=1 for all cases.\n",
      "     |  entry : array_like\n",
      "     |      The entry times, if left truncation occurs\n",
      "     |  strata : array_like\n",
      "     |      Stratum labels.  If None, all observations are taken to be\n",
      "     |      in a single stratum.\n",
      "     |  ties : str\n",
      "     |      The method used to handle tied times, must be either 'breslow'\n",
      "     |      or 'efron'.\n",
      "     |  offset : array_like\n",
      "     |      Array of offset values\n",
      "     |  missing : str\n",
      "     |      The method used to handle missing data\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Proportional hazards regression models should not include an\n",
      "     |  explicit or implicit intercept.  The effect of an intercept is\n",
      "     |  not identified using the partial likelihood approach.\n",
      "     |  \n",
      "     |  `endog`, `event`, `strata`, `entry`, and the first dimension\n",
      "     |  of `exog` all must have the same length\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PHReg\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, status=None, entry=None, strata=None, offset=None, ties='breslow', missing='drop', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  baseline_cumulative_hazard(self, params)\n",
      "     |      Estimate the baseline cumulative hazard and survival\n",
      "     |      functions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A list of triples (time, hazard, survival) containing the time\n",
      "     |      values and corresponding cumulative hazard and survival\n",
      "     |      function values for each stratum.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Uses the Nelson-Aalen estimator.\n",
      "     |  \n",
      "     |  baseline_cumulative_hazard_function(self, params)\n",
      "     |      Returns a function that calculates the baseline cumulative\n",
      "     |      hazard function for each stratum.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A dict mapping stratum names to the estimated baseline\n",
      "     |      cumulative hazard function.\n",
      "     |  \n",
      "     |  breslow_gradient(self, params)\n",
      "     |      Returns the gradient of the log partial likelihood, using the\n",
      "     |      Breslow method to handle tied times.\n",
      "     |  \n",
      "     |  breslow_hessian(self, params)\n",
      "     |      Returns the Hessian of the log partial likelihood evaluated at\n",
      "     |      `params`, using the Breslow method to handle tied times.\n",
      "     |  \n",
      "     |  breslow_loglike(self, params)\n",
      "     |      Returns the value of the log partial likelihood function\n",
      "     |      evaluated at `params`, using the Breslow method to handle tied\n",
      "     |      times.\n",
      "     |  \n",
      "     |  efron_gradient(self, params)\n",
      "     |      Returns the gradient of the log partial likelihood evaluated\n",
      "     |      at `params`, using the Efron method to handle tied times.\n",
      "     |  \n",
      "     |  efron_hessian(self, params)\n",
      "     |      Returns the Hessian matrix of the partial log-likelihood\n",
      "     |      evaluated at `params`, using the Efron method to handle tied\n",
      "     |      times.\n",
      "     |  \n",
      "     |  efron_loglike(self, params)\n",
      "     |      Returns the value of the log partial likelihood function\n",
      "     |      evaluated at `params`, using the Efron method to handle tied\n",
      "     |      times.\n",
      "     |  \n",
      "     |  fit(self, groups=None, **args)\n",
      "     |      Fit a proportional hazards regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      groups : array_like\n",
      "     |          Labels indicating groups of observations that may be\n",
      "     |          dependent.  If present, the standard errors account for\n",
      "     |          this dependence. Does not affect fitted values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      PHRegResults\n",
      "     |          Returns a results instance.\n",
      "     |  \n",
      "     |  fit_regularized(self, method='elastic_net', alpha=0.0, start_params=None, refit=False, **kwargs)\n",
      "     |      Return a regularized fit to a linear regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'elastic_net'}\n",
      "     |          Only the `elastic_net` approach is currently implemented.\n",
      "     |      alpha : scalar or array_like\n",
      "     |          The penalty weight.  If a scalar, the same penalty weight\n",
      "     |          applies to all variables in the model.  If a vector, it\n",
      "     |          must have the same length as `params`, and contains a\n",
      "     |          penalty weight for each coefficient.\n",
      "     |      start_params : array_like\n",
      "     |          Starting values for `params`.\n",
      "     |      refit : bool\n",
      "     |          If True, the model is refit using only the variables that\n",
      "     |          have non-zero coefficients in the regularized fit.  The\n",
      "     |          refitted model is not regularized.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used to fit the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      PHRegResults\n",
      "     |          Returns a results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The penalty is the ``elastic net`` penalty, which is a\n",
      "     |      combination of L1 and L2 penalties.\n",
      "     |      \n",
      "     |      The function that is minimized is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          -loglike/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      "     |      \n",
      "     |      where :math:`|*|_1` and :math:`|*|_2` are the L1 and L2 norms.\n",
      "     |      \n",
      "     |      Post-estimation results are based on the same data used to\n",
      "     |      select variables, hence may be subject to overfitting biases.\n",
      "     |      \n",
      "     |      The elastic_net method uses the following keyword arguments:\n",
      "     |      \n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations\n",
      "     |      L1_wt  : float\n",
      "     |          Must be in [0, 1].  The L1 penalty has weight L1_wt and the\n",
      "     |          L2 penalty has weight 1 - L1_wt.\n",
      "     |      cnvrg_tol : float\n",
      "     |          Convergence threshold for line searches\n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale=1.0, exog=None)\n",
      "     |      Returns a scipy distribution object corresponding to the\n",
      "     |      distribution of uncensored endog (duration) values for each\n",
      "     |      case.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The proportional hazards model parameters.\n",
      "     |      scale : float\n",
      "     |          Present for compatibility, not used.\n",
      "     |      exog : array_like\n",
      "     |          A design matrix, defaults to model.exog.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A list of objects of type scipy.stats.distributions.rv_discrete\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The distributions are obtained from a simple discrete estimate\n",
      "     |      of the survivor function that puts all mass on the observed\n",
      "     |      failure times within a stratum.\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Returns the Hessian matrix of the log partial likelihood\n",
      "     |      function evaluated at `params`.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Returns the log partial likelihood function evaluated at\n",
      "     |      `params`.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, cov_params=None, endog=None, strata=None, offset=None, pred_type='lhr', pred_only=False)\n",
      "     |      Returns predicted values from the proportional hazards\n",
      "     |      regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The proportional hazards model parameters.\n",
      "     |      exog : array_like\n",
      "     |          Data to use as `exog` in forming predictions.  If not\n",
      "     |          provided, the `exog` values from the model used to fit the\n",
      "     |          data are used.\n",
      "     |      cov_params : array_like\n",
      "     |          The covariance matrix of the estimated `params` vector,\n",
      "     |          used to obtain prediction errors if pred_type='lhr',\n",
      "     |          otherwise optional.\n",
      "     |      endog : array_like\n",
      "     |          Duration (time) values at which the predictions are made.\n",
      "     |          Only used if pred_type is either 'cumhaz' or 'surv'.  If\n",
      "     |          using model `exog`, defaults to model `endog` (time), but\n",
      "     |          may be provided explicitly to make predictions at\n",
      "     |          alternative times.\n",
      "     |      strata : array_like\n",
      "     |          A vector of stratum values used to form the predictions.\n",
      "     |          Not used (may be 'None') if pred_type is 'lhr' or 'hr'.\n",
      "     |          If `exog` is None, the model stratum values are used.  If\n",
      "     |          `exog` is not None and pred_type is 'surv' or 'cumhaz',\n",
      "     |          stratum values must be provided (unless there is only one\n",
      "     |          stratum).\n",
      "     |      offset : array_like\n",
      "     |          Offset values used to create the predicted values.\n",
      "     |      pred_type : str\n",
      "     |          If 'lhr', returns log hazard ratios, if 'hr' returns\n",
      "     |          hazard ratios, if 'surv' returns the survival function, if\n",
      "     |          'cumhaz' returns the cumulative hazard function.\n",
      "     |      pred_only : bool\n",
      "     |          If True, returns only an array of predicted values.  Otherwise\n",
      "     |          returns a bunch containing the predicted values and standard\n",
      "     |          errors.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A bunch containing two fields: `predicted_values` and\n",
      "     |      `standard_errors`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Standard errors are only returned when predicting the log\n",
      "     |      hazard ratio (pred_type is 'lhr').\n",
      "     |      \n",
      "     |      Types `surv` and `cumhaz` require estimation of the cumulative\n",
      "     |      hazard function.\n",
      "     |  \n",
      "     |  robust_covariance(self, params)\n",
      "     |      Returns a covariance matrix for the proportional hazards model\n",
      "     |      regresion coefficient estimates that is robust to certain\n",
      "     |      forms of model misspecification.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameter vector at which the covariance matrix is\n",
      "     |          calculated.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The robust covariance matrix as a square ndarray.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This function uses the `groups` argument to determine groups\n",
      "     |      within which observations may be dependent.  The covariance\n",
      "     |      matrix is calculated using the Huber-White \"sandwich\" approach.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Returns the score function evaluated at `params`.\n",
      "     |  \n",
      "     |  score_residuals(self, params)\n",
      "     |      Returns the score residuals calculated at a given vector of\n",
      "     |      parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameter vector at which the score residuals are\n",
      "     |          calculated.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The score residuals, returned as a ndarray having the same\n",
      "     |      shape as `exog`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Observations in a stratum with no observed events have undefined\n",
      "     |      score residuals, and contain NaN in the returned matrix.\n",
      "     |  \n",
      "     |  weighted_covariate_averages(self, params)\n",
      "     |      Returns the hazard-weighted average of covariate values for\n",
      "     |      subjects who are at-risk at a particular time.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameter vector\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      averages : list of ndarrays\n",
      "     |          averages[stx][i,:] is a row vector containing the weighted\n",
      "     |          average values (for all the covariates) of at-risk\n",
      "     |          subjects a the i^th largest observed failure time in\n",
      "     |          stratum `stx`, using the hazard multipliers as weights.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Used to calculate leverages and score residuals.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, data, status=None, entry=None, strata=None, offset=None, subset=None, ties='breslow', missing='drop', *args, **kwargs) from builtins.type\n",
      "     |      Create a proportional hazards regression model from a formula\n",
      "     |      and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      status : array_like\n",
      "     |          The censoring status values; status=1 indicates that an\n",
      "     |          event occurred (e.g. failure or death), status=0 indicates\n",
      "     |          that the observation was right censored. If None, defaults\n",
      "     |          to status=1 for all cases.\n",
      "     |      entry : array_like\n",
      "     |          The entry times, if left truncation occurs\n",
      "     |      strata : array_like\n",
      "     |          Stratum labels.  If None, all observations are taken to be\n",
      "     |          in a single stratum.\n",
      "     |      offset : array_like\n",
      "     |          Array of offset values\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index\n",
      "     |          values that indicate the subset of df to use in the\n",
      "     |          model. Assumes df is a `pandas.DataFrame`\n",
      "     |      ties : str\n",
      "     |          The method used to handle tied times, must be either 'breslow'\n",
      "     |          or 'efron'.\n",
      "     |      missing : str\n",
      "     |          The method used to handle missing data\n",
      "     |      args : extra arguments\n",
      "     |          These are passed to the model\n",
      "     |      kwargs : extra keyword arguments\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : PHReg model instance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Poisson(CountModel)\n",
      "     |  Poisson(endog, exog, offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |  \n",
      "     |  Poisson Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  offset : array_like\n",
      "     |      Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |  exposure : array_like\n",
      "     |      Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.\n",
      "     |      missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  check_rank : bool\n",
      "     |      Check exog rank to determine model degrees of freedom. Default is\n",
      "     |      True. Setting to False reduces model initialization time when\n",
      "     |      exog.shape[1] is large.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Poisson\n",
      "     |      CountModel\n",
      "     |      DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      Poisson model cumulative distribution function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          `X` is the linear predictor of the model.  See notes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The value of the Poisson CDF at each point.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The CDF is defined as\n",
      "     |      \n",
      "     |      .. math:: \\exp\\left(-\\lambda\\right)\\sum_{i=0}^{y}\\frac{\\lambda^{i}}{i!}\n",
      "     |      \n",
      "     |      where :math:`\\lambda` assumes the loglinear model. I.e.,\n",
      "     |      \n",
      "     |      .. math:: \\ln\\lambda_{i}=X\\beta\n",
      "     |      \n",
      "     |      The parameter `X` is :math:`X\\beta` in the above formula.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='newton', maxiter=35, full_output=1, disp=1, callback=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      fit the model subject to linear equality constraints\n",
      "     |      \n",
      "     |      The constraints are of the form   `R params = q`\n",
      "     |      where R is the constraint_matrix and q is the vector of\n",
      "     |      constraint_values.\n",
      "     |      \n",
      "     |      The estimation creates a new model with transformed design matrix,\n",
      "     |      exog, and converts the results back to the original parameterization.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : formula expression or tuple\n",
      "     |          If it is a tuple, then the constraint needs to be given by two\n",
      "     |          arrays (constraint_matrix, constraint_value), i.e. (R, q).\n",
      "     |          Otherwise, the constraints can be given as strings or list of\n",
      "     |          strings.\n",
      "     |          see t_test for details\n",
      "     |      start_params : None or array_like\n",
      "     |          starting values for the optimization. `start_params` needs to be\n",
      "     |          given in the original parameter space and are internally\n",
      "     |          transformed.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the transformed model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Poisson model Hessian matrix of the loglikelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (k_vars, k_vars)\n",
      "     |          The Hessian, second derivative of loglikelihood function,\n",
      "     |          evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial^{2}\\ln L}{\\partial\\beta\\partial\\beta^{\\prime}}=-\\sum_{i=1}^{n}\\lambda_{i}x_{i}x_{i}^{\\prime}\n",
      "     |      \n",
      "     |      where the loglinear model is assumed\n",
      "     |      \n",
      "     |      .. math:: \\ln\\lambda_{i}=x_{i}\\beta\n",
      "     |  \n",
      "     |  hessian_factor(self, params)\n",
      "     |      Poisson model Hessian factor\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (nobs,)\n",
      "     |          The Hessian factor, second derivative of loglikelihood function\n",
      "     |          with respect to the linear predictor evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial^{2}\\ln L}{\\partial\\beta\\partial\\beta^{\\prime}}=-\\sum_{i=1}^{n}\\lambda_{i}\n",
      "     |      \n",
      "     |      where the loglinear model is assumed\n",
      "     |      \n",
      "     |      .. math:: \\ln\\lambda_{i}=x_{i}\\beta\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood of Poisson model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\sum_{i=1}^{n}\\left[-\\lambda_{i}+y_{i}x_{i}^{\\prime}\\beta-\\ln y_{i}!\\right]\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Loglikelihood for observations of Poisson model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : array_like\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L_{i}=\\left[-\\lambda_{i}+y_{i}x_{i}^{\\prime}\\beta-\\ln y_{i}!\\right]\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      Poisson model probability mass function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          `X` is the linear predictor of the model.  See notes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pdf : ndarray\n",
      "     |          The value of the Poisson probability mass function, PMF, for each\n",
      "     |          point of X.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The PMF is defined as\n",
      "     |      \n",
      "     |      .. math:: \\frac{e^{-\\lambda_{i}}\\lambda_{i}^{y_{i}}}{y_{i}!}\n",
      "     |      \n",
      "     |      where :math:`\\lambda` assumes the loglinear model. I.e.,\n",
      "     |      \n",
      "     |      .. math:: \\ln\\lambda_{i}=x_{i}\\beta\n",
      "     |      \n",
      "     |      The parameter `X` is :math:`x_{i}\\beta` in the above formula.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Poisson model score (gradient) vector of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L}{\\partial\\beta}=\\sum_{i=1}^{n}\\left(y_{i}-\\lambda_{i}\\right)x_{i}\n",
      "     |      \n",
      "     |      where the loglinear model is assumed\n",
      "     |      \n",
      "     |      .. math:: \\ln\\lambda_{i}=x_{i}\\beta\n",
      "     |  \n",
      "     |  score_factor(self, params)\n",
      "     |      Poisson model score_factor for each observation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : array_like\n",
      "     |          The score factor (nobs, ) of the model evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L_{i}}{\\partial\\beta}=\\left(y_{i}-\\lambda_{i}\\right)\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |      \n",
      "     |      where the loglinear model is assumed\n",
      "     |      \n",
      "     |      .. math:: \\ln\\lambda_{i}=x_{i}\\beta\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Poisson model Jacobian of the log-likelihood for each observation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : array_like\n",
      "     |          The score vector (nobs, k_vars) of the model evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L_{i}}{\\partial\\beta}=\\left(y_{i}-\\lambda_{i}\\right)x_{i}\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |      \n",
      "     |      where the loglinear model is assumed\n",
      "     |      \n",
      "     |      .. math:: \\ln\\lambda_{i}=x_{i}\\beta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  family\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CountModel:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, offset=None, exposure=None, missing='none', check_rank=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exposure=None, offset=None, linear=False)\n",
      "     |      Predict response variable of a count model given exogenous variables\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Model parameters\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Is exog is None, model exog is used.\n",
      "     |      exposure : array_like, optional\n",
      "     |          Log(exposure) is added to the linear prediction with\n",
      "     |          coefficient equal to 1. If exposure is not provided and exog\n",
      "     |          is None, uses the model's exposure if present.  If not, uses\n",
      "     |          0 as the default value.\n",
      "     |      offset : array_like, optional\n",
      "     |          Offset is added to the linear prediction with coefficient\n",
      "     |          equal to 1. If offset is not provided and exog\n",
      "     |          is None, uses the model's offset if present.  If not, uses\n",
      "     |          0 as the default value.\n",
      "     |      linear : bool\n",
      "     |          If True, returns the linear predicted values.  If False,\n",
      "     |          returns the exponential of the linear predicted value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If exposure is specified, then it will be logged by the method.\n",
      "     |      The user does not need to log it first.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DiscreteModel:\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class PoissonBayesMixedGLM(_VariationalBayesMixedGLM, _BayesMixedGLM)\n",
      "     |  PoissonBayesMixedGLM(endog, exog, exog_vc, ident, vcp_p=1, fe_p=2, fep_names=None, vcp_names=None, vc_names=None)\n",
      "     |  \n",
      "     |  Generalized Linear Mixed Model with Bayesian estimation\n",
      "     |  \n",
      "     |  The class implements the Laplace approximation to the posterior\n",
      "     |  distribution (`fit_map`) and a variational Bayes approximation to\n",
      "     |  the posterior (`fit_vb`).  See the two fit method docstrings for\n",
      "     |  more information about the fitting approaches.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      Vector of response values.\n",
      "     |  exog : array_like\n",
      "     |      Array of covariates for the fixed effects part of the mean\n",
      "     |      structure.\n",
      "     |  exog_vc : array_like\n",
      "     |      Array of covariates for the random part of the model.  A\n",
      "     |      scipy.sparse array may be provided, or else the passed\n",
      "     |      array will be converted to sparse internally.\n",
      "     |  ident : array_like\n",
      "     |      Array of integer labels showing which random terms (columns\n",
      "     |      of `exog_vc`) have a common variance.\n",
      "     |  vcp_p : float\n",
      "     |      Prior standard deviation for variance component parameters\n",
      "     |      (the prior standard deviation of log(s) is vcp_p, where s is\n",
      "     |      the standard deviation of a random effect).\n",
      "     |  fe_p : float\n",
      "     |      Prior standard deviation for fixed effects parameters.\n",
      "     |  family : statsmodels.genmod.families instance\n",
      "     |      The GLM family.\n",
      "     |  fep_names : list[str]\n",
      "     |      The names of the fixed effects parameters (corresponding to\n",
      "     |      columns of exog).  If None, default names are constructed.\n",
      "     |  vcp_names : list[str]\n",
      "     |      The names of the variance component parameters (corresponding\n",
      "     |      to distinct labels in ident).  If None, default names are\n",
      "     |      constructed.\n",
      "     |  vc_names : list[str]\n",
      "     |      The names of the random effect realizations.\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  MixedGLMResults object\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  There are three types of values in the posterior distribution:\n",
      "     |  fixed effects parameters (fep), corresponding to the columns of\n",
      "     |  `exog`, random effects realizations (vc), corresponding to the\n",
      "     |  columns of `exog_vc`, and the standard deviations of the random\n",
      "     |  effects realizations (vcp), corresponding to the unique integer\n",
      "     |  labels in `ident`.\n",
      "     |  \n",
      "     |  All random effects are modeled as being independent Gaussian\n",
      "     |  values (given the variance structure parameters).  Every column of\n",
      "     |  `exog_vc` has a distinct realized random effect that is used to\n",
      "     |  form the linear predictors.  The elements of `ident` determine the\n",
      "     |  distinct variance structure parameters.  Two random effect\n",
      "     |  realizations that have the same value in `ident` have the same\n",
      "     |  variance.  When fitting with a formula, `ident` is constructed\n",
      "     |  internally (each element of `vc_formulas` yields a distinct label\n",
      "     |  in `ident`).\n",
      "     |  \n",
      "     |  The random effect standard deviation parameters (`vcp`) have\n",
      "     |  log-normal prior distributions with mean 0 and standard deviation\n",
      "     |  `vcp_p`.\n",
      "     |  \n",
      "     |  Note that for some families, e.g. Binomial, the posterior mode may\n",
      "     |  be difficult to find numerically if `vcp_p` is set to too large of\n",
      "     |  a value.  Setting `vcp_p` to 0.5 seems to work well.\n",
      "     |  \n",
      "     |  The prior for the fixed effects parameters is Gaussian with mean 0\n",
      "     |  and standard deviation `fe_p`.  It is recommended that quantitative\n",
      "     |  covariates be standardized.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  A Poisson random effects model with random intercepts for villages\n",
      "     |  and random slopes for each year within each village:\n",
      "     |  \n",
      "     |  >>> random = {\"a\": '0 + C(Village)', \"b\": '0 + C(Village)*year_cen'}\n",
      "     |  >>> model = PoissonBayesMixedGLM.from_formula(\n",
      "     |                  'y ~ year_cen', random, data)\n",
      "     |  >>> result = model.fit_vb()\n",
      "     |  \n",
      "     |  \n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Introduction to generalized linear mixed models:\n",
      "     |  https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models\n",
      "     |  \n",
      "     |  SAS documentation:\n",
      "     |  https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_intromix_a0000000215.htm\n",
      "     |  \n",
      "     |  An assessment of estimation methods for generalized linear mixed\n",
      "     |  models with binary outcomes\n",
      "     |  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3866838/\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PoissonBayesMixedGLM\n",
      "     |      _VariationalBayesMixedGLM\n",
      "     |      _BayesMixedGLM\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, exog_vc, ident, vcp_p=1, fe_p=2, fep_names=None, vcp_names=None, vc_names=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  vb_elbo(self, vb_mean, vb_sd)\n",
      "     |      Returns the evidence lower bound (ELBO) for the model.\n",
      "     |  \n",
      "     |  vb_elbo_grad(self, vb_mean, vb_sd)\n",
      "     |      Returns the gradient of the model's evidence lower bound (ELBO).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, vc_formulas, data, vcp_p=1, fe_p=2, vcp_names=None, vc_names=None) from builtins.type\n",
      "     |      Fit a BayesMixedGLM using a formula.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str\n",
      "     |          Formula for the endog and fixed effects terms (use ~ to\n",
      "     |          separate dependent and independent expressions).\n",
      "     |      vc_formulas : dictionary\n",
      "     |          vc_formulas[name] is a one-sided formula that creates one\n",
      "     |          collection of random effects with a common variance\n",
      "     |          parameter.  If using categorical (factor) variables to\n",
      "     |          produce variance components, note that generally `0 + ...`\n",
      "     |          should be used so that an intercept is not included.\n",
      "     |      data : data frame\n",
      "     |          The data to which the formulas are applied.\n",
      "     |      family : genmod.families instance\n",
      "     |          A GLM family.\n",
      "     |      vcp_p : float\n",
      "     |          The prior standard deviation for the logarithms of the standard\n",
      "     |          deviations of the random effects.\n",
      "     |      fe_p : float\n",
      "     |          The prior standard deviation for the fixed effects parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _VariationalBayesMixedGLM:\n",
      "     |  \n",
      "     |  fit_vb(self, mean=None, sd=None, fit_method='BFGS', minim_opts=None, scale_fe=False, verbose=False)\n",
      "     |      Fit a model using the variational Bayes mean field approximation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : array_like\n",
      "     |          Starting value for VB mean vector\n",
      "     |      sd : array_like\n",
      "     |          Starting value for VB standard deviation vector\n",
      "     |      fit_method : str\n",
      "     |          Algorithm for scipy.minimize\n",
      "     |      minim_opts : dict\n",
      "     |          Options passed to scipy.minimize\n",
      "     |      scale_fe : bool\n",
      "     |          If true, the columns of the fixed effects design matrix\n",
      "     |          are centered and scaled to unit variance before fitting\n",
      "     |          the model.  The results are back-transformed so that the\n",
      "     |          results are presented on the original scale.\n",
      "     |      verbose : bool\n",
      "     |          If True, print the gradient norm to the screen each time\n",
      "     |          it is calculated.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The goal is to find a factored Gaussian approximation\n",
      "     |      q1*q2*...  to the posterior distribution, approximately\n",
      "     |      minimizing the KL divergence from the factored approximation\n",
      "     |      to the actual posterior.  The KL divergence, or ELBO function\n",
      "     |      has the form\n",
      "     |      \n",
      "     |          E* log p(y, fe, vcp, vc) - E* log q\n",
      "     |      \n",
      "     |      where E* is expectation with respect to the product of qj.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Blei, Kucukelbir, McAuliffe (2017).  Variational Inference: A\n",
      "     |      review for Statisticians\n",
      "     |      https://arxiv.org/pdf/1601.00670.pdf\n",
      "     |  \n",
      "     |  vb_elbo_base(self, h, tm, fep_mean, vcp_mean, vc_mean, fep_sd, vcp_sd, vc_sd)\n",
      "     |      Returns the evidence lower bound (ELBO) for the model.\n",
      "     |      \n",
      "     |      This function calculates the family-specific ELBO function\n",
      "     |      based on information provided from a subclass.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      h : function mapping 1d vector to 1d vector\n",
      "     |          The contribution of the model to the ELBO function can be\n",
      "     |          expressed as y_i*lp_i + Eh_i(z), where y_i and lp_i are\n",
      "     |          the response and linear predictor for observation i, and z\n",
      "     |          is a standard normal random variable.  This formulation\n",
      "     |          can be achieved for any GLM with a canonical link\n",
      "     |          function.\n",
      "     |  \n",
      "     |  vb_elbo_grad_base(self, h, tm, tv, fep_mean, vcp_mean, vc_mean, fep_sd, vcp_sd, vc_sd)\n",
      "     |      Return the gradient of the ELBO function.\n",
      "     |      \n",
      "     |      See vb_elbo_base for parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _VariationalBayesMixedGLM:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _VariationalBayesMixedGLM:\n",
      "     |  \n",
      "     |  rng = 5\n",
      "     |  \n",
      "     |  verbose = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BayesMixedGLM:\n",
      "     |  \n",
      "     |  fit(self, method='BFGS', minim_opts=None)\n",
      "     |      fit is equivalent to fit_map.\n",
      "     |      \n",
      "     |      See fit_map for parameter information.\n",
      "     |      \n",
      "     |      Use `fit_vb` to fit the model using variational Bayes.\n",
      "     |  \n",
      "     |  fit_map(self, method='BFGS', minim_opts=None, scale_fe=False)\n",
      "     |      Construct the Laplace approximation to the posterior distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str\n",
      "     |          Optimization method for finding the posterior mode.\n",
      "     |      minim_opts : dict\n",
      "     |          Options passed to scipy.minimize.\n",
      "     |      scale_fe : bool\n",
      "     |          If True, the columns of the fixed effects design matrix\n",
      "     |          are centered and scaled to unit variance before fitting\n",
      "     |          the model.  The results are back-transformed so that the\n",
      "     |          results are presented on the original scale.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      BayesMixedGLMResults instance.\n",
      "     |  \n",
      "     |  logposterior(self, params)\n",
      "     |      The overall log-density: log p(y, fe, vc, vcp).\n",
      "     |      \n",
      "     |      This differs by an additive constant from the log posterior\n",
      "     |      log p(fe, vc, vcp | y).\n",
      "     |  \n",
      "     |  logposterior_grad(self, params)\n",
      "     |      The gradient of the log posterior.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, linear=False)\n",
      "     |      Return the fitted mean structure.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameter vector, may be the full parameter vector, or may\n",
      "     |          be truncated to include only the mean parameters.\n",
      "     |      exog : array_like\n",
      "     |          The design matrix for the mean structure.  If omitted, use the\n",
      "     |          model's design matrix.\n",
      "     |      linear : bool\n",
      "     |          If True, return the linear predictor without passing through the\n",
      "     |          link function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A 1-dimensional array of predicted values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "    \n",
      "    class ProbPlot(builtins.object)\n",
      "     |  ProbPlot(data, dist=<scipy.stats._continuous_distns.norm_gen object at 0x000001D5AE351180>, fit=False, distargs=(), a=0, loc=0, scale=1)\n",
      "     |  \n",
      "     |  Q-Q and P-P Probability Plots\n",
      "     |  \n",
      "     |  Can take arguments specifying the parameters for dist or fit them\n",
      "     |  automatically. (See fit under kwargs.)\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  data : array_like\n",
      "     |      A 1d data array\n",
      "     |  dist : callable\n",
      "     |      Compare x against dist. A scipy.stats or statsmodels distribution. The\n",
      "     |      default is scipy.stats.distributions.norm (a standard normal). Can be\n",
      "     |      a SciPy frozen distribution.\n",
      "     |  fit : bool\n",
      "     |      If fit is false, loc, scale, and distargs are passed to the\n",
      "     |      distribution. If fit is True then the parameters for dist are fit\n",
      "     |      automatically using dist.fit. The quantiles are formed from the\n",
      "     |      standardized data, after subtracting the fitted loc and dividing by\n",
      "     |      the fitted scale. fit cannot be used if dist is a SciPy frozen\n",
      "     |      distribution.\n",
      "     |  distargs : tuple\n",
      "     |      A tuple of arguments passed to dist to specify it fully so dist.ppf\n",
      "     |      may be called. distargs must not contain loc or scale. These values\n",
      "     |      must be passed using the loc or scale inputs. distargs cannot be used\n",
      "     |      if dist is a SciPy frozen distribution.\n",
      "     |  a : float\n",
      "     |      Offset for the plotting position of an expected order statistic, for\n",
      "     |      example. The plotting positions are given by\n",
      "     |      (i - a)/(nobs - 2*a + 1) for i in range(0,nobs+1)\n",
      "     |  loc : float\n",
      "     |      Location parameter for dist. Cannot be used if dist is a SciPy frozen\n",
      "     |      distribution.\n",
      "     |  scale : float\n",
      "     |      Scale parameter for dist. Cannot be used if dist is a SciPy frozen\n",
      "     |      distribution.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  scipy.stats.probplot\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  1) Depends on matplotlib.\n",
      "     |  2) If `fit` is True then the parameters are fit using the\n",
      "     |      distribution's `fit()` method.\n",
      "     |  3) The call signatures for the `qqplot`, `ppplot`, and `probplot`\n",
      "     |      methods are similar, so examples 1 through 4 apply to all\n",
      "     |      three methods.\n",
      "     |  4) The three plotting methods are summarized below:\n",
      "     |      ppplot : Probability-Probability plot\n",
      "     |          Compares the sample and theoretical probabilities (percentiles).\n",
      "     |      qqplot : Quantile-Quantile plot\n",
      "     |          Compares the sample and theoretical quantiles\n",
      "     |      probplot : Probability plot\n",
      "     |          Same as a Q-Q plot, however probabilities are shown in the scale of\n",
      "     |          the theoretical distribution (x-axis) and the y-axis contains\n",
      "     |          unscaled quantiles of the sample data.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  The first example shows a Q-Q plot for regression residuals\n",
      "     |  \n",
      "     |  >>> # example 1\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> from matplotlib import pyplot as plt\n",
      "     |  >>> data = sm.datasets.longley.load()\n",
      "     |  >>> data.exog = sm.add_constant(data.exog)\n",
      "     |  >>> model = sm.OLS(data.endog, data.exog)\n",
      "     |  >>> mod_fit = model.fit()\n",
      "     |  >>> res = mod_fit.resid # residuals\n",
      "     |  >>> pplot = sm.ProbPlot(res)\n",
      "     |  >>> fig = pplot.qqplot()\n",
      "     |  >>> h = plt.title(\"Ex. 1 - qqplot - residuals of OLS fit\")\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  qqplot of the residuals against quantiles of t-distribution with 4\n",
      "     |  degrees of freedom:\n",
      "     |  \n",
      "     |  >>> # example 2\n",
      "     |  >>> import scipy.stats as stats\n",
      "     |  >>> pplot = sm.ProbPlot(res, stats.t, distargs=(4,))\n",
      "     |  >>> fig = pplot.qqplot()\n",
      "     |  >>> h = plt.title(\"Ex. 2 - qqplot - residuals against quantiles of t-dist\")\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  qqplot against same as above, but with mean 3 and std 10:\n",
      "     |  \n",
      "     |  >>> # example 3\n",
      "     |  >>> pplot = sm.ProbPlot(res, stats.t, distargs=(4,), loc=3, scale=10)\n",
      "     |  >>> fig = pplot.qqplot()\n",
      "     |  >>> h = plt.title(\"Ex. 3 - qqplot - resids vs quantiles of t-dist\")\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Automatically determine parameters for t distribution including the\n",
      "     |  loc and scale:\n",
      "     |  \n",
      "     |  >>> # example 4\n",
      "     |  >>> pplot = sm.ProbPlot(res, stats.t, fit=True)\n",
      "     |  >>> fig = pplot.qqplot(line=\"45\")\n",
      "     |  >>> h = plt.title(\"Ex. 4 - qqplot - resids vs. quantiles of fitted t-dist\")\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  A second `ProbPlot` object can be used to compare two separate sample\n",
      "     |  sets by using the `other` kwarg in the `qqplot` and `ppplot` methods.\n",
      "     |  \n",
      "     |  >>> # example 5\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> x = np.random.normal(loc=8.25, scale=2.75, size=37)\n",
      "     |  >>> y = np.random.normal(loc=8.75, scale=3.25, size=37)\n",
      "     |  >>> pp_x = sm.ProbPlot(x, fit=True)\n",
      "     |  >>> pp_y = sm.ProbPlot(y, fit=True)\n",
      "     |  >>> fig = pp_x.qqplot(line=\"45\", other=pp_y)\n",
      "     |  >>> h = plt.title(\"Ex. 5 - qqplot - compare two sample sets\")\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  In qqplot, sample size of `other` can be equal or larger than the first.\n",
      "     |  In case of larger, size of `other` samples will be reduced to match the\n",
      "     |  size of the first by interpolation\n",
      "     |  \n",
      "     |  >>> # example 6\n",
      "     |  >>> x = np.random.normal(loc=8.25, scale=2.75, size=37)\n",
      "     |  >>> y = np.random.normal(loc=8.75, scale=3.25, size=57)\n",
      "     |  >>> pp_x = sm.ProbPlot(x, fit=True)\n",
      "     |  >>> pp_y = sm.ProbPlot(y, fit=True)\n",
      "     |  >>> fig = pp_x.qqplot(line=\"45\", other=pp_y)\n",
      "     |  >>> title = \"Ex. 6 - qqplot - compare different sample sizes\"\n",
      "     |  >>> h = plt.title(title)\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  In ppplot, sample size of `other` and the first can be different. `other`\n",
      "     |  will be used to estimate an empirical cumulative distribution function\n",
      "     |  (ECDF). ECDF(x) will be plotted against p(x)=0.5/n, 1.5/n, ..., (n-0.5)/n\n",
      "     |  where x are sorted samples from the first.\n",
      "     |  \n",
      "     |  >>> # example 7\n",
      "     |  >>> x = np.random.normal(loc=8.25, scale=2.75, size=37)\n",
      "     |  >>> y = np.random.normal(loc=8.75, scale=3.25, size=57)\n",
      "     |  >>> pp_x = sm.ProbPlot(x, fit=True)\n",
      "     |  >>> pp_y = sm.ProbPlot(y, fit=True)\n",
      "     |  >>> pp_y.ppplot(line=\"45\", other=pp_x)\n",
      "     |  >>> plt.title(\"Ex. 7A- ppplot - compare two sample sets, other=pp_x\")\n",
      "     |  >>> pp_x.ppplot(line=\"45\", other=pp_y)\n",
      "     |  >>> plt.title(\"Ex. 7B- ppplot - compare two sample sets, other=pp_y\")\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  The following plot displays some options, follow the link to see the\n",
      "     |  code.\n",
      "     |  \n",
      "     |  .. plot:: plots/graphics_gofplots_qqplot.py\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data, dist=<scipy.stats._continuous_distns.norm_gen object at 0x000001D5AE351180>, fit=False, distargs=(), a=0, loc=0, scale=1)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ppplot(self, xlabel=None, ylabel=None, line=None, other=None, ax=None, **plotkwargs)\n",
      "     |      Plot of the percentiles of x versus the percentiles of a distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      xlabel : str or None, optional\n",
      "     |          User-provided labels for the x-axis. If None (default),\n",
      "     |          other values are used depending on the status of the kwarg `other`.\n",
      "     |      ylabel : str or None, optional\n",
      "     |          User-provided labels for the y-axis. If None (default),\n",
      "     |          other values are used depending on the status of the kwarg `other`.\n",
      "     |      line : {None, \"45\", \"s\", \"r\", q\"}, optional\n",
      "     |          Options for the reference line to which the data is compared:\n",
      "     |      \n",
      "     |          - \"45\": 45-degree line\n",
      "     |          - \"s\": standardized line, the expected order statistics are\n",
      "     |            scaled by the standard deviation of the given sample and have\n",
      "     |            the mean added to them\n",
      "     |          - \"r\": A regression line is fit\n",
      "     |          - \"q\": A line is fit through the quartiles.\n",
      "     |          - None: by default no reference line is added to the plot.\n",
      "     |      \n",
      "     |      other : ProbPlot, array_like, or None, optional\n",
      "     |          If provided, ECDF(x) will be plotted against p(x) where x are\n",
      "     |          sorted samples from `self`. ECDF is an empirical cumulative\n",
      "     |          distribution function estimated from `other` and\n",
      "     |          p(x) = 0.5/n, 1.5/n, ..., (n-0.5)/n where n is the number of\n",
      "     |          samples in `self`. If an array-object is provided, it will be\n",
      "     |          turned into a `ProbPlot` instance default parameters. If not\n",
      "     |          provided (default), `self.dist(x)` is be plotted against p(x).\n",
      "     |      \n",
      "     |      ax : AxesSubplot, optional\n",
      "     |          If given, this subplot is used to plot in instead of a new figure\n",
      "     |          being created.\n",
      "     |      **plotkwargs\n",
      "     |          Additional arguments to be passed to the `plot` command.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Figure\n",
      "     |          If `ax` is None, the created figure.  Otherwise the figure to which\n",
      "     |          `ax` is connected.\n",
      "     |  \n",
      "     |  probplot(self, xlabel=None, ylabel=None, line=None, exceed=False, ax=None, **plotkwargs)\n",
      "     |      Plot of unscaled quantiles of x against the prob of a distribution.\n",
      "     |      \n",
      "     |      The x-axis is scaled linearly with the quantiles, but the probabilities\n",
      "     |      are used to label the axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      xlabel : {None, str}, optional\n",
      "     |          User-provided labels for the x-axis. If None (default),\n",
      "     |          other values are used depending on the status of the kwarg `other`.\n",
      "     |      ylabel : {None, str}, optional\n",
      "     |          User-provided labels for the y-axis. If None (default),\n",
      "     |          other values are used depending on the status of the kwarg `other`.\n",
      "     |      line : {None, \"45\", \"s\", \"r\", q\"}, optional\n",
      "     |          Options for the reference line to which the data is compared:\n",
      "     |      \n",
      "     |          - \"45\" - 45-degree line\n",
      "     |          - \"s\" - standardized line, the expected order statistics are scaled\n",
      "     |            by the standard deviation of the given sample and have the mean\n",
      "     |            added to them\n",
      "     |          - \"r\" - A regression line is fit\n",
      "     |          - \"q\" - A line is fit through the quartiles.\n",
      "     |          - None - by default no reference line is added to the plot.\n",
      "     |      \n",
      "     |      exceed : bool, optional\n",
      "     |          If False (default) the raw sample quantiles are plotted against\n",
      "     |          the theoretical quantiles, show the probability that a sample will\n",
      "     |          not exceed a given value. If True, the theoretical quantiles are\n",
      "     |          flipped such that the figure displays the probability that a\n",
      "     |          sample will exceed a given value.\n",
      "     |      ax : AxesSubplot, optional\n",
      "     |          If given, this subplot is used to plot in instead of a new figure\n",
      "     |          being created.\n",
      "     |      **plotkwargs\n",
      "     |          Additional arguments to be passed to the `plot` command.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Figure\n",
      "     |          If `ax` is None, the created figure.  Otherwise the figure to which\n",
      "     |          `ax` is connected.\n",
      "     |  \n",
      "     |  qqplot(self, xlabel=None, ylabel=None, line=None, other=None, ax=None, swap: bool = False, **plotkwargs)\n",
      "     |      Plot of the quantiles of x versus the quantiles/ppf of a distribution.\n",
      "     |      \n",
      "     |      Can also be used to plot against the quantiles of another `ProbPlot`\n",
      "     |      instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      xlabel : {None, str}\n",
      "     |          User-provided labels for the x-axis. If None (default),\n",
      "     |          other values are used depending on the status of the kwarg `other`.\n",
      "     |      ylabel : {None, str}\n",
      "     |          User-provided labels for the y-axis. If None (default),\n",
      "     |          other values are used depending on the status of the kwarg `other`.\n",
      "     |      line : {None, \"45\", \"s\", \"r\", q\"}, optional\n",
      "     |          Options for the reference line to which the data is compared:\n",
      "     |      \n",
      "     |          - \"45\" - 45-degree line\n",
      "     |          - \"s\" - standardized line, the expected order statistics are scaled\n",
      "     |            by the standard deviation of the given sample and have the mean\n",
      "     |            added to them\n",
      "     |          - \"r\" - A regression line is fit\n",
      "     |          - \"q\" - A line is fit through the quartiles.\n",
      "     |          - None - by default no reference line is added to the plot.\n",
      "     |      \n",
      "     |      other : {ProbPlot, array_like, None}, optional\n",
      "     |          If provided, the sample quantiles of this `ProbPlot` instance are\n",
      "     |          plotted against the sample quantiles of the `other` `ProbPlot`\n",
      "     |          instance. Sample size of `other` must be equal or larger than\n",
      "     |          this `ProbPlot` instance. If the sample size is larger, sample\n",
      "     |          quantiles of `other` will be interpolated to match the sample size\n",
      "     |          of this `ProbPlot` instance. If an array-like object is provided,\n",
      "     |          it will be turned into a `ProbPlot` instance using default\n",
      "     |          parameters. If not provided (default), the theoretical quantiles\n",
      "     |          are used.\n",
      "     |      ax : AxesSubplot, optional\n",
      "     |          If given, this subplot is used to plot in instead of a new figure\n",
      "     |          being created.\n",
      "     |      swap : bool, optional\n",
      "     |          Flag indicating to swap the x and y labels.\n",
      "     |      **plotkwargs\n",
      "     |          Additional arguments to be passed to the `plot` command.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Figure\n",
      "     |          If `ax` is None, the created figure.  Otherwise the figure to which\n",
      "     |          `ax` is connected.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  sample_percentiles\n",
      "     |      Sample percentiles\n",
      "     |  \n",
      "     |  sample_quantiles\n",
      "     |      sample quantiles\n",
      "     |  \n",
      "     |  sorted_data\n",
      "     |      sorted data\n",
      "     |  \n",
      "     |  theoretical_percentiles\n",
      "     |      Theoretical percentiles\n",
      "     |  \n",
      "     |  theoretical_quantiles\n",
      "     |      Theoretical quantiles\n",
      "    \n",
      "    class Probit(BinaryModel)\n",
      "     |  Probit(endog, exog, check_rank=True, **kwargs)\n",
      "     |  \n",
      "     |  Probit Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  check_rank : bool\n",
      "     |      Check exog rank to determine model degrees of freedom. Default is\n",
      "     |      True. Setting to False reduces model initialization time when\n",
      "     |      exog.shape[1] is large.\n",
      "     |  \n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Probit\n",
      "     |      BinaryModel\n",
      "     |      DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      Probit (Normal) cumulative distribution function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          The linear predictor of the model (XB).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cdf : ndarray\n",
      "     |          The cdf evaluated at `X`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This function is just an alias for scipy.stats.norm.cdf\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='newton', maxiter=35, full_output=1, disp=1, callback=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Probit model Hessian matrix of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (k_vars, k_vars)\n",
      "     |          The Hessian, second derivative of loglikelihood function,\n",
      "     |          evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial^{2}\\ln L}{\\partial\\beta\\partial\\beta^{\\prime}}=-\\lambda_{i}\\left(\\lambda_{i}+x_{i}^{\\prime}\\beta\\right)x_{i}x_{i}^{\\prime}\n",
      "     |      \n",
      "     |      where\n",
      "     |      \n",
      "     |      .. math:: \\lambda_{i}=\\frac{q_{i}\\phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)}{\\Phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)}\n",
      "     |      \n",
      "     |      and :math:`q=2y-1`\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of probit model (i.e., the normal distribution).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\sum_{i}\\ln\\Phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)\n",
      "     |      \n",
      "     |      Where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      "     |      normal distribution is symmetric.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Log-likelihood of probit model for each observation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : array_like\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L_{i}=\\ln\\Phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |      \n",
      "     |      where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      "     |      normal distribution is symmetric.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      Probit (Normal) probability density function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          The linear predictor of the model (XB).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pdf : ndarray\n",
      "     |          The value of the normal density function for each point of X.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This function is just an alias for scipy.stats.norm.pdf\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Probit model score (gradient) vector\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L}{\\partial\\beta}=\\sum_{i=1}^{n}\\left[\\frac{q_{i}\\phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)}{\\Phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)}\\right]x_{i}\n",
      "     |      \n",
      "     |      Where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      "     |      normal distribution is symmetric.\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Probit model Jacobian for each observation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jac : array_like\n",
      "     |          The derivative of the loglikelihood for each observation evaluated\n",
      "     |          at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\frac{\\partial\\ln L_{i}}{\\partial\\beta}=\\left[\\frac{q_{i}\\phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)}{\\Phi\\left(q_{i}x_{i}^{\\prime}\\beta\\right)}\\right]x_{i}\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |      \n",
      "     |      Where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      "     |      normal distribution is symmetric.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BinaryModel:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, check_rank=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, linear=False)\n",
      "     |      Predict response variable of a model given exogenous variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Fitted parameters of the model.\n",
      "     |      exog : array_like\n",
      "     |          1d or 2d array of exogenous values.  If not supplied, the\n",
      "     |          whole exog attribute of the model is used.\n",
      "     |      linear : bool, optional\n",
      "     |          If True, returns the linear predictor dot(exog,params).  Else,\n",
      "     |          returns the value of the cdf at the linear predictor.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array\n",
      "     |          Fitted values at exog.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DiscreteModel:\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class QuantReg(statsmodels.regression.linear_model.RegressionModel)\n",
      "     |  QuantReg(endog, exog, **kwargs)\n",
      "     |  \n",
      "     |  Quantile Regression\n",
      "     |  \n",
      "     |  Estimate a quantile regression model using iterative reweighted least\n",
      "     |  squares.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array or dataframe\n",
      "     |      endogenous/response variable\n",
      "     |  exog : array or dataframe\n",
      "     |      exogenous/explanatory variable(s)\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The Least Absolute Deviation (LAD) estimator is a special case where\n",
      "     |  quantile is set to 0.5 (q argument of the fit method).\n",
      "     |  \n",
      "     |  The asymptotic covariance matrix is estimated following the procedure in\n",
      "     |  Greene (2008, p.407-408), using either the logistic or gaussian kernels\n",
      "     |  (kernel argument of the fit method).\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  General:\n",
      "     |  \n",
      "     |  * Birkes, D. and Y. Dodge(1993). Alternative Methods of Regression, John Wiley and Sons.\n",
      "     |  * Green,W. H. (2008). Econometric Analysis. Sixth Edition. International Student Edition.\n",
      "     |  * Koenker, R. (2005). Quantile Regression. New York: Cambridge University Press.\n",
      "     |  * LeSage, J. P.(1999). Applied Econometrics Using MATLAB,\n",
      "     |  \n",
      "     |  Kernels (used by the fit method):\n",
      "     |  \n",
      "     |  * Green (2008) Table 14.2\n",
      "     |  \n",
      "     |  Bandwidth selection (used by the fit method):\n",
      "     |  \n",
      "     |  * Bofinger, E. (1975). Estimation of a density function using order statistics. Australian Journal of Statistics 17: 1-17.\n",
      "     |  * Chamberlain, G. (1994). Quantile regression, censoring, and the structure of wages. In Advances in Econometrics, Vol. 1: Sixth World Congress, ed. C. A. Sims, 171-209. Cambridge: Cambridge University Press.\n",
      "     |  * Hall, P., and S. Sheather. (1988). On the distribution of the Studentized quantile. Journal of the Royal Statistical Society, Series B 50: 381-391.\n",
      "     |  \n",
      "     |  Keywords: Least Absolute Deviation(LAD) Regression, Quantile Regression,\n",
      "     |  Regression, Robust Estimation.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QuantReg\n",
      "     |      statsmodels.regression.linear_model.RegressionModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, q=0.5, vcov='robust', kernel='epa', bandwidth='hsheather', max_iter=1000, p_tol=1e-06, **kwargs)\n",
      "     |      Solve by Iterative Weighted Least Squares\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float\n",
      "     |          Quantile must be strictly between 0 and 1\n",
      "     |      vcov : str, method used to calculate the variance-covariance matrix\n",
      "     |          of the parameters. Default is ``robust``:\n",
      "     |      \n",
      "     |          - robust : heteroskedasticity robust standard errors (as suggested\n",
      "     |            in Greene 6th edition)\n",
      "     |          - iid : iid errors (as in Stata 12)\n",
      "     |      \n",
      "     |      kernel : str, kernel to use in the kernel density estimation for the\n",
      "     |          asymptotic covariance matrix:\n",
      "     |      \n",
      "     |          - epa: Epanechnikov\n",
      "     |          - cos: Cosine\n",
      "     |          - gau: Gaussian\n",
      "     |          - par: Parzene\n",
      "     |      \n",
      "     |      bandwidth : str, Bandwidth selection method in kernel density\n",
      "     |          estimation for asymptotic covariance estimate (full\n",
      "     |          references in QuantReg docstring):\n",
      "     |      \n",
      "     |          - hsheather: Hall-Sheather (1988)\n",
      "     |          - bofinger: Bofinger (1975)\n",
      "     |          - chamberlain: Chamberlain (1994)\n",
      "     |  \n",
      "     |  whiten(self, data)\n",
      "     |      QuantReg model whitener does nothing: returns data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.regression.linear_model.RegressionModel:\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      "     |      Construct a random number generator for the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters (regression coefficients).\n",
      "     |      scale : scalar\n",
      "     |          The variance parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      dist_class : class\n",
      "     |          A random number generator class.  Must take 'loc' and 'scale'\n",
      "     |          as arguments and return a random number generator implementing\n",
      "     |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Frozen random number generator object with mean and variance\n",
      "     |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      "     |          to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      "     |      the returned random number generator must be called with\n",
      "     |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      "     |      the data set used to fit the model.  If any other value is\n",
      "     |      used for ``n``, misleading results will be produced.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize model components.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return linear predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a linear model.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Model exog is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          An array of fitted values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the model has not yet been fit, params is not optional.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.regression.linear_model.RegressionModel:\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      "     |      constant is included.\n",
      "     |  \n",
      "     |  df_resid\n",
      "     |      The residual degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the number of observations minus the rank of\n",
      "     |      the regressor matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Must be overridden by subclasses.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RLM(statsmodels.base.model.LikelihoodModel)\n",
      "     |  RLM(endog, exog, M=None, missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Robust Linear Model\n",
      "     |  \n",
      "     |  Estimate a robust linear model via iteratively reweighted least squares\n",
      "     |  given a robust criterion estimator.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  M : statsmodels.robust.norms.RobustNorm, optional\n",
      "     |      The robust criterion function for downweighting outliers.\n",
      "     |      The current options are LeastSquares, HuberT, RamsayE, AndrewWave,\n",
      "     |      TrimmedMean, Hampel, and TukeyBiweight.  The default is HuberT().\n",
      "     |      See statsmodels.robust.norms for more information.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  \n",
      "     |  df_model : float\n",
      "     |      The degrees of freedom of the model.  The number of regressors p less\n",
      "     |      one for the intercept.  Note that the reported model degrees\n",
      "     |      of freedom does not count the intercept as a regressor, though\n",
      "     |      the model is assumed to have an intercept.\n",
      "     |  df_resid : float\n",
      "     |      The residual degrees of freedom.  The number of observations n\n",
      "     |      less the number of regressors p.  Note that here p does include\n",
      "     |      the intercept as using a degree of freedom.\n",
      "     |  endog : ndarray\n",
      "     |      See above.  Note that endog is a reference to the data so that if\n",
      "     |      data is already an array and it is changed, then `endog` changes\n",
      "     |      as well.\n",
      "     |  exog : ndarray\n",
      "     |      See above.  Note that endog is a reference to the data so that if\n",
      "     |      data is already an array and it is changed, then `endog` changes\n",
      "     |      as well.\n",
      "     |  M : statsmodels.robust.norms.RobustNorm\n",
      "     |       See above.  Robust estimator instance instantiated.\n",
      "     |  nobs : float\n",
      "     |      The number of observations n\n",
      "     |  pinv_wexog : ndarray\n",
      "     |      The pseudoinverse of the design / exogenous data array.  Note that\n",
      "     |      RLM has no whiten method, so this is just the pseudo inverse of the\n",
      "     |      design.\n",
      "     |  normalized_cov_params : ndarray\n",
      "     |      The p x p normalized covariance of the design / exogenous data.\n",
      "     |      This is approximately equal to (X.T X)^(-1)\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> data = sm.datasets.stackloss.load()\n",
      "     |  >>> data.exog = sm.add_constant(data.exog)\n",
      "     |  >>> rlm_model = sm.RLM(data.endog, data.exog,                            M=sm.robust.norms.HuberT())\n",
      "     |  \n",
      "     |  >>> rlm_results = rlm_model.fit()\n",
      "     |  >>> rlm_results.params\n",
      "     |  array([  0.82938433,   0.92606597,  -0.12784672, -41.02649835])\n",
      "     |  >>> rlm_results.bse\n",
      "     |  array([ 0.11100521,  0.30293016,  0.12864961,  9.79189854])\n",
      "     |  >>> rlm_results_HC2 = rlm_model.fit(cov=\"H2\")\n",
      "     |  >>> rlm_results_HC2.params\n",
      "     |  array([  0.82938433,   0.92606597,  -0.12784672, -41.02649835])\n",
      "     |  >>> rlm_results_HC2.bse\n",
      "     |  array([ 0.11945975,  0.32235497,  0.11796313,  9.08950419])\n",
      "     |  >>> mod = sm.RLM(data.endog, data.exog, M=sm.robust.norms.Hampel())\n",
      "     |  >>> rlm_hamp_hub = mod.fit(scale_est=sm.robust.scale.HuberScale())\n",
      "     |  >>> rlm_hamp_hub.params\n",
      "     |  array([  0.73175452,   1.25082038,  -0.14794399, -40.27122257])\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RLM\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, M=None, missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  deviance(self, tmp_results)\n",
      "     |      Returns the (unnormalized) log-likelihood from the M estimator.\n",
      "     |  \n",
      "     |  fit(self, maxiter=50, tol=1e-08, scale_est='mad', init=None, cov='H1', update_scale=True, conv='dev', start_params=None)\n",
      "     |      Fits the model using iteratively reweighted least squares.\n",
      "     |      \n",
      "     |      The IRLS routine runs until the specified objective converges to `tol`\n",
      "     |      or `maxiter` has been reached.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conv : str\n",
      "     |          Indicates the convergence criteria.\n",
      "     |          Available options are \"coefs\" (the coefficients), \"weights\" (the\n",
      "     |          weights in the iteration), \"sresid\" (the standardized residuals),\n",
      "     |          and \"dev\" (the un-normalized log-likelihood for the M\n",
      "     |          estimator).  The default is \"dev\".\n",
      "     |      cov : str, optional\n",
      "     |          'H1', 'H2', or 'H3'\n",
      "     |          Indicates how the covariance matrix is estimated.  Default is 'H1'.\n",
      "     |          See rlm.RLMResults for more information.\n",
      "     |      init : str\n",
      "     |          Specifies method for the initial estimates of the parameters.\n",
      "     |          Default is None, which means that the least squares estimate\n",
      "     |          is used.  Currently it is the only available choice.\n",
      "     |      maxiter : int\n",
      "     |          The maximum number of iterations to try. Default is 50.\n",
      "     |      scale_est : str or HuberScale()\n",
      "     |          'mad' or HuberScale()\n",
      "     |          Indicates the estimate to use for scaling the weights in the IRLS.\n",
      "     |          The default is 'mad' (median absolute deviation.  Other options are\n",
      "     |          'HuberScale' for Huber's proposal 2. Huber's proposal 2 has\n",
      "     |          optional keyword arguments d, tol, and maxiter for specifying the\n",
      "     |          tuning constant, the convergence tolerance, and the maximum number\n",
      "     |          of iterations. See statsmodels.robust.scale for more information.\n",
      "     |      tol : float\n",
      "     |          The convergence tolerance of the estimate.  Default is 1e-8.\n",
      "     |      update_scale : Bool\n",
      "     |          If `update_scale` is False then the scale estimate for the\n",
      "     |          weights is held constant over the iteration.  Otherwise, it\n",
      "     |          is updated for each fit in the iteration.  Default is True.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution of the optimizer. If not provided,\n",
      "     |          the initial parameters are computed using OLS.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : statsmodels.rlm.RLMresults\n",
      "     |          Results instance\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Must be overridden by subclasses.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return linear predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a linear model\n",
      "     |      exog : array_like, optional.\n",
      "     |          Design / exogenous data. Model exog is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An array of fitted values\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RecursiveLS(statsmodels.tsa.statespace.mlemodel.MLEModel)\n",
      "     |  RecursiveLS(endog, exog, constraints=None, **kwargs)\n",
      "     |  \n",
      "     |  Recursive least squares\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The observed time-series process :math:`y`\n",
      "     |  exog : array_like\n",
      "     |      Array of exogenous regressors, shaped nobs x k.\n",
      "     |  constraints : array_like, str, or tuple\n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed that the\n",
      "     |            linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length p row vector.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Recursive least squares (RLS) corresponds to expanding window ordinary\n",
      "     |  least squares (OLS).\n",
      "     |  \n",
      "     |  This model applies the Kalman filter to compute recursive estimates of the\n",
      "     |  coefficients and recursive residuals.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [*] Durbin, James, and Siem Jan Koopman. 2012.\n",
      "     |     Time Series Analysis by State Space Methods: Second Edition.\n",
      "     |     Oxford University Press.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RecursiveLS\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, constraints=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  filter(self, return_ssm=False, **kwargs)\n",
      "     |      Kalman filtering\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit(self)\n",
      "     |      Fits the model by application of the Kalman filter\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      RecursiveLSResults\n",
      "     |  \n",
      "     |  smooth(self, return_ssm=False, **kwargs)\n",
      "     |      Kalman smoothing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  update(self, params, **kwargs)\n",
      "     |      Update the parameters of the model\n",
      "     |      \n",
      "     |      Updates the representation matrices to fill in the new parameter\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True..\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, constraints=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names (for parameters\n",
      "     |      actually included in the model).\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_states : int\n",
      "     |          The dimension of the unobserved state process.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      "     |          exogenous regressors.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : MLEModel subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method must be implemented\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |      \n",
      "     |      TODO: add an option to allow changing the ordering for the\n",
      "     |            orthogonalized option. Will require permuting matrices when\n",
      "     |            constructing the extended model.\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer, to be\n",
      "     |          transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters which may be used in likelihood\n",
      "     |          evaluation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a noop in the base class, subclasses should override where\n",
      "     |      appropriate.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters used in likelihood evaluation, to\n",
      "     |          be transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a noop in the base class, subclasses should override where\n",
      "     |      appropriate.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SurvfuncRight(builtins.object)\n",
      "     |  SurvfuncRight(time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0)\n",
      "     |  \n",
      "     |  Estimation and inference for a survival function.\n",
      "     |  \n",
      "     |  The survival function S(t) = P(T > t) is the probability that an\n",
      "     |  event time T is greater than t.\n",
      "     |  \n",
      "     |  This class currently only supports right censoring.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  time : array_like\n",
      "     |      An array of times (censoring times or event times)\n",
      "     |  status : array_like\n",
      "     |      Status at the event time, status==1 is the 'event'\n",
      "     |      (e.g. death, failure), meaning that the event\n",
      "     |      occurs at the given value in `time`; status==0\n",
      "     |      indicates that censoring has occurred, meaning that\n",
      "     |      the event occurs after the given value in `time`.\n",
      "     |  entry : array_like, optional An array of entry times for handling\n",
      "     |      left truncation (the subject is not in the risk set on or\n",
      "     |      before the entry time)\n",
      "     |  title : str\n",
      "     |      Optional title used for plots and summary output.\n",
      "     |  freq_weights : array_like\n",
      "     |      Optional frequency weights\n",
      "     |  exog : array_like\n",
      "     |      Optional, if present used to account for violation of\n",
      "     |      independent censoring.\n",
      "     |  bw_factor : float\n",
      "     |      Band-width multiplier for kernel-based estimation.  Only used\n",
      "     |      if exog is provided.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  surv_prob : array_like\n",
      "     |      The estimated value of the survivor function at each time\n",
      "     |      point in `surv_times`.\n",
      "     |  surv_prob_se : array_like\n",
      "     |      The standard errors for the values in `surv_prob`.  Not available\n",
      "     |      if exog is provided.\n",
      "     |  surv_times : array_like\n",
      "     |      The points where the survival function changes.\n",
      "     |  n_risk : array_like\n",
      "     |      The number of subjects at risk just before each time value in\n",
      "     |      `surv_times`.  Not available if exog is provided.\n",
      "     |  n_events : array_like\n",
      "     |      The number of events (e.g. deaths) that occur at each point\n",
      "     |      in `surv_times`.  Not available if exog is provided.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If exog is None, the standard Kaplan-Meier estimator is used.  If\n",
      "     |  exog is not None, a local estimate of the marginal survival\n",
      "     |  function around each point is constructed, and these are then\n",
      "     |  averaged.  This procedure gives an estimate of the marginal\n",
      "     |  survival function that accounts for dependent censoring as long as\n",
      "     |  the censoring becomes independent when conditioning on the\n",
      "     |  covariates in exog.  See Zeng et al. (2004) for details.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  D. Zeng (2004).  Estimating marginal survival function by\n",
      "     |  adjusting for dependent censoring using many covariates.  Annals\n",
      "     |  of Statistics 32:4.\n",
      "     |  https://arxiv.org/pdf/math/0409180.pdf\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  plot(self, ax=None)\n",
      "     |      Plot the survival function.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Change the line color:\n",
      "     |      \n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\n",
      "     |      >>> df = data.loc[data.sex == \"F\", :]\n",
      "     |      >>> sf = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\n",
      "     |      >>> fig = sf.plot()\n",
      "     |      >>> ax = fig.get_axes()[0]\n",
      "     |      >>> li = ax.get_lines()\n",
      "     |      >>> li[0].set_color('purple')\n",
      "     |      >>> li[1].set_color('purple')\n",
      "     |      \n",
      "     |      Do not show the censoring points:\n",
      "     |      \n",
      "     |      >>> fig = sf.plot()\n",
      "     |      >>> ax = fig.get_axes()[0]\n",
      "     |      >>> li = ax.get_lines()\n",
      "     |      >>> li[1].set_visible(False)\n",
      "     |  \n",
      "     |  quantile(self, p)\n",
      "     |      Estimated quantile of a survival distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : float\n",
      "     |          The probability point at which the quantile\n",
      "     |          is determined.\n",
      "     |      \n",
      "     |      Returns the estimated quantile.\n",
      "     |  \n",
      "     |  quantile_ci(self, p, alpha=0.05, method='cloglog')\n",
      "     |      Returns a confidence interval for a survival quantile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : float\n",
      "     |          The probability point for which a confidence interval is\n",
      "     |          determined.\n",
      "     |      alpha : float\n",
      "     |          The confidence interval has nominal coverage probability\n",
      "     |          1 - `alpha`.\n",
      "     |      method : str\n",
      "     |          Function to use for g-transformation, must be ...\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      lb : float\n",
      "     |          The lower confidence limit.\n",
      "     |      ub : float\n",
      "     |          The upper confidence limit.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is obtained by inverting Z-tests.  The\n",
      "     |      limits of the confidence interval will always be observed\n",
      "     |      event times.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      The method is based on the approach used in SAS, documented here:\n",
      "     |      \n",
      "     |        http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_details03.htm\n",
      "     |  \n",
      "     |  simultaneous_cb(self, alpha=0.05, method='hw', transform='log')\n",
      "     |      Returns a simultaneous confidence band for the survival function.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float\n",
      "     |          `1 - alpha` is the desired simultaneous coverage\n",
      "     |          probability for the confidence region.  Currently alpha\n",
      "     |          must be set to 0.05, giving 95% simultaneous intervals.\n",
      "     |      method : str\n",
      "     |          The method used to produce the simultaneous confidence\n",
      "     |          band.  Only the Hall-Wellner (hw) method is currently\n",
      "     |          implemented.\n",
      "     |      transform : str\n",
      "     |          The used to produce the interval (note that the returned\n",
      "     |          interval is on the survival probability scale regardless\n",
      "     |          of which transform is used).  Only `log` and `arcsin` are\n",
      "     |          implemented.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      lcb : array_like\n",
      "     |          The lower confidence limits corresponding to the points\n",
      "     |          in `surv_times`.\n",
      "     |      ucb : array_like\n",
      "     |          The upper confidence limits corresponding to the points\n",
      "     |          in `surv_times`.\n",
      "     |  \n",
      "     |  summary(self)\n",
      "     |      Return a summary of the estimated survival function.\n",
      "     |      \n",
      "     |      The summary is a dataframe containing the unique event times,\n",
      "     |      estimated survival function values, and related quantities.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class WLS(RegressionModel)\n",
      "     |  WLS(endog, exog, weights=1.0, missing='none', hasconst=None, **kwargs)\n",
      "     |  \n",
      "     |  Weighted Least Squares\n",
      "     |  \n",
      "     |  The weights are presumed to be (proportional to) the inverse of\n",
      "     |  the variance of the observations.  That is, if the variables are\n",
      "     |  to be transformed by 1/sqrt(W) you must supply weights = 1/W.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  weights : array_like, optional\n",
      "     |      A 1d array of weights.  If you supply 1/W then the variables are\n",
      "     |      pre- multiplied by 1/sqrt(W).  If no weights are supplied the\n",
      "     |      default value is 1 and WLS results are the same as OLS.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  hasconst : None or bool\n",
      "     |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      "     |      a constant is not checked for and k_constant is set to 1 and all\n",
      "     |      result statistics are calculated as if a constant is present. If\n",
      "     |      False, a constant is not checked for and k_constant is set to 0.\n",
      "     |  **kwargs\n",
      "     |      Extra arguments that are used to set model properties when using the\n",
      "     |      formula interface.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  weights : ndarray\n",
      "     |      The stored weights supplied as an argument.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  GLS : Fit a linear model using Generalized Least Squares.\n",
      "     |  OLS : Fit a linear model using Ordinary Least Squares.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If the weights are a function of the data, then the post estimation\n",
      "     |  statistics such as fvalue and mse_model might not be correct, as the\n",
      "     |  package does not yet support no-constant regression.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> Y = [1,3,4,5,2,3,4]\n",
      "     |  >>> X = range(1,8)\n",
      "     |  >>> X = sm.add_constant(X)\n",
      "     |  >>> wls_model = sm.WLS(Y,X, weights=list(range(1,8)))\n",
      "     |  >>> results = wls_model.fit()\n",
      "     |  >>> results.params\n",
      "     |  array([ 2.91666667,  0.0952381 ])\n",
      "     |  >>> results.tvalues\n",
      "     |  array([ 2.0652652 ,  0.35684428])\n",
      "     |  >>> print(results.t_test([1, 0]))\n",
      "     |  <T test: effect=array([ 2.91666667]), sd=array([[ 1.41224801]]), t=array([[ 2.0652652]]), p=array([[ 0.04690139]]), df_denom=5>\n",
      "     |  >>> print(results.f_test([0, 1]))\n",
      "     |  <F test: F=array([[ 0.12733784]]), p=[[ 0.73577409]], df_denom=5, df_num=1>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WLS\n",
      "     |      RegressionModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, weights=1.0, missing='none', hasconst=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      "     |      Return a regularized fit to a linear regression model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str\n",
      "     |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      "     |      alpha : scalar or array_like\n",
      "     |          The penalty weight.  If a scalar, the same penalty weight\n",
      "     |          applies to all variables in the model.  If a vector, it\n",
      "     |          must have the same length as `params`, and contains a\n",
      "     |          penalty weight for each coefficient.\n",
      "     |      L1_wt : scalar\n",
      "     |          The fraction of the penalty given to the L1 penalty term.\n",
      "     |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      "     |          ridge fit, if 1 it is a lasso fit.\n",
      "     |      start_params : array_like\n",
      "     |          Starting values for ``params``.\n",
      "     |      profile_scale : bool\n",
      "     |          If True the penalized fit is computed using the profile\n",
      "     |          (concentrated) log-likelihood for the Gaussian model.\n",
      "     |          Otherwise the fit uses the residual sum of squares.\n",
      "     |      refit : bool\n",
      "     |          If True, the model is refit using only the variables that\n",
      "     |          have non-zero coefficients in the regularized fit.  The\n",
      "     |          refitted model is not regularized.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      statsmodels.base.elastic_net.RegularizedResults\n",
      "     |          The regularized results.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The elastic net uses a combination of L1 and L2 penalties.\n",
      "     |      The implementation closely follows the glmnet package in R.\n",
      "     |      \n",
      "     |      The function that is minimized is:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      "     |      \n",
      "     |      where RSS is the usual regression sum of squares, n is the\n",
      "     |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      "     |      norms.\n",
      "     |      \n",
      "     |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      "     |      exog data.\n",
      "     |      \n",
      "     |      Post-estimation results are based on the same data used to\n",
      "     |      select variables, hence may be subject to overfitting biases.\n",
      "     |      \n",
      "     |      The elastic_net method uses the following keyword arguments:\n",
      "     |      \n",
      "     |      maxiter : int\n",
      "     |          Maximum number of iterations\n",
      "     |      cnvrg_tol : float\n",
      "     |          Convergence threshold for line searches\n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The square root lasso approach is a variation of the Lasso\n",
      "     |      that is largely self-tuning (the optimal tuning parameter\n",
      "     |      does not depend on the standard deviation of the regression\n",
      "     |      errors).  If the errors are Gaussian, the tuning parameter\n",
      "     |      can be taken to be\n",
      "     |      \n",
      "     |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      "     |      \n",
      "     |      where n is the sample size and p is the number of predictors.\n",
      "     |      \n",
      "     |      The square root lasso uses the following keyword arguments:\n",
      "     |      \n",
      "     |      zero_tol : float\n",
      "     |          Coefficients below this threshold are treated as zero.\n",
      "     |      \n",
      "     |      The cvxopt module is required to estimate model using the square root\n",
      "     |      lasso.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      "     |         generalized linear models via coordinate descent.  Journal of\n",
      "     |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      "     |      \n",
      "     |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      "     |         pivotal recovery of sparse signals via conic programming.\n",
      "     |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Compute the weights for calculating the Hessian.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameter at which Hessian is evaluated.\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Compute the value of the gaussian log-likelihood function at params.\n",
      "     |      \n",
      "     |      Given the whitened design matrix, the log-likelihood is evaluated\n",
      "     |      at the parameter vector `params` for the dependent variable `Y`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameter estimates.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The value of the log-likelihood function for a WLS Model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: -\\frac{n}{2}\\log SSR\n",
      "     |                -\\frac{n}{2}\\left(1+\\log\\left(\\frac{2\\pi}{n}\\right)\\right)\n",
      "     |                -\\frac{1}{2}\\log\\left(\\left|W\\right|\\right)\n",
      "     |      \n",
      "     |      where :math:`W` is a diagonal weight matrix matrix and\n",
      "     |      :math:`SSR=\\left(Y-\\hat{Y}\\right)^\\prime W \\left(Y-\\hat{Y}\\right)` is\n",
      "     |      the sum of the squared weighted residuals.\n",
      "     |  \n",
      "     |  whiten(self, x)\n",
      "     |      Whitener for WLS model, multiplies each column by sqrt(self.weights).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          Data to be whitened.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          The whitened values sqrt(weights)*X.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RegressionModel:\n",
      "     |  \n",
      "     |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      "     |      Full fit of the model.\n",
      "     |      \n",
      "     |      The results include an estimate of covariance matrix, (whitened)\n",
      "     |      residuals and an estimate of scale.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str, optional\n",
      "     |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      "     |          to solve the least squares problem. \"qr\" uses the QR\n",
      "     |          factorization.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `regression.linear_model.RegressionResults` for a description\n",
      "     |          of the available covariance estimators.\n",
      "     |      cov_kwds : list or None, optional\n",
      "     |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      "     |          description required keywords for alternative covariance\n",
      "     |          estimators.\n",
      "     |      use_t : bool, optional\n",
      "     |          Flag indicating to use the Student's t distribution when computing\n",
      "     |          p-values.  Default behavior depends on cov_type. See\n",
      "     |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      "     |          implementation details.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that contain information used when\n",
      "     |          constructing a model using the formula interface.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      RegressionResults\n",
      "     |          The model estimation results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      RegressionResults\n",
      "     |          The results container.\n",
      "     |      RegressionResults.get_robustcov_results\n",
      "     |          A method to change the covariance estimator used when fitting the\n",
      "     |          model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      "     |      to solve the least squares minimization.\n",
      "     |  \n",
      "     |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      "     |      Construct a random number generator for the predictive distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The model parameters (regression coefficients).\n",
      "     |      scale : scalar\n",
      "     |          The variance parameter.\n",
      "     |      exog : array_like\n",
      "     |          The predictor variable matrix.\n",
      "     |      dist_class : class\n",
      "     |          A random number generator class.  Must take 'loc' and 'scale'\n",
      "     |          as arguments and return a random number generator implementing\n",
      "     |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      gen\n",
      "     |          Frozen random number generator object with mean and variance\n",
      "     |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      "     |          to generate random values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      "     |      the returned random number generator must be called with\n",
      "     |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      "     |      the data set used to fit the model.  If any other value is\n",
      "     |      used for ``n``, misleading results will be produced.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize model components.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None)\n",
      "     |      Return linear predicted values from a design matrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Parameters of a linear model.\n",
      "     |      exog : array_like, optional\n",
      "     |          Design / exogenous data. Model exog is used if None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      array_like\n",
      "     |          An array of fitted values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the model has not yet been fit, params is not optional.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RegressionModel:\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      "     |      constant is included.\n",
      "     |  \n",
      "     |  df_resid\n",
      "     |      The residual degree of freedom.\n",
      "     |      \n",
      "     |      The dof is defined as the number of observations minus the rank of\n",
      "     |      the regressor matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ZeroInflatedGeneralizedPoisson(GenericZeroInflated)\n",
      "     |  ZeroInflatedGeneralizedPoisson(endog, exog, exog_infl=None, offset=None, exposure=None, inflation='logit', p=2, missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Zero Inflated Generalized Poisson Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  \n",
      "     |  exog_infl : array_like or None\n",
      "     |      Explanatory variables for the binary inflation model, i.e. for\n",
      "     |      mixing probability model. If None, then a constant is used.\n",
      "     |  offset : array_like\n",
      "     |      Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |  exposure : array_like\n",
      "     |      Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.\n",
      "     |  inflation : {'logit', 'probit'}\n",
      "     |      The model for the zero inflation, either Logit (default) or Probit\n",
      "     |  p : float\n",
      "     |      dispersion power parameter for the GeneralizedPoisson model.  p=1 for\n",
      "     |      ZIGP-1 and p=2 for ZIGP-2. Default is p=2\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  exog_infl : ndarray\n",
      "     |      A reference to the zero-inflated exogenous design.\n",
      "     |  p : scalar\n",
      "     |      P denotes parametrizations for ZIGP regression.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ZeroInflatedGeneralizedPoisson\n",
      "     |      GenericZeroInflated\n",
      "     |      statsmodels.discrete.discrete_model.CountModel\n",
      "     |      statsmodels.discrete.discrete_model.DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, exog_infl=None, offset=None, exposure=None, inflation='logit', p=2, missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GenericZeroInflated:\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='bfgs', maxiter=35, full_output=1, disp=1, callback=None, cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Generic Zero Inflated model Hessian matrix of the loglikelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (k_vars, k_vars)\n",
      "     |          The Hessian, second derivative of loglikelihood function,\n",
      "     |          evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood of Generic Zero Inflated model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\sum_{y_{i}=0}\\ln(w_{i}+(1-w_{i})*P_{main\\_model})+\n",
      "     |          \\sum_{y_{i}>0}(\\ln(1-w_{i})+L_{main\\_model})\n",
      "     |          where P - pdf of main model, L - loglike function of main model.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Loglikelihood for observations of Generic Zero Inflated model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : ndarray\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes for definition.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\ln(w_{i}+(1-w_{i})*P_{main\\_model})+\n",
      "     |          \\ln(1-w_{i})+L_{main\\_model}\n",
      "     |          where P - pdf of main model, L - loglike function of main model.\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exog_infl=None, exposure=None, offset=None, which='mean')\n",
      "     |      Predict response variable of a count model given exogenous variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      exog : ndarray, optional\n",
      "     |          A reference to the exogenous design.\n",
      "     |          If not assigned, will be used exog from fitting.\n",
      "     |      exog_infl : ndarray, optional\n",
      "     |          A reference to the zero-inflated exogenous design.\n",
      "     |          If not assigned, will be used exog from fitting.\n",
      "     |      offset : ndarray, optional\n",
      "     |          Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |      exposure : ndarray, optional\n",
      "     |          Log(exposure) is added to the linear prediction with coefficient\n",
      "     |          equal to 1. If exposure is specified, then it will be logged by the method.\n",
      "     |          The user does not need to log it first.\n",
      "     |      which : str, optional\n",
      "     |          Define values that will be predicted.\n",
      "     |          'mean', 'mean-main', 'linear', 'mean-nonzero', 'prob-zero, 'prob', 'prob-main'\n",
      "     |          Default is 'mean'.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Generic Zero Inflated model score (gradient) vector of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.discrete.discrete_model.DiscreteModel:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      The cumulative distribution function of the model.\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      The probability density (mass) function of the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ZeroInflatedNegativeBinomialP(GenericZeroInflated)\n",
      "     |  ZeroInflatedNegativeBinomialP(endog, exog, exog_infl=None, offset=None, exposure=None, inflation='logit', p=2, missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Zero Inflated Generalized Negative Binomial Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  \n",
      "     |  exog_infl : array_like or None\n",
      "     |      Explanatory variables for the binary inflation model, i.e. for\n",
      "     |      mixing probability model. If None, then a constant is used.\n",
      "     |  offset : array_like\n",
      "     |      Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |  exposure : array_like\n",
      "     |      Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.\n",
      "     |  inflation : {'logit', 'probit'}\n",
      "     |      The model for the zero inflation, either Logit (default) or Probit\n",
      "     |  p : float\n",
      "     |      dispersion power parameter for the NegativeBinomialP model.  p=1 for\n",
      "     |      ZINB-1 and p=2 for ZINM-2. Default is p=2\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  exog_infl : ndarray\n",
      "     |      A reference to the zero-inflated exogenous design.\n",
      "     |  p : scalar\n",
      "     |      P denotes parametrizations for ZINB regression. p=1 for ZINB-1 and\n",
      "     |  p=2 for ZINB-2. Default is p=2\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ZeroInflatedNegativeBinomialP\n",
      "     |      GenericZeroInflated\n",
      "     |      statsmodels.discrete.discrete_model.CountModel\n",
      "     |      statsmodels.discrete.discrete_model.DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, exog_infl=None, offset=None, exposure=None, inflation='logit', p=2, missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GenericZeroInflated:\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='bfgs', maxiter=35, full_output=1, disp=1, callback=None, cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Generic Zero Inflated model Hessian matrix of the loglikelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (k_vars, k_vars)\n",
      "     |          The Hessian, second derivative of loglikelihood function,\n",
      "     |          evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood of Generic Zero Inflated model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\sum_{y_{i}=0}\\ln(w_{i}+(1-w_{i})*P_{main\\_model})+\n",
      "     |          \\sum_{y_{i}>0}(\\ln(1-w_{i})+L_{main\\_model})\n",
      "     |          where P - pdf of main model, L - loglike function of main model.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Loglikelihood for observations of Generic Zero Inflated model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : ndarray\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes for definition.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\ln(w_{i}+(1-w_{i})*P_{main\\_model})+\n",
      "     |          \\ln(1-w_{i})+L_{main\\_model}\n",
      "     |          where P - pdf of main model, L - loglike function of main model.\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exog_infl=None, exposure=None, offset=None, which='mean')\n",
      "     |      Predict response variable of a count model given exogenous variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      exog : ndarray, optional\n",
      "     |          A reference to the exogenous design.\n",
      "     |          If not assigned, will be used exog from fitting.\n",
      "     |      exog_infl : ndarray, optional\n",
      "     |          A reference to the zero-inflated exogenous design.\n",
      "     |          If not assigned, will be used exog from fitting.\n",
      "     |      offset : ndarray, optional\n",
      "     |          Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |      exposure : ndarray, optional\n",
      "     |          Log(exposure) is added to the linear prediction with coefficient\n",
      "     |          equal to 1. If exposure is specified, then it will be logged by the method.\n",
      "     |          The user does not need to log it first.\n",
      "     |      which : str, optional\n",
      "     |          Define values that will be predicted.\n",
      "     |          'mean', 'mean-main', 'linear', 'mean-nonzero', 'prob-zero, 'prob', 'prob-main'\n",
      "     |          Default is 'mean'.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Generic Zero Inflated model score (gradient) vector of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.discrete.discrete_model.DiscreteModel:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      The cumulative distribution function of the model.\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      The probability density (mass) function of the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ZeroInflatedPoisson(GenericZeroInflated)\n",
      "     |  ZeroInflatedPoisson(endog, exog, exog_infl=None, offset=None, exposure=None, inflation='logit', missing='none', **kwargs)\n",
      "     |  \n",
      "     |  Poisson Zero Inflated Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array_like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  \n",
      "     |  exog_infl : array_like or None\n",
      "     |      Explanatory variables for the binary inflation model, i.e. for\n",
      "     |      mixing probability model. If None, then a constant is used.\n",
      "     |  offset : array_like\n",
      "     |      Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |  exposure : array_like\n",
      "     |      Log(exposure) is added to the linear prediction with coefficient\n",
      "     |      equal to 1.\n",
      "     |  inflation : {'logit', 'probit'}\n",
      "     |      The model for the zero inflation, either Logit (default) or Probit\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  endog : ndarray\n",
      "     |      A reference to the endogenous response variable\n",
      "     |  exog : ndarray\n",
      "     |      A reference to the exogenous design.\n",
      "     |  exog_infl : ndarray\n",
      "     |      A reference to the zero-inflated exogenous design.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ZeroInflatedPoisson\n",
      "     |      GenericZeroInflated\n",
      "     |      statsmodels.discrete.discrete_model.CountModel\n",
      "     |      statsmodels.discrete.discrete_model.DiscreteModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog, exog_infl=None, offset=None, exposure=None, inflation='logit', missing='none', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GenericZeroInflated:\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='bfgs', maxiter=35, full_output=1, disp=1, callback=None, cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      \n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : int\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : int\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : int\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      "     |      Fit the model using a regularized maximum likelihood.\n",
      "     |      \n",
      "     |      The regularization method AND the solver used is determined by the\n",
      "     |      argument method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : 'l1' or 'l1_cvxopt_cp'\n",
      "     |          See notes for details.\n",
      "     |      maxiter : {int, 'defined_by_method'}\n",
      "     |          Maximum number of iterations to perform.\n",
      "     |          If 'defined_by_method', then use method defaults (see notes).\n",
      "     |      full_output : bool\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args).\n",
      "     |      callback : callable callback(xk)\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      "     |          The weight multiplying the l1 penalty term.\n",
      "     |      trim_mode : 'auto, 'size', or 'off'\n",
      "     |          If not 'off', trim (set to zero) parameters that would have been\n",
      "     |          zero if the solver reached the theoretical minimum.\n",
      "     |          If 'auto', trim params using the Theory above.\n",
      "     |          If 'size', trim params if they have very small absolute value.\n",
      "     |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      "     |          Tolerance used when trim_mode == 'size'.\n",
      "     |      auto_trim_tol : float\n",
      "     |          Tolerance used when trim_mode == 'auto'.\n",
      "     |      qc_tol : float\n",
      "     |          Print warning and do not allow auto trim when (ii) (above) is\n",
      "     |          violated by this much.\n",
      "     |      qc_verbose : bool\n",
      "     |          If true, print out a full QC report upon failure.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments used when fitting the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Results\n",
      "     |          A results instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      "     |      \n",
      "     |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      "     |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      "     |      \n",
      "     |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      "     |      \n",
      "     |          'l1'\n",
      "     |              acc : float (default 1e-6)\n",
      "     |                  Requested accuracy as used by slsqp\n",
      "     |          'l1_cvxopt_cp'\n",
      "     |              abstol : float\n",
      "     |                  absolute accuracy (default: 1e-7).\n",
      "     |              reltol : float\n",
      "     |                  relative accuracy (default: 1e-6).\n",
      "     |              feastol : float\n",
      "     |                  tolerance for feasibility conditions (default: 1e-7).\n",
      "     |              refinement : int\n",
      "     |                  number of iterative refinement steps when solving KKT\n",
      "     |                  equations (default: 1).\n",
      "     |      \n",
      "     |      Optimization methodology\n",
      "     |      \n",
      "     |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      "     |      non-smooth problem\n",
      "     |      \n",
      "     |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      "     |      \n",
      "     |      via the transformation to the smooth, convex, constrained problem\n",
      "     |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      "     |      \n",
      "     |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      "     |      \n",
      "     |      subject to\n",
      "     |      \n",
      "     |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      "     |      \n",
      "     |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      "     |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      "     |      minimum, exactly one of two conditions holds:\n",
      "     |      \n",
      "     |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      "     |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Generic Zero Inflated model Hessian matrix of the loglikelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hess : ndarray, (k_vars, k_vars)\n",
      "     |          The Hessian, second derivative of loglikelihood function,\n",
      "     |          evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood of Generic Zero Inflated model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : float\n",
      "     |          The log-likelihood function of the model evaluated at `params`.\n",
      "     |          See notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\sum_{y_{i}=0}\\ln(w_{i}+(1-w_{i})*P_{main\\_model})+\n",
      "     |          \\sum_{y_{i}>0}(\\ln(1-w_{i})+L_{main\\_model})\n",
      "     |          where P - pdf of main model, L - loglike function of main model.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |      Loglikelihood for observations of Generic Zero Inflated model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      loglike : ndarray\n",
      "     |          The log likelihood for each observation of the model evaluated\n",
      "     |          at `params`. See Notes for definition.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. math:: \\ln L=\\ln(w_{i}+(1-w_{i})*P_{main\\_model})+\n",
      "     |          \\ln(1-w_{i})+L_{main\\_model}\n",
      "     |          where P - pdf of main model, L - loglike function of main model.\n",
      "     |      \n",
      "     |      for observations :math:`i=1,...,n`\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, exog_infl=None, exposure=None, offset=None, which='mean')\n",
      "     |      Predict response variable of a count model given exogenous variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      exog : ndarray, optional\n",
      "     |          A reference to the exogenous design.\n",
      "     |          If not assigned, will be used exog from fitting.\n",
      "     |      exog_infl : ndarray, optional\n",
      "     |          A reference to the zero-inflated exogenous design.\n",
      "     |          If not assigned, will be used exog from fitting.\n",
      "     |      offset : ndarray, optional\n",
      "     |          Offset is added to the linear prediction with coefficient equal to 1.\n",
      "     |      exposure : ndarray, optional\n",
      "     |          Log(exposure) is added to the linear prediction with coefficient\n",
      "     |          equal to 1. If exposure is specified, then it will be logged by the method.\n",
      "     |          The user does not need to log it first.\n",
      "     |      which : str, optional\n",
      "     |          Define values that will be predicted.\n",
      "     |          'mean', 'mean-main', 'linear', 'mean-nonzero', 'prob-zero, 'prob', 'prob-main'\n",
      "     |          Default is 'mean'.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  score_obs(self, params)\n",
      "     |      Generic Zero Inflated model score (gradient) vector of the log-likelihood\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The parameters of the model\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray, 1-D\n",
      "     |          The score vector of the model, i.e. the first derivative of the\n",
      "     |          loglikelihood function, evaluated at `params`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.discrete.discrete_model.DiscreteModel:\n",
      "     |  \n",
      "     |  cdf(self, X)\n",
      "     |      The cumulative distribution function of the model.\n",
      "     |  \n",
      "     |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      "     |      Computes cov_params on a reduced parameter space\n",
      "     |      corresponding to the nonzero parameters resulting from the\n",
      "     |      l1 regularized fit.\n",
      "     |      \n",
      "     |      Returns a full cov_params matrix, with entries corresponding\n",
      "     |      to zero'd values set to np.nan.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize is called by\n",
      "     |      statsmodels.model.LikelihoodModel.__init__\n",
      "     |      and should contain any preprocessing that needs to be done for a model.\n",
      "     |  \n",
      "     |  pdf(self, X)\n",
      "     |      The probability density (mass) function of the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    add_constant(data, prepend=True, has_constant='skip')\n",
      "        Add a column of ones to an array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            A column-ordered design matrix.\n",
      "        prepend : bool\n",
      "            If true, the constant is in the first column.  Else the constant is\n",
      "            appended (last column).\n",
      "        has_constant : str {'raise', 'add', 'skip'}\n",
      "            Behavior if ``data`` already has a constant. The default will return\n",
      "            data without adding another constant. If 'raise', will raise an\n",
      "            error if any column has a constant value. Using 'add' will add a\n",
      "            column of 1s if a constant column is present.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        array_like\n",
      "            The original values with a constant (column of ones) as the first or\n",
      "            last column. Returned value type depends on input type.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When the input is a pandas Series or DataFrame, the added column's name\n",
      "        is 'const'.\n",
      "    \n",
      "    categorical(data, col=None, dictnames=False, drop=False)\n",
      "        Construct a dummy matrix from categorical variables\n",
      "        \n",
      "        .. deprecated:: 0.12\n",
      "        \n",
      "           Use pandas.get_dummies instead.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            An array, Series or DataFrame.  This can be either a 1d vector of\n",
      "            the categorical variable or a 2d array with the column specifying\n",
      "            the categorical variable specified by the col argument.\n",
      "        col : {str, int, None}\n",
      "            If data is a DataFrame col must in a column of data. If data is a\n",
      "            Series, col must be either the name of the Series or None. For arrays,\n",
      "            `col` can be an int that is the (zero-based) column index\n",
      "            number.  `col` can only be None for a 1d array.  The default is None.\n",
      "        dictnames : bool, optional\n",
      "            If True, a dictionary mapping the column number to the categorical\n",
      "            name is returned.  Used to have information about plain arrays.\n",
      "        drop : bool\n",
      "            Whether or not keep the categorical variable in the returned matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dummy_matrix : array_like\n",
      "            A matrix of dummy (indicator/binary) float variables for the\n",
      "            categorical data.\n",
      "        dictnames :  dict[int, str], optional\n",
      "            Mapping between column numbers and categorical names.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This returns a dummy variable for *each* distinct variable.  If a\n",
      "        a DaataFrame is provided, the names for the new variable is the\n",
      "        old variable name - underscore - category name.  So if the a variable\n",
      "        'vote' had answers as 'yes' or 'no' then the returned array would have to\n",
      "        new variables-- 'vote_yes' and 'vote_no'.  There is currently\n",
      "        no name checking.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> import statsmodels.api as sm\n",
      "        \n",
      "        Univariate examples\n",
      "        \n",
      "        >>> import string\n",
      "        >>> string_var = [string.ascii_lowercase[0:5],\n",
      "        ...               string.ascii_lowercase[5:10],\n",
      "        ...               string.ascii_lowercase[10:15],\n",
      "        ...               string.ascii_lowercase[15:20],\n",
      "        ...               string.ascii_lowercase[20:25]]\n",
      "        >>> string_var *= 5\n",
      "        >>> string_var = np.asarray(sorted(string_var))\n",
      "        >>> design = sm.tools.categorical(string_var, drop=True)\n",
      "        \n",
      "        Or for a numerical categorical variable\n",
      "        \n",
      "        >>> instr = np.floor(np.arange(10,60, step=2)/10)\n",
      "        >>> design = sm.tools.categorical(instr, drop=True)\n",
      "        \n",
      "        With a structured array\n",
      "        \n",
      "        >>> num = np.random.randn(25,2)\n",
      "        >>> struct_ar = np.zeros((25,1),\n",
      "        ...                      dtype=[('var1', 'f4'),('var2', 'f4'),\n",
      "        ...                             ('instrument','f4'),('str_instr','a5')])\n",
      "        >>> struct_ar['var1'] = num[:,0][:,None]\n",
      "        >>> struct_ar['var2'] = num[:,1][:,None]\n",
      "        >>> struct_ar['instrument'] = instr[:,None]\n",
      "        >>> struct_ar['str_instr'] = string_var[:,None]\n",
      "        >>> design = sm.tools.categorical(struct_ar, col='instrument', drop=True)\n",
      "        \n",
      "        Or\n",
      "        \n",
      "        >>> design2 = sm.tools.categorical(struct_ar, col='str_instr', drop=True)\n",
      "    \n",
      "    load = load_pickle(fname)\n",
      "        Load a previously saved object\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "           Loading pickled models is not secure against erroneous or maliciously\n",
      "           constructed data. Never unpickle data received from an untrusted or\n",
      "           unauthenticated source.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : {str, pathlib.Path}\n",
      "            Filename to unpickle\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This method can be used to load *both* models and results.\n",
      "    \n",
      "    load_pickle(fname)\n",
      "        Load a previously saved object\n",
      "        \n",
      "        .. warning::\n",
      "        \n",
      "           Loading pickled models is not secure against erroneous or maliciously\n",
      "           constructed data. Never unpickle data received from an untrusted or\n",
      "           unauthenticated source.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        fname : {str, pathlib.Path}\n",
      "            Filename to unpickle\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This method can be used to load *both* models and results.\n",
      "    \n",
      "    qqline(ax, line, x=None, y=None, dist=None, fmt='r-', **lineoptions)\n",
      "        Plot a reference line for a qqplot.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ax : matplotlib axes instance\n",
      "            The axes on which to plot the line\n",
      "        line : str {\"45\",\"r\",\"s\",\"q\"}\n",
      "            Options for the reference line to which the data is compared.:\n",
      "        \n",
      "            - \"45\" - 45-degree line\n",
      "            - \"s\"  - standardized line, the expected order statistics are scaled by\n",
      "                     the standard deviation of the given sample and have the mean\n",
      "                     added to them\n",
      "            - \"r\"  - A regression line is fit\n",
      "            - \"q\"  - A line is fit through the quartiles.\n",
      "            - None - By default no reference line is added to the plot.\n",
      "        \n",
      "        x : ndarray\n",
      "            X data for plot. Not needed if line is \"45\".\n",
      "        y : ndarray\n",
      "            Y data for plot. Not needed if line is \"45\".\n",
      "        dist : scipy.stats.distribution\n",
      "            A scipy.stats distribution, needed if line is \"q\".\n",
      "        fmt : str, optional\n",
      "            Line format string passed to `plot`.\n",
      "        **lineoptions\n",
      "            Additional arguments to be passed to the `plot` command.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        There is no return value. The line is plotted on the given `ax`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Import the food expenditure dataset.  Plot annual food expenditure on x-axis\n",
      "        and household income on y-axis.  Use qqline to add regression line into the\n",
      "        plot.\n",
      "        \n",
      "        >>> import statsmodels.api as sm\n",
      "        >>> import numpy as np\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from statsmodels.graphics.gofplots import qqline\n",
      "        \n",
      "        >>> foodexp = sm.datasets.engel.load()\n",
      "        >>> x = foodexp.exog\n",
      "        >>> y = foodexp.endog\n",
      "        >>> ax = plt.subplot(111)\n",
      "        >>> plt.scatter(x, y)\n",
      "        >>> ax.set_xlabel(foodexp.exog_name[0])\n",
      "        >>> ax.set_ylabel(foodexp.endog_name)\n",
      "        >>> qqline(ax, \"r\", x, y)\n",
      "        >>> plt.show()\n",
      "        \n",
      "        .. plot:: plots/graphics_gofplots_qqplot_qqline.py\n",
      "    \n",
      "    qqplot(data, dist=<scipy.stats._continuous_distns.norm_gen object at 0x000001D5AE351180>, distargs=(), a=0, loc=0, scale=1, fit=False, line=None, ax=None, **plotkwargs)\n",
      "        Q-Q plot of the quantiles of x versus the quantiles/ppf of a distribution.\n",
      "        \n",
      "        Can take arguments specifying the parameters for dist or fit them\n",
      "        automatically. (See fit under Parameters.)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            A 1d data array.\n",
      "        dist : callable\n",
      "            Comparison distribution. The default is\n",
      "            scipy.stats.distributions.norm (a standard normal).\n",
      "        distargs : tuple\n",
      "            A tuple of arguments passed to dist to specify it fully\n",
      "            so dist.ppf may be called.\n",
      "        a : float\n",
      "            Offset for the plotting position of an expected order statistic, for\n",
      "            example. The plotting positions are given by (i - a)/(nobs - 2*a + 1)\n",
      "            for i in range(0,nobs+1)\n",
      "        loc : float\n",
      "            Location parameter for dist\n",
      "        scale : float\n",
      "            Scale parameter for dist\n",
      "        fit : bool\n",
      "            If fit is false, loc, scale, and distargs are passed to the\n",
      "            distribution. If fit is True then the parameters for dist\n",
      "            are fit automatically using dist.fit. The quantiles are formed\n",
      "            from the standardized data, after subtracting the fitted loc\n",
      "            and dividing by the fitted scale.\n",
      "        line : {None, \"45\", \"s\", \"r\", \"q\"}\n",
      "            Options for the reference line to which the data is compared:\n",
      "        \n",
      "            - \"45\" - 45-degree line\n",
      "            - \"s\" - standardized line, the expected order statistics are scaled\n",
      "              by the standard deviation of the given sample and have the mean\n",
      "              added to them\n",
      "            - \"r\" - A regression line is fit\n",
      "            - \"q\" - A line is fit through the quartiles.\n",
      "            - None - by default no reference line is added to the plot.\n",
      "        \n",
      "        ax : AxesSubplot, optional\n",
      "            If given, this subplot is used to plot in instead of a new figure being\n",
      "            created.\n",
      "        **plotkwargs\n",
      "            Additional matplotlib arguments to be passed to the `plot` command.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Figure\n",
      "            If `ax` is None, the created figure.  Otherwise the figure to which\n",
      "            `ax` is connected.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.probplot\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Depends on matplotlib. If `fit` is True then the parameters are fit using\n",
      "        the distribution's fit() method.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import statsmodels.api as sm\n",
      "        >>> from matplotlib import pyplot as plt\n",
      "        >>> data = sm.datasets.longley.load()\n",
      "        >>> exog = sm.add_constant(data.exog)\n",
      "        >>> mod_fit = sm.OLS(data.endog, exog).fit()\n",
      "        >>> res = mod_fit.resid # residuals\n",
      "        >>> fig = sm.qqplot(res)\n",
      "        >>> plt.show()\n",
      "        \n",
      "        qqplot of the residuals against quantiles of t-distribution with 4 degrees\n",
      "        of freedom:\n",
      "        \n",
      "        >>> import scipy.stats as stats\n",
      "        >>> fig = sm.qqplot(res, stats.t, distargs=(4,))\n",
      "        >>> plt.show()\n",
      "        \n",
      "        qqplot against same as above, but with mean 3 and std 10:\n",
      "        \n",
      "        >>> fig = sm.qqplot(res, stats.t, distargs=(4,), loc=3, scale=10)\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Automatically determine parameters for t distribution including the\n",
      "        loc and scale:\n",
      "        \n",
      "        >>> fig = sm.qqplot(res, stats.t, fit=True, line=\"45\")\n",
      "        >>> plt.show()\n",
      "        \n",
      "        The following plot displays some options, follow the link to see the code.\n",
      "        \n",
      "        .. plot:: plots/graphics_gofplots_qqplot.py\n",
      "    \n",
      "    qqplot_2samples(data1, data2, xlabel=None, ylabel=None, line=None, ax=None)\n",
      "        Q-Q Plot of two samples' quantiles.\n",
      "        \n",
      "        Can take either two `ProbPlot` instances or two array-like objects. In the\n",
      "        case of the latter, both inputs will be converted to `ProbPlot` instances\n",
      "        using only the default values - so use `ProbPlot` instances if\n",
      "        finer-grained control of the quantile computations is required.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data1 : {array_like, ProbPlot}\n",
      "            Data to plot along x axis. If the sample sizes are unequal, the longer\n",
      "            series is always plotted along the x-axis.\n",
      "        data2 : {array_like, ProbPlot}\n",
      "            Data to plot along y axis. Does not need to have the same number of\n",
      "            observations as data 1. If the sample sizes are unequal, the longer\n",
      "            series is always plotted along the x-axis.\n",
      "        xlabel : {None, str}\n",
      "            User-provided labels for the x-axis. If None (default),\n",
      "            other values are used.\n",
      "        ylabel : {None, str}\n",
      "            User-provided labels for the y-axis. If None (default),\n",
      "            other values are used.\n",
      "        line : {None, \"45\", \"s\", \"r\", q\"}\n",
      "            Options for the reference line to which the data is compared:\n",
      "        \n",
      "            - \"45\" - 45-degree line\n",
      "            - \"s\" - standardized line, the expected order statistics are scaled\n",
      "              by the standard deviation of the given sample and have the mean\n",
      "              added to them\n",
      "            - \"r\" - A regression line is fit\n",
      "            - \"q\" - A line is fit through the quartiles.\n",
      "            - None - by default no reference line is added to the plot.\n",
      "        \n",
      "        ax : AxesSubplot, optional\n",
      "            If given, this subplot is used to plot in instead of a new figure being\n",
      "            created.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Figure\n",
      "            If `ax` is None, the created figure.  Otherwise the figure to which\n",
      "            `ax` is connected.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.probplot\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        1) Depends on matplotlib.\n",
      "        2) If `data1` and `data2` are not `ProbPlot` instances, instances will be\n",
      "           created using the default parameters. Therefore, it is recommended to use\n",
      "           `ProbPlot` instance if fine-grained control is needed in the computation\n",
      "           of the quantiles.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import statsmodels.api as sm\n",
      "        >>> import numpy as np\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from statsmodels.graphics.gofplots import qqplot_2samples\n",
      "        >>> x = np.random.normal(loc=8.5, scale=2.5, size=37)\n",
      "        >>> y = np.random.normal(loc=8.0, scale=3.0, size=37)\n",
      "        >>> pp_x = sm.ProbPlot(x)\n",
      "        >>> pp_y = sm.ProbPlot(y)\n",
      "        >>> qqplot_2samples(pp_x, pp_y)\n",
      "        >>> plt.show()\n",
      "        \n",
      "        .. plot:: plots/graphics_gofplots_qqplot_2samples.py\n",
      "        \n",
      "        >>> fig = qqplot_2samples(pp_x, pp_y, xlabel=None, ylabel=None,\n",
      "        ...                       line=None, ax=None)\n",
      "    \n",
      "    show_versions(show_dirs=True)\n",
      "        List the versions of statsmodels and any installed dependencies\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        show_dirs : bool\n",
      "            Flag indicating to show module locations\n",
      "    \n",
      "    test(extra_args=None, exit=False)\n",
      "        Run the test suite\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        extra_args : list[str]\n",
      "            List of argument to pass to pytest when running the test suite. The\n",
      "            default is ['--tb=short', '--disable-pytest-warnings'].\n",
      "        exit : bool\n",
      "            Flag indicating whether the test runner should exist when finished.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        int\n",
      "            The status code from the test run if exit is False.\n",
      "    \n",
      "    webdoc(func=None, stable=None)\n",
      "        Opens a browser and displays online documentation\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        func : {str, callable}\n",
      "            Either a string to search the documentation or a function\n",
      "        stable : bool\n",
      "            Flag indicating whether to use the stable documentation (True) or\n",
      "            the development documentation (False).  If not provided, opens\n",
      "            the stable documentation if the current version of statsmodels is a\n",
      "            release\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import statsmodels.api as sm\n",
      "        \n",
      "        Documentation site\n",
      "        \n",
      "        >>> sm.webdoc()\n",
      "        \n",
      "        Search for glm in docs\n",
      "        \n",
      "        >>> sm.webdoc('glm')\n",
      "        \n",
      "        Go to current generated help for OLS\n",
      "        \n",
      "        >>> sm.webdoc(sm.OLS, stable=False)\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        By default, open stable documentation if the current version of\n",
      "        statsmodels is a release.  Otherwise opens the development documentation.\n",
      "        \n",
      "        Uses the default system browser.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['BayesGaussMI', 'BinomialBayesMixedGLM', 'Factor', 'GEE', '...\n",
      "\n",
      "VERSION\n",
      "    0.13.2\n",
      "\n",
      "FILE\n",
      "    d:\\programs\\python310\\lib\\site-packages\\statsmodels\\api.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e7e443",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expr</th>\n",
       "      <th>age</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.351478</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.504438</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.435134</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.572882</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.993803</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106.060605</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>114.593613</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103.445769</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>102.818702</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>105.053772</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>102.622521</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101.556491</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90.918788</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>107.078929</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>105.318178</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>96.810322</td>\n",
       "      <td>1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>101.062276</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.763332</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>94.290992</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90.970949</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>105.030672</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>98.455295</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>97.030269</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>104.207160</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>102.128773</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>98.293741</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>103.947551</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>112.008916</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>98.148634</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>99.222945</td>\n",
       "      <td>2</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          expr  age dose\n",
       "0   107.351478    1   D1\n",
       "1   104.504438    1   D1\n",
       "2   103.435134    1   D1\n",
       "3   109.572882    1   D1\n",
       "4   114.993803    1   D1\n",
       "5   106.060605    1   D1\n",
       "6   114.593613    1   D1\n",
       "7   103.445769    1   D1\n",
       "8   102.818702    1   D1\n",
       "9   105.053772    1   D1\n",
       "10  102.622521    1   D1\n",
       "11  101.556491    1   D1\n",
       "12   90.918788    1   D1\n",
       "13  107.078929    1   D1\n",
       "14  105.318178    1   D1\n",
       "15   96.810322    1   D1\n",
       "16  101.062276    2   D1\n",
       "17  100.763332    2   D1\n",
       "18   94.290992    2   D1\n",
       "19   90.970949    2   D1\n",
       "20  105.030672    2   D1\n",
       "21   98.455295    2   D1\n",
       "22   97.030269    2   D1\n",
       "23  104.207160    2   D1\n",
       "24  102.128773    2   D1\n",
       "25   98.293741    2   D1\n",
       "26  103.947551    2   D1\n",
       "27  112.008916    2   D1\n",
       "28   98.148634    2   D1\n",
       "29   99.222945    2   D1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atero = pd.read_csv('./data/atherosclerosis.csv')\n",
    "atero.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69182254",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {group: list(frame) for group, frame in atero.groupby(['age', 'dose']).expr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b96c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'D1') 5.863453521054204\n",
      "(1, 'D2') 4.369024138263363\n",
      "(2, 'D1') 5.116310343506721\n",
      "(2, 'D2') 5.1353744681594735\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    print(group, np.std(groups[group], ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a64fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dose</th>\n",
       "      <td>16.912241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638094</td>\n",
       "      <td>0.427552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>197.452754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.449841</td>\n",
       "      <td>0.008313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose:age</th>\n",
       "      <td>0.927077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.852272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>1590.257424</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sum_sq    df         F    PR(>F)\n",
       "dose        16.912241   1.0  0.638094  0.427552\n",
       "age        197.452754   1.0  7.449841  0.008313\n",
       "dose:age     0.927077   1.0  0.034978  0.852272\n",
       "Residual  1590.257424  60.0       NaN       NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = atero.copy()\n",
    "model = ols('expr ~ dose*age', data).fit()\n",
    "res = sm.stats.anova_lm(model, typ=2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "228a063c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "      ...  \n",
       "59    False\n",
       "60    False\n",
       "61    False\n",
       "62    False\n",
       "63    False\n",
       "Length: 64, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.age == 1) & (data.dose == 'D1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89beba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'D1'), (1, 'D2'), (2, 'D1'), (2, 'D2')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, j) for i in data.age.unique() \n",
    "        for j in data.dose.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4dd757db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019394870904884"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.age == 1].expr.std()/np.sqrt(data[data.age == 1].expr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9edd8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.errorbar(1, data[data.age == 1].expr.mean(), 2*data[data.age == 1].expr.std()/\n",
    "            np.sqrt(data[data.age == 1].expr.count()), fmt='o', linewidth=2, capsize=6)\n",
    "ax2.errorbar(1, data[data.dose == 'D1'].expr.mean(), 2*data[data.dose == 'D1'].expr.std()/\n",
    "            np.sqrt(data[data.dose == 'D1'].expr.count()), fmt='o', linewidth=2, capsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "630850d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='expr'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x=data[data.age == 1].age, y=data[data.age == 1].expr, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ac3a94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='dose', ylabel='expr'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x=data[data.dose == 'D1'].dose, y=data[data.dose == 'D1'].expr, data=data, capsize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f675307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sum_sq  df         F    PR(>F)\n",
      "age        197.452754   1  7.449841  0.008313\n",
      "dose        16.912241   1  0.638094  0.427552\n",
      "age:dose     0.927077   1  0.034978  0.852272\n",
      "Residual  1590.257424  60       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "N =  len(data.expr)\n",
    "m1 = len(data.age.unique())\n",
    "m2 = len(data.dose.unique())\n",
    "df_a = m1 - 1\n",
    "df_b = m2 - 1\n",
    "df_axb = df_a*df_b \n",
    "df_w = N - m1*m2\n",
    "#Общее среднее\n",
    "grand_mean = data['expr'].mean()\n",
    "#Суммы квадратов\n",
    "ssq_a = sum([(data[data.age ==i].expr.mean()-grand_mean)**2 for i in data.age])\n",
    "ssq_b = sum([(data[data.dose ==i].expr.mean()-grand_mean)**2 for i in data.dose])\n",
    "ssq_t = sum((data.expr - grand_mean)**2)\n",
    "spl_age=[data[data.age == i] for i in data.age.unique()]\n",
    "age_means=[[x_age[x_age.dose == d].expr.mean() for d in x_age.dose] for x_age in spl_age]\n",
    "ssq_w = sum([sum((spl_age[i].expr-age_means[i])**2) for i in range(len(data.age.unique()))])\n",
    "\n",
    "ssq_axb = ssq_t-ssq_a-ssq_b-ssq_w\n",
    "#Средние квадраты\n",
    "ms_a = ssq_a/df_a\n",
    "ms_b = ssq_b/df_b\n",
    "ms_axb = ssq_axb/df_axb\n",
    "ms_w = ssq_w/df_w\n",
    "#F-значения\n",
    "f_a = ms_a/ms_w\n",
    "f_b = ms_b/ms_w\n",
    "f_axb = ms_axb/ms_w\n",
    "#P-значения\n",
    "p_a = scipy_stats.f.sf(f_a, df_a, df_w)\n",
    "p_b = scipy_stats.f.sf(f_b, df_b, df_w)\n",
    "p_axb = scipy_stats.f.sf(f_axb, df_axb, df_w)\n",
    "#результаты\n",
    "results = {'sum_sq':[ssq_a, ssq_b, ssq_axb, ssq_w],\n",
    "           'df':[df_a, df_b, df_axb, df_w],\n",
    "           'F':[f_a, f_b, f_axb, 'NaN'],\n",
    "            'PR(>F)':[p_a, p_b, p_axb, 'NaN']}\n",
    "columns=['sum_sq', 'df', 'F', 'PR(>F)']\n",
    "aov_table1 = pd.DataFrame(results, columns=columns,\n",
    "                          index=['age', 'dose', \n",
    "                          'age:dose', 'Residual'])\n",
    "print(aov_table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64b8e3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 'D1'): 104.75846407656802, (1, 'D2'): 105.5458643045101, (2, 'D1'): 101.00480486634189, (2, 'D2'): 102.27362937036308} {1: 105.15216419053905, 2: 101.63921711835249} {'D1': 102.88163447145496, 'D2': 103.90974683743659}\n"
     ]
    }
   ],
   "source": [
    "## interaction term manually\n",
    "a_means = {i: data[data.age == i].expr.mean() for i in data.age.unique()}\n",
    "b_means = {i: data[data.dose == i].expr.mean() for i in data.dose.unique()}\n",
    "axb_means = {(i, j): data[(data.age == i) & (data.dose == j)].expr.mean() \n",
    "                     for i in data.age.unique() for j in data.dose.unique()} \n",
    "ssq_axb_man = sum([(axb_means[(i, j)] + grand_mean - a_means[i] - b_means[j])**2 \n",
    "                   for (i, j) in zip(data.age, data.dose)])\n",
    "print(axb_means, a_means, b_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6877d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9270773343935161, 0.9270773343932915, 0.9999999999997577)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssq_axb, ssq_axb_man, ssq_axb_man/ssq_axb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d916d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.000000000003883"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9208b325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var4</th>\n",
       "      <th>hormone</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.859039</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.842343</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.318099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.064451</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.620316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.574463</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.779778</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.268481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.111522</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.313773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.505793</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.806948</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24.210153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.673599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.152882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21.796952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20.580963</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19.433480</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.222232</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.768142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         var4  hormone  sex\n",
       "0   17.859039        1    1\n",
       "1   20.842343        1    1\n",
       "2   19.318099        1    1\n",
       "3   20.064451        1    1\n",
       "4   17.620316        1    1\n",
       "5   14.574463        1    1\n",
       "6   14.779778        1    1\n",
       "7   19.268481        1    1\n",
       "8   22.111522        1    1\n",
       "9   18.313773        1    1\n",
       "10  24.505793        1    1\n",
       "11  20.806948        1    1\n",
       "12  24.210153        1    1\n",
       "13  14.673599        1    1\n",
       "14  25.152882        1    1\n",
       "15  21.796952        1    1\n",
       "16  20.580963        0    1\n",
       "17  19.433480        0    1\n",
       "18  18.222232        0    1\n",
       "19  19.768142        0    1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds = pd.read_csv('./data/birds.csv')\n",
    "birds.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6f67d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hormone</th>\n",
       "      <td>0.847472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086528</td>\n",
       "      <td>0.769653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.119762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.912318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hormone:sex</th>\n",
       "      <td>89.483384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.136390</td>\n",
       "      <td>0.003682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>587.650394</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sum_sq    df         F    PR(>F)\n",
       "hormone        0.847472   1.0  0.086528  0.769653\n",
       "sex            0.119762   1.0  0.012228  0.912318\n",
       "hormone:sex   89.483384   1.0  9.136390  0.003682\n",
       "Residual     587.650394  60.0       NaN       NaN"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b = ols('var4 ~ hormone*sex', birds).fit()\n",
    "res_b = sm.stats.anova_lm(model_b, typ=2)\n",
    "res_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51e741b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='hormone', ylabel='var4'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x='hormone', y='var4', hue='sex', dodge=0.1, capsize=.1, data=birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44a49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
